{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2984110-71b2-4348-a58c-ff8040667ee3",
   "metadata": {},
   "source": [
    "#### 프로젝트 : mini BERT 만들기\n",
    "##### 학습목표\n",
    "1. [X] 한글 코퍼스를 가공하여 BERT pretrain용 데이터셋을 잘 생성하였다.\n",
    "2. [X] 구현한 BERT 모델의 학습이 안정적으로 진행됨을 확인하였다.\n",
    "3. [X] Vocab size를 8000으로 줄이고, 1M짜리 mini BERT 모델의 제작과 학습이 정상적으로 진행되었다.\n",
    "##### 평가기준\n",
    "1. [X] MLM, NSP task의 특징이 잘 반영된 pretrain용 데이터셋 생성과정이 체계적으로 진행되었다.\n",
    "2. [X] 학습진행 과정 중에 MLM, NSP loss의 안정적인 감소가 확인되었다.\n",
    "3. [X] 학습된 모델 및 학습과정의 시각화 내역이 제출되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0daf0-d102-4ac5-99e1-13e431795727",
   "metadata": {},
   "source": [
    "##### 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58a7cea-d91a-487a-931b-67c49b1ffed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://d3s0tskafalll9.cloudfront.net/media/documents/kowiki.txt.zip\n",
    "# !unzip kowiki.txt.zip\n",
    "# !pip install sentencepiece\n",
    "# !pip install tqdm\n",
    "# !conda install -y -c conda-forge ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95693c-59e7-411f-88f1-c1e4806ce622",
   "metadata": {},
   "source": [
    "##### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b98774-3a9b-4411-a0a4-6524db3f7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __future__ 모듈 불러오기 (파이썬 버전 호환성 보장용)\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# PyTorch 관련 라이브러리\n",
    "import torch\n",
    "import torch.nn as nn                 # 신경망 레이어 정의\n",
    "import torch.nn.functional as F       # 활성화 함수 및 손실 함수\n",
    "import torch.optim as optim           # 최적화 알고리즘 (SGD, Adam 등)\n",
    "from torch.utils.data import DataLoader, TensorDataset  # 데이터 로딩/배치 구성\n",
    "from torchsummary import summary      # 모델 구조 요약 (Keras summary 유사)\n",
    "from torchinfo import summary         # 더 상세한 모델 summary\n",
    "\n",
    "# 파이썬 표준 라이브러리\n",
    "import os, re, math, random, json, shutil, zipfile, copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from datetime import datetime\n",
    "\n",
    "# 시각화 및 학습 진행 상황 표시\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm        # 학습 진행 상태 Progress Bar\n",
    "import sentencepiece as spm           # 토크나이저 (SentencePiece)\n",
    "\n",
    "# 랜덤 시드 고정 (재현 가능성 확보)\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565973e-0360-4411-9813-1eb36a54392c",
   "metadata": {},
   "source": [
    "##### Tokenizer 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39f0f40-9957-4d8e-b7c8-bfa3c4bbc0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nspm.SentencePieceTrainer.train(\\n    f\"--input={corpus_file} \"\\n    f\"--model_prefix={prefix} \"\\n    f\"--vocab_size={vocab_size + 7} \"\\n    f\"--model_type=bpe \"\\n    f\"--max_sentence_length=999999 \"\\n    f\"--pad_id=0 --pad_piece=[PAD] \"\\n    f\"--unk_id=1 --unk_piece=[UNK] \"\\n    f\"--bos_id=2 --bos_piece=[BOS] \"\\n    f\"--eos_id=3 --eos_piece=[EOS] \"\\n    f\"--user_defined_symbols=[SEP],[CLS],[MASK]\"\\n)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위키 코퍼스 파일 경로 (학습 데이터)\n",
    "corpus_file = \"kowiki.txt\"\n",
    "\n",
    "# 학습된 모델의 저장 prefix (모델/단어 사전 파일 이름 접두사)\n",
    "prefix = \"ko_8000\"\n",
    "\n",
    "# 단어 사전 크기 (vocab size)\n",
    "vocab_size = 8000\n",
    "\n",
    "# SentencePieceTrainer를 사용한 BPE 토크나이저 학습\n",
    "# 실제 실행 시 주석을 해제해서 사용합니다.\n",
    "# - vocab_size + 7 : [PAD], [UNK], [BOS], [EOS], [SEP], [CLS], [MASK] 7개 특수토큰 추가\n",
    "# - model_type=bpe : Byte-Pair Encoding 방식 사용\n",
    "# - max_sentence_length=999999 : 문장 최대 길이 설정\n",
    "# - user_defined_symbols : 추가 사용자 정의 토큰 설정\n",
    "\"\"\"\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus_file} \"\n",
    "    f\"--model_prefix={prefix} \"\n",
    "    f\"--vocab_size={vocab_size + 7} \"\n",
    "    f\"--model_type=bpe \"\n",
    "    f\"--max_sentence_length=999999 \"\n",
    "    f\"--pad_id=0 --pad_piece=[PAD] \"\n",
    "    f\"--unk_id=1 --unk_piece=[UNK] \"\n",
    "    f\"--bos_id=2 --bos_piece=[BOS] \"\n",
    "    f\"--eos_id=3 --eos_piece=[EOS] \"\n",
    "    f\"--user_defined_symbols=[SEP],[CLS],[MASK]\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3406ee28-7b95-4dab-9a67-953239c857e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentencePieceProcessor 객체 생성\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "\n",
    "# 학습된 SentencePiece 모델 로드 (.model 파일)\n",
    "# -> ko_8000.model 과 ko_8000.vocab 파일이 같은 위치에 있어야 함\n",
    "vocab.load(\"ko_8000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc17d151-a6c4-4905-9bcd-1c66f866e684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁1', '▁이', '으로', '에서', '▁있', '▁2', '▁그', '▁대', '▁사', '이다', '었다', '▁지', '▁수', '▁19', '▁가', '▁시', '▁20', '▁기', '▁전', '▁아', '▁하', '▁있다', '▁다', '▁제', '했다', '하였', '▁일', '▁한', '▁중', '▁정', '▁주', '하는', '▁것', '▁자', '▁공', '▁인', '되었다', '▁경', '▁위', '▁유', '▁보', '하고', '▁3', '▁등', '▁부', '하였다', '▁조', '하여', '▁미', '▁동', '▁선', '▁나', '으며', '▁모', '▁연', '▁영', '▁의', '▁오', '▁마', '에는', '▁발', '▁소', '한다', '▁고', '▁개', '▁201', '▁구', '▁세', '▁도', '▁상', '▁비', '▁스', '▁국', '▁서', '▁후', '▁여', '▁200', '▁때', '▁4', '▁성', '▁해', '▁관', '▁있는', '▁신', '▁프', '▁대한', '부터', '▁5', '▁방', '▁또', '지만', '▁(', '▁역', '되어', '▁않', '▁만', '▁\"', '▁장', '▁바', '까지']\n"
     ]
    }
   ],
   "source": [
    "# 학습된 vocab에서 특수 토큰([PAD]~[MASK])을 제외한 실제 토큰 리스트 생성\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):  # 0~6은 특수토큰, 7번부터 일반 토큰 시작\n",
    "    if not vocab.is_unknown(id):              # [UNK]가 아닌 경우만 추가\n",
    "        vocab_list.append(vocab.id_to_piece(id))  # 토큰 ID → 실제 토큰 문자열 변환\n",
    "\n",
    "# 학습된 토큰 중 앞 100개만 출력 (샘플 확인용)\n",
    "print(vocab_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18589aba-3b67-4cd5-9836-585b4259d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# 입력 문장 A와 B 정의\n",
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "\n",
    "# 문장 A, B를 SentencePiece 토큰화 후\n",
    "# BERT 입력 형식에 맞게 [CLS] + A + [SEP] + B + [SEP] 형태로 구성\n",
    "tokens_org = (\n",
    "    [\"[CLS]\"] \n",
    "    + vocab.encode_as_pieces(string_a) \n",
    "    + [\"[SEP]\"] \n",
    "    + vocab.encode_as_pieces(string_b) \n",
    "    + [\"[SEP]\"]\n",
    ")\n",
    "\n",
    "# 변환된 토큰 시퀀스 출력\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ae812-1719-4477-8908-2c1211b7001d",
   "metadata": {},
   "source": [
    "##### 데이터 전처리 (1) MASK 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dab1c99-e6df-4e18-9800-fe06d26f089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변환된 토큰 시퀀스 출력 (확인용)\n",
    "print(tokens_org)\n",
    "\n",
    "# [CLS], [SEP], [SEP] 3개 특수토큰 제외\n",
    "# 나머지 토큰 중 15%를 마스킹 대상으로 설정\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "\n",
    "# 마스크 대상 개수 출력\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d96d9cdd-272c-4131-916d-f37a9fbf71fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4] ['▁추', '적', '추', '적']\n",
      "[5, 6] ['▁비', '가']\n",
      "[7, 8] ['▁내', '리는']\n",
      "[9, 10, 11] ['▁날', '이었', '어']\n",
      "[12, 13, 14] ['▁그', '날', '은']\n",
      "[15, 16, 17] ['▁', '왠', '지']\n",
      "[18, 19, 20] ['▁손', '님', '이']\n",
      "[21, 22] ['▁많', '아']\n",
      "[23] ['▁첫']\n",
      "[24, 25] ['▁번', '에']\n",
      "[26, 27] ['▁삼', '십']\n",
      "[28] ['▁전']\n",
      "[29, 30, 31] ['▁둘', '째', '번']\n",
      "[32, 33] ['▁오', '십']\n",
      "[34] ['▁전']\n",
      "[35, 36, 37] ['▁오', '랜', '만에']\n",
      "[38, 39, 40] ['▁받아', '보', '는']\n",
      "[41] ['▁십']\n",
      "[42, 43, 44] ['▁전', '짜', '리']\n",
      "[45, 46, 47] ['▁백', '통', '화']\n",
      "[48, 49, 50] ['▁서', '푼', '에']\n",
      "[52, 53, 54] ['▁손', '바', '닥']\n",
      "[55, 56] ['▁위', '엔']\n",
      "[57, 58, 59] ['▁기', '쁨', '의']\n",
      "[60, 61] ['▁눈', '물이']\n",
      "[62, 63] ['▁흘', '러']\n",
      "[64, 65, 66] ['▁컬', '컬', '한']\n",
      "[67, 68] ['▁목', '에']\n",
      "[69, 70] ['▁모', '주']\n",
      "[71, 72, 73] ['▁한', '잔', '을']\n",
      "[74, 75] ['▁적', '셔']\n",
      "[76] ['▁몇']\n",
      "[77] ['▁달']\n",
      "[78] ['▁포']\n",
      "[79, 80] ['▁전', '부터']\n",
      "[81, 82, 83, 84] ['▁콜', '록', '거', '리는']\n",
      "[85] ['▁아내']\n",
      "[86, 87] ['▁생각', '에']\n",
      "[88, 89, 90] ['▁그', '토', '록']\n",
      "[91, 92] ['▁먹', '고']\n",
      "[93, 94, 95] ['▁싶', '다', '던']\n"
     ]
    }
   ],
   "source": [
    "cand_idx = []  \n",
    "for (i, token) in enumerate(tokens_org):\n",
    "    # 특수 토큰([CLS], [SEP])은 마스킹 후보에서 제외\n",
    "    if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "        continue\n",
    "    \n",
    "    # SentencePiece에서 단어 시작은 \"▁\"(U+2581) 로 표시됨\n",
    "    # 만약 현재 토큰이 단어의 연속이라면 → 직전 후보 리스트에 추가\n",
    "    if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  \n",
    "        cand_idx[-1].append(i)\n",
    "    else:\n",
    "        # 새로운 단어 시작\n",
    "        cand_idx.append([i])\n",
    "\n",
    "# 후보 인덱스 및 실제 토큰 출력 (확인용)\n",
    "for cand in cand_idx:\n",
    "    print(cand, [tokens_org[i] for i in cand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db761cc3-cd72-4a8a-9b6b-7e35a75b57ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24, 25],\n",
       " [57, 58, 59],\n",
       " [32, 33],\n",
       " [64, 65, 66],\n",
       " [41],\n",
       " [79, 80],\n",
       " [52, 53, 54],\n",
       " [67, 68],\n",
       " [29, 30, 31],\n",
       " [91, 92],\n",
       " [23],\n",
       " [26, 27],\n",
       " [76],\n",
       " [42, 43, 44],\n",
       " [78],\n",
       " [60, 61],\n",
       " [38, 39, 40],\n",
       " [93, 94, 95],\n",
       " [9, 10, 11],\n",
       " [81, 82, 83, 84],\n",
       " [85],\n",
       " [12, 13, 14],\n",
       " [34],\n",
       " [71, 72, 73],\n",
       " [77],\n",
       " [45, 46, 47],\n",
       " [48, 49, 50],\n",
       " [28],\n",
       " [74, 75],\n",
       " [62, 63],\n",
       " [88, 89, 90],\n",
       " [5, 6],\n",
       " [35, 36, 37],\n",
       " [55, 56],\n",
       " [18, 19, 20],\n",
       " [86, 87],\n",
       " [7, 8],\n",
       " [15, 16, 17],\n",
       " [1, 2, 3, 4],\n",
       " [21, 22],\n",
       " [69, 70]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 단위 후보 인덱스 리스트를 랜덤 셔플\n",
    "random.shuffle(cand_idx)\n",
    "\n",
    "# 섞인 후보 인덱스 출력\n",
    "cand_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af4602e-f39b-472f-8c8d-0534dd023e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[MASK]', '[MASK]', '[MASK]', '▁삼', '십', '▁전', '▁둘', '째', '번', '[MASK]', '[MASK]', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '프', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '[MASK]', '[MASK]', '[MASK]', '▁눈', '물이', '▁흘', '러', '[MASK]', '[MASK]', '[MASK]', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# 원본 토큰 시퀀스를 복사 (원본은 보존)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_lms = []  # 마스크된 토큰 정보 (index, label) 저장 리스트\n",
    "for index_set in cand_idx:\n",
    "    # 마스크할 개수를 초과하면 종료\n",
    "    if len(mask_lms) >= mask_cnt:\n",
    "        break\n",
    "    # 단어 단위 마스킹 시, 전체 개수를 초과하지 않도록 제어\n",
    "    if len(mask_lms) + len(index_set) > mask_cnt:\n",
    "        continue\n",
    "    \n",
    "    # dice 값으로 마스킹 유형 결정 (80/10/10 규칙)\n",
    "    dice = random.random()\n",
    "    for index in index_set:\n",
    "        masked_token = None\n",
    "        if dice < 0.8:        # 80% 확률 → [MASK] 토큰으로 대체\n",
    "            masked_token = \"[MASK]\"\n",
    "        elif dice < 0.9:      # 10% 확률 → 원래 토큰 유지\n",
    "            masked_token = tokens[index]\n",
    "        else:                 # 10% 확률 → 랜덤 토큰으로 대체\n",
    "            masked_token = random.choice(vocab_list)\n",
    "\n",
    "        # 마스크된 위치와 정답 토큰(label)을 기록\n",
    "        mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "        # 실제 입력 토큰 시퀀스 갱신\n",
    "        tokens[index] = masked_token\n",
    "\n",
    "# 결과 확인\n",
    "print(\"tokens_org\")  # 원본 토큰 시퀀스\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")      # 마스킹된 토큰 시퀀스\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cee0642-977a-41d3-b4bb-0488032eda25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_idx   : [23, 24, 25, 32, 33, 41, 57, 58, 59, 64, 65, 66, 79, 80]\n",
      "mask_label : ['▁첫', '▁번', '에', '▁오', '십', '▁십', '▁기', '쁨', '의', '▁컬', '컬', '한', '▁전', '부터']\n"
     ]
    }
   ],
   "source": [
    "# 마스크된 토큰들을 index 순서대로 정렬\n",
    "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "\n",
    "# 마스크 위치(index) 리스트\n",
    "mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "\n",
    "# 정답 레이블(원래 토큰) 리스트\n",
    "mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"mask_idx   :\", mask_idx)     # 마스킹된 위치\n",
    "print(\"mask_label :\", mask_label)   # 해당 위치의 원래 토큰(정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f55c18-1621-4a2b-a669-27c4193f9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '[MASK]', '[MASK]', '[MASK]', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '팹', '著', '內', '[SEP]', '▁손', '바', '닥', '[MASK]', '[MASK]', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '[MASK]', '[MASK]', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '[MASK]', '[MASK]', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "mask_idx   : [21, 22, 23, 48, 49, 50, 55, 56, 62, 63, 69, 70, 86, 87]\n",
      "mask_label : ['▁많', '아', '▁첫', '▁서', '푼', '에', '▁위', '엔', '▁흘', '러', '▁모', '주', '▁생각', '에']\n"
     ]
    }
   ],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    BERT Pre-training용 MLM 마스킹 함수\n",
    "    Args:\n",
    "        tokens (list): 입력 토큰 시퀀스 (BERT 포맷: [CLS] ... [SEP] ... [SEP])\n",
    "        mask_cnt (int): 전체 토큰 중 마스킹할 개수\n",
    "        vocab_list (list): 랜덤 치환 시 사용할 일반 토큰 리스트\n",
    "    Returns:\n",
    "        tokens (list): 마스킹이 적용된 토큰 시퀀스\n",
    "        mask_idx (list): 마스킹된 위치 인덱스\n",
    "        mask_label (list): 각 위치의 정답 레이블 토큰\n",
    "    \"\"\"\n",
    "    cand_idx = []\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        # 특수 토큰([CLS], [SEP])은 마스킹 대상에서 제외\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        # SentencePiece에서 '▁' (U+2581)로 단어 경계 구분\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[-1].append(i)   # 직전 단어에 이어붙이기\n",
    "        else:\n",
    "            cand_idx.append([i])     # 새로운 단어 시작\n",
    "\n",
    "    # 마스킹 후보 순서를 랜덤 셔플\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:            # 목표 개수 채우면 종료\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
    "            continue\n",
    "\n",
    "        # 80/10/10 규칙 적용\n",
    "        dice = random.random()\n",
    "        for index in index_set:\n",
    "            if dice < 0.8:          # 80%: [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9:        # 10%: 원래 토큰 그대로\n",
    "                masked_token = tokens[index]\n",
    "            else:                   # 10%: 랜덤 토큰으로 대체\n",
    "                masked_token = random.choice(vocab_list)\n",
    "\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "\n",
    "    # 마스킹 위치 정렬 (index 순서대로)\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label# 원본 토큰 시퀀스를 복사 (원본 유지)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "# 마스킹 적용 (MLM 데이터 생성)\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"tokens_org\")   # 원본 입력 토큰\n",
    "print(tokens_org, \"\\n\")\n",
    "\n",
    "print(\"tokens\")       # 마스킹된 입력 토큰\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)     # 마스킹된 위치 인덱스\n",
    "print(\"mask_label :\", mask_label)   # 각 위치의 원래 토큰(정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab4e87f-4815-4d5e-9447-ef08badec03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁비', '가', '[MASK]', '[MASK]', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '[MASK]', '[MASK]', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '[MASK]', '[MASK]', '가로', '21', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁일반', '멈', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "mask_idx   : [1, 2, 3, 4, 7, 8, 26, 27, 60, 61, 62, 63, 86, 87]\n",
      "mask_label : ['▁추', '적', '추', '적', '▁내', '리는', '▁삼', '십', '▁눈', '물이', '▁흘', '러', '▁생각', '에']\n"
     ]
    }
   ],
   "source": [
    "tokens = copy.deepcopy(tokens_org)\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c39104-36b8-4cc0-acb9-471dfb49a136",
   "metadata": {},
   "source": [
    "##### 데이터 전처리 (2) NSP pair 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3f8232-2e30-44c7-a0f7-f07858a7304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 입력 문자열 (여러 줄로 구성된 텍스트)\n",
    "string = \"\"\"추적추적 비가 내리는 날이었어\n",
    "그날은 왠지 손님이 많아\n",
    "첫 번에 삼십 전 둘째 번 오십 전\n",
    "오랜만에 받아보는 십 전짜리 백통화 서푼에\n",
    "손바닥 위엔 기쁨의 눈물이 흘러\n",
    "컬컬한 목에 모주 한잔을 적셔\n",
    "몇 달 포 전부터 콜록거리는 아내\n",
    "생각에 그토록 먹고 싶다던\n",
    "설렁탕 한 그릇을 이제는 살 수 있어\n",
    "집으로 돌아가는 길 난 문득 떠올라\n",
    "아내의 목소리가 거칠어만 가는 희박한 숨소리가\n",
    "오늘은 왠지 나가지 말라던 내 옆에 있어 달라던\n",
    "그리도 나가고 싶으면 일찍이라도 들어와 달라던\n",
    "아내의 간절한 목소리가 들려와\n",
    "나를 원망하듯 비는 점점 거세져\n",
    "싸늘히 식어가는 아내가 떠올라 걱정은 더해져\n",
    "난 몰라 오늘은 운수 좋은 날\n",
    "난 맨날 이렇게 살 수 있으면 얼마나 좋을까\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbf49447-bda8-43aa-813a-800d935f5771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'],\n",
       " ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'],\n",
       " ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 줄로 구성된 string을 줄 단위로 분할 → 각 줄을 SentencePiece 토큰화\n",
    "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
    "\n",
    "# 앞 3개 문장 토큰화 결과 확인\n",
    "doc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c5d4b6-794a-4d4f-b32b-6fcfdc13dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 입력 길이 (하나의 학습 예시 토큰 개수)\n",
    "n_test_seq = 64\n",
    "\n",
    "# 최소 시퀀스 길이 (너무 짧은 문장은 제외)\n",
    "min_seq = 8\n",
    "\n",
    "# 최대 시퀀스 길이 (특수토큰 [CLS], [SEP], [SEP] 3개 고려)\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a3ef15d-33b5-41a2-9f97-c369ab10f60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\n",
      "tokens_a: 22 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아']\n",
      "tokens_b: 40 ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\n",
      "\n",
      "current_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\n",
      "tokens_a: 12 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔']\n",
      "tokens_b: 59 ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']\n",
      "\n",
      "current_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\n",
      "tokens_a: 56 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져']\n",
      "tokens_b: 17 ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']\n",
      "\n",
      "current_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\n",
      "tokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\n",
      "tokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []   # 문장들을 묶어둘 버퍼\n",
    "current_length = 0   # 현재 묶음의 총 토큰 길이\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    # 문장 추가\n",
    "    current_chunk.append(doc[i])\n",
    "    current_length += len(doc[i]) \n",
    "    \n",
    "    # 조건 충족 시 → 하나의 학습 샘플로 분리\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "        \n",
    "        # 문장 경계 랜덤 선택 → 앞/뒤 문장 분리\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "            \n",
    "        # 앞쪽 문장 묶음 → tokens_a\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "\n",
    "        # 뒤쪽 문장 묶음 → tokens_b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        # 결과 확인\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        print()\n",
    "        \n",
    "        # 초기화 (다음 chunk 준비)\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d2f89cf-c8dc-437b-bd7c-18821021b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    NSP 학습용 문장 쌍의 길이를 max_seq 이하로 잘라내는 함수\n",
    "    Args:\n",
    "        tokens_a (list): 문장 A 토큰 리스트\n",
    "        tokens_b (list): 문장 B 토큰 리스트\n",
    "        max_seq (int): 최대 시퀀스 길이 (특수토큰 제외)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:   # 길이가 허용 범위 내면 종료\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]          # A가 길면 앞쪽에서 잘라내기\n",
    "        else:\n",
    "            tokens_b.pop()           # B가 길면 뒤쪽에서 잘라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37a6c7cd-41ec-4e47-9e3e-1caa196dbf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\n",
      "is_next: 1\n",
      "tokens_a: 49 ['적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에']\n",
      "tokens_b: 12 ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\n",
      "\n",
      "current_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\n",
      "is_next: 1\n",
      "tokens_a: 31 ['컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던']\n",
      "tokens_b: 30 ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠']\n",
      "\n",
      "current_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\n",
      "is_next: 1\n",
      "tokens_a: 31 ['은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던']\n",
      "tokens_b: 30 ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '가는']\n",
      "\n",
      "current_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\n",
      "is_next: 0\n",
      "tokens_a: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n",
      "tokens_b: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  \n",
    "current_length = 0\n",
    "\n",
    "for i in range(len(doc)):  \n",
    "    # 문장 추가\n",
    "    current_chunk.append(doc[i])  \n",
    "    current_length += len(doc[i])  \n",
    "    \n",
    "    # 조건 충족 시 → 문장 쌍 생성\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq): \n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # 문장 경계 무작위 선택\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        \n",
    "        # 앞쪽 문장 묶음\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "\n",
    "        # 뒤쪽 문장 묶음\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        # 50% 확률로 문장 쌍 순서를 뒤바꿔 is_next = 0 생성\n",
    "        if random.random() < 0.5: \n",
    "            is_next = 0   # False (랜덤 Negative 예시)\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1   # True (실제 문장 순서)\n",
    "\n",
    "        # 길이 제한 적용\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "\n",
    "        # 안전성 체크\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        # 결과 확인\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        print()\n",
    "\n",
    "        # 초기화 후 다음 chunk 준비\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ecb8628-c965-4016-9f09-b82b8b19e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\n",
      "is_next: 0\n",
      "tokens_a: 39 ['▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\n",
      "tokens_b: 22 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아']\n",
      "tokens: 64 ['[CLS]', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', '▁번', '에', '▁삼', '십', '▁전', '[MASK]', '[MASK]', '▁번', '▁오', '십', '굶', '▁오', '랜', '만에', '▁받아', '보', '는', '[MASK]', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '[MASK]', '[MASK]', '[MASK]', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[SEP]']\n",
      "masked index: 9 [6, 7, 11, 18, 49, 50, 51, 61, 62]\n",
      "masked label: 9 ['▁둘', '째', '▁전', '▁십', '▁날', '이었', '어', '▁많', '아']\n",
      "\n",
      "current_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\n",
      "is_next: 1\n",
      "tokens_a: 31 ['컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던']\n",
      "tokens_b: 30 ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠']\n",
      "tokens: 64 ['[CLS]', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', '컬', '한', '[MASK]', '[MASK]', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '[MASK]', '▁달', '[MASK]', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '[MASK]', '[MASK]', '▁길', '▁난', '▁문', '득', '[MASK]', '[MASK]', '[MASK]', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '[SEP]']\n",
      "masked index: 9 [3, 4, 12, 14, 47, 48, 53, 54, 55]\n",
      "masked label: 9 ['▁목', '에', '▁몇', '▁포', '▁돌아', '가는', '▁떠', '올', '라']\n",
      "\n",
      "current_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\n",
      "is_next: 0\n",
      "tokens_a: 17 ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']\n",
      "tokens_b: 44 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나']\n",
      "tokens: 64 ['[CLS]', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', 'え', 'れ', '▁대표적인', '▁더', '해', '져', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '[SEP]']\n",
      "masked index: 9 [12, 13, 14, 40, 41, 42, 43, 44, 45]\n",
      "masked label: 9 ['▁', '걱', '정은', '▁싶', '으면', '▁일', '찍', '이라', '도']\n",
      "\n",
      "current_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\n",
      "is_next: 1\n",
      "tokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\n",
      "tokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n",
      "tokens: 25 ['[CLS]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]']\n",
      "segment: 25 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 25 ['[CLS]', '[MASK]', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]', '▁난', '[MASK]', '[MASK]', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]']\n",
      "masked index: 3 [1, 12, 13]\n",
      "masked label: 3 ['▁난', '▁맨', '날']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instances = []          # 최종 학습 데이터 저장 리스트\n",
    "current_chunk = []  \n",
    "current_length = 0\n",
    "\n",
    "for i in range(len(doc)):  \n",
    "    # 문장 추가\n",
    "    current_chunk.append(doc[i]) \n",
    "    current_length += len(doc[i])  \n",
    "    \n",
    "    # 조건 충족 시 → 문장 쌍 생성\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  \n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "        \n",
    "        # 문장 경계 무작위 분할\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        \n",
    "        # A, B 문장 생성\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        # 50% 확률로 is_next = 0 (랜덤 Negative)\n",
    "        if random.random() < 0.5:  \n",
    "            is_next = 0    \n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1   \n",
    "\n",
    "        # 길이 제한 적용\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "\n",
    "        # 최종 입력 시퀀스 구성 ([CLS] A [SEP] B [SEP])\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "\n",
    "        # Segment ID 생성 (A=0, B=1)\n",
    "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "        print(\"tokens:\", len(tokens), tokens)\n",
    "        print(\"segment:\", len(segment), segment)\n",
    "\n",
    "        # MLM 마스킹 적용\n",
    "        tokens, mask_idx, mask_label = create_pretrain_mask(\n",
    "            tokens, int((len(tokens) - 3) * 0.15), vocab_list\n",
    "        )\n",
    "        print(\"masked tokens:\", len(tokens), tokens)\n",
    "        print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "        print(\"masked label:\", len(mask_label), mask_label)\n",
    "\n",
    "        # 인스턴스 저장\n",
    "        instance = {\n",
    "            \"tokens\": tokens,\n",
    "            \"segment\": segment,\n",
    "            \"is_next\": is_next,\n",
    "            \"mask_idx\": mask_idx,\n",
    "            \"mask_label\": mask_label\n",
    "        }\n",
    "        instances.append(instance)\n",
    "        print()\n",
    "\n",
    "        # 초기화\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b4c966a-057b-4fff-8e34-9ef1b79f2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁번', '에', '▁삼', '십', '▁전', '[MASK]', '[MASK]', '▁번', '▁오', '십', '굶', '▁오', '랜', '만에', '▁받아', '보', '는', '[MASK]', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '[MASK]', '[MASK]', '[MASK]', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 7, 11, 18, 49, 50, 51, 61, 62], 'mask_label': ['▁둘', '째', '▁전', '▁십', '▁날', '이었', '어', '▁많', '아']}\n",
      "{'tokens': ['[CLS]', '컬', '한', '[MASK]', '[MASK]', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '[MASK]', '▁달', '[MASK]', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '[MASK]', '[MASK]', '▁길', '▁난', '▁문', '득', '[MASK]', '[MASK]', '[MASK]', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [3, 4, 12, 14, 47, 48, 53, 54, 55], 'mask_label': ['▁목', '에', '▁몇', '▁포', '▁돌아', '가는', '▁떠', '올', '라']}\n",
      "{'tokens': ['[CLS]', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', 'え', 'れ', '▁대표적인', '▁더', '해', '져', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [12, 13, 14, 40, 41, 42, 43, 44, 45], 'mask_label': ['▁', '걱', '정은', '▁싶', '으면', '▁일', '찍', '이라', '도']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]', '▁난', '[MASK]', '[MASK]', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 12, 13], 'mask_label': ['▁난', '▁맨', '날']}\n"
     ]
    }
   ],
   "source": [
    "# instances 리스트에 저장된 학습용 데이터 샘플들을 출력\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c65644f0-afad-4e4a-95cd-545b7552f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    BERT Pre-training 학습 인스턴스를 생성하는 함수\n",
    "    Args:\n",
    "        vocab (SentencePieceProcessor): 학습된 토크나이저\n",
    "        doc (list): 문서 단위 토큰화 결과 (문장별 토큰 리스트)\n",
    "        n_seq (int): 전체 시퀀스 최대 길이 ([CLS], [SEP], [SEP] 포함)\n",
    "        mask_prob (float): 마스킹 비율 (ex: 0.15 = 15%)\n",
    "        vocab_list (list): 랜덤 치환에 사용할 일반 토큰 리스트\n",
    "    Returns:\n",
    "        instances (list): 학습 샘플 리스트 (딕셔너리 구조)\n",
    "    \"\"\"\n",
    "    max_seq = n_seq - 3     # [CLS], [SEP], [SEP] 제외한 최대 토큰 길이\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        # 문장 누적\n",
    "        current_chunk.append(doc[i])\n",
    "        current_length += len(doc[i])\n",
    "        \n",
    "        # 조건 충족 시 → 하나의 학습 샘플 생성\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "            # 랜덤 경계 선택\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            \n",
    "            # 앞쪽 문장 A\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            \n",
    "            # 뒤쪽 문장 B\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            # 50% 확률로 NSP Negative 샘플 생성\n",
    "            if random.random() < 0.5:\n",
    "                is_next = 0\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1\n",
    "\n",
    "            # 길이 제한 적용\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "\n",
    "            # 최종 입력 시퀀스 구성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "\n",
    "            # Segment ID 생성 (A=0, B=1)\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            # MLM 마스킹 적용\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(\n",
    "                tokens, int((len(tokens) - 3) * mask_prob), vocab_list\n",
    "            )\n",
    "\n",
    "            # 인스턴스 저장\n",
    "            instance = {\n",
    "                \"tokens\": tokens,          # [MASK]가 적용된 입력 토큰 시퀀스\n",
    "                \"segment\": segment,        # NSP용 Segment 구분\n",
    "                \"is_next\": is_next,        # NSP 라벨\n",
    "                \"mask_idx\": mask_idx,      # MLM 마스크 위치\n",
    "                \"mask_label\": mask_label   # MLM 정답 토큰\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            # 초기화 (다음 chunk 준비)\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f89f9a02-697f-4e29-bff2-cb26d8880fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '↔', '숨', '▁날', '이었', '어', '[SEP]', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '틋', '[MASK]', '[MASK]', '[MASK]', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[MASK]', '[MASK]', '[MASK]', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 8, 32, 33, 34, 35, 52, 53, 54], 'mask_label': ['▁내', '리는', '▁번', '▁오', '십', '▁전', '▁손', '바', '닥']}\n",
      "{'tokens': ['[CLS]', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '[MASK]', '[MASK]', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가', '[SEP]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁북', '트', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 7, 8, 9, 10, 20, 21, 61, 62], 'mask_label': ['▁먹', '고', '▁싶', '다', '던', '▁살', '▁수', '▁적', '셔']}\n",
      "{'tokens': ['[CLS]', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '[MASK]', '[MASK]', '[MASK]', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁달', '라', '던', '[MASK]', '[MASK]', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [17, 18, 19, 42, 43, 44, 45, 49, 50], 'mask_label': ['▁식', '어', '가는', '▁내', '▁옆', '에', '▁있어', '▁그리', '도']}\n",
      "{'tokens': ['[CLS]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]', '▁난', '▁몰', '라', '[MASK]', '[MASK]', '▁운', '수', '[MASK]', '▁날', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [18, 19, 22], 'mask_label': ['▁오늘', '은', '▁좋은']}\n"
     ]
    }
   ],
   "source": [
    "# NSP + MLM 학습용 인스턴스 생성\n",
    "instances = create_pretrain_instances(\n",
    "    vocab,          # SentencePiece 토크나이저\n",
    "    doc,            # 문장 단위 토큰화된 문서\n",
    "    n_test_seq,     # 최대 시퀀스 길이 (64)\n",
    "    0.15,           # 마스킹 확률 (15%)\n",
    "    vocab_list      # 랜덤 치환용 일반 토큰 리스트\n",
    ")\n",
    "\n",
    "# 생성된 인스턴스 출력\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87dd72-7623-4c24-8048-bff076eb41c9",
   "metadata": {},
   "source": [
    "##### 데이터 전처리 (3) 데이터셋 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c62e5e8-5fcd-49dd-adcc-c085706f0cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3957761"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = \"kowiki.txt\"\n",
    "total = 0\n",
    "\n",
    "# 파일 열어서 한 줄씩 읽으며 카운트\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "\n",
    "# 전체 문장 수 출력\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69f2f2f3-c260-404a-bc6f-c7fe678f3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fe692475b044b19d4b41e9638109b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 lines : ['▁지', '미', '▁카', '터']\n",
      "['▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카', '터', '▁주', '니어', '(,', '▁192', '4', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '▁대통령', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.']\n",
      "['▁그는', '▁2002', '년', '▁말', '▁인', '권', '과', '▁중', '재', '▁역할', '에', '▁대한', '▁공', '로를', '▁인정', '받아', '▁노', '벨', '▁평화', '상을', '▁받', '게', '▁되었다', '.']\n",
      "\n",
      "14 lines : ['▁수학']\n",
      "['▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '▁구조', ',', '▁공간', ',', '▁변화', ',', '▁미', '적', '분', '▁등의', '▁개념', '을', '▁다루', '는', '▁학', '문', '이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '▁이용', '해서', '▁공', '리로', '▁구성된', '▁추', '상', '적', '▁구조를', '▁연구', '하는', '▁학', '문', '으로', '▁여겨', '지', '기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조', '와', '▁발전', '▁과정', '에서는', '▁자연', '과학', '에', '▁속하는', '▁물리', '학을', '▁비롯한', '▁다른', '▁학', '문', '들과', '▁깊', '은', '▁연', '관을', '▁맺', '고', '▁있다', '.', '▁하지만', ',', '▁어느', '▁과학', '의', '▁분야', '들과', '는', '▁달리', ',', '▁자연', '계에서', '▁관측', '되지', '▁않는', '▁개념', '들에', '▁대해서', '까지', '▁이론', '을', '▁일반', '화', '▁및', '▁추', '상', '화', '시', '킬', '▁수', '▁있다는', '▁차', '이가', '▁있다고', '▁한다', '.', '▁수', '학자', '들은', '▁그러', '한', '▁개념', '들에', '▁대해서', '▁추', '측', '을', '▁하고', ',', '▁적', '절', '하게', '▁선택', '된', '▁정의', '와', '▁공', '리', '로부터', '의', '▁엄', '밀', '한', '▁연', '역을', '▁통해', '서', '▁추', '측', '들의', '▁진', '위를', '▁파', '악', '한다', '.']\n",
      "['▁수', '학의', '▁기초', '를', '▁확', '실', '히', '▁세', '우', '기', '▁위해', ',', '▁수', '리', '논', '리', '학과', '▁집합', '론', '이', '▁발전', '하였고', ',', '▁이와', '▁더불어', '▁범', '주', '론', '이', '▁최근', '에도', '▁발전', '되고', '▁있다', '.', '▁“', '근', '본', '▁위', '기', '”', '라는', '▁말', '은', '▁대', '략', '▁19', '00', '년', '에서', '▁1930', '년', '▁사이에', '▁일어난', ',', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁탐', '구를', '▁상징', '적으로', '▁보여', '주는', '▁말이다', '.', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁몇', '▁가지', '▁의견', '▁불', '일', '치는', '▁오늘날', '에도', '▁계속', '되고', '▁있다', '.', '▁수', '학의', '▁기초', '에', '▁대한', '▁위', '기는', '▁그', '▁당시', '▁수많은', '▁논', '쟁', '에', '▁의해', '▁촉', '발', '되었으며', ',', '▁그', '▁논', '쟁', '에는', '▁칸', '토', '어의', '▁집합', '론', '과', '▁브라', '우', '어', '-', '힐', '베', '르트', '▁논', '쟁', '이', '▁포함', '되었다', '.']\n",
      "\n",
      "4 lines : ['▁수학', '▁상', '수']\n",
      "['▁수학', '에서', '▁상', '수', '란', '▁그', '▁값', '이', '▁변', '하지', '▁않는', '▁불', '변', '량', '으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상', '수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리', '적', '▁측정', '과는', '▁상', '관', '없이', '▁정의', '된다', '.']\n",
      "['▁특정', '▁수학', '▁상', '수', ',', '▁예를', '▁들', '면', '▁골', '롬', '-', '딕', '맨', '▁상', '수', ',', '▁프랑', '세', '즈', '-', '로', '빈', '슨', '▁상', '수', ',', '▁formula', '_1', ',', '▁레', '비', '▁상', '수', '같은', '▁상', '수는', '▁다른', '▁수학', '상', '수', '▁또는', '▁함수', '와', '▁약', '한', '▁상', '관', '관', '계', '▁또는', '▁강한', '▁상', '관', '관', '계를', '▁갖', '는다', '.']\n",
      "\n",
      "10 lines : ['▁문학']\n",
      "['▁문학', '(', '文', '學', ')', '은', '▁언', '어를', '▁예술', '적', '▁표현', '의', '▁제', '재', '로', '▁삼', '아', '▁새로운', '▁의미', '를', '▁창', '출', '하여', ',', '▁인간', '과', '▁사회', '를', '▁진', '실', '되', '게', '▁묘사', '하는', '▁예술', '의', '▁하', '위', '분', '야', '이다', '.', '▁간', '단', '하게', '▁설명', '하면', ',', '▁언', '어를', '▁통해', '▁인간의', '▁삶', '을', '▁미', '적', '(', '美', '的', ')', '으로', '▁형', '상', '화', '한', '▁것이라고', '▁볼', '▁수', '▁있다', '.', '▁문학', '은', '▁원래', '▁문', '예', '(', '文', '藝', ')', '라고', '▁부', '르는', '▁것이', '▁', '옳', '으며', ',', '▁문', '학을', '▁학', '문', '의', '▁대상', '으로서', '▁탐', '구', '하는', '▁학', '문', '의', '▁명칭', '▁역시', '▁문', '예', '학', '이다', '.', '▁문', '예', '학', '은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '▁핵', '심', '분', '야', '로서', '▁인', '문', '학의', '▁하', '위', '범', '주에', '▁포함', '된다', '.']\n",
      "['▁반', '영', '론', '적', '▁관', '점에', '▁의한', '▁감', '상은', '▁작품', '을', '▁창', '작', '된', '▁당시', '▁시대', '▁정', '황', '과', '▁연결', '시켜', '▁감', '상', '하는', '▁입', '장', '이고', ',', '▁내', '재', '적', '▁관', '점', '의', '▁감', '상은', '▁작품', '의', '▁형식', ',', '▁내용', '에', '▁국', '한', '하여', '▁감', '상', '하는', '▁것이다', '.', '▁표현', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁작가', '의', '▁전기', '적', '▁사실', '과', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것이', '고', ',', '▁수용', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁독', '자와', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것을', '▁말한다', '.']\n",
      "\n",
      "10 lines : ['▁나라', '▁목록']\n",
      "['▁이', '▁문', '서는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁20', '6', '개', '▁나라', '의', '▁각', '▁현', '황', '과', '▁주', '권', '▁승', '인', '▁정보를', '▁개', '요', '▁형태로', '▁나', '열', '하고', '▁있다', '.']\n",
      "['▁위', '▁목록', '에', '▁포함', '되지', '▁않은', '▁다음', '▁국가', '는', '▁몬', '테', '비', '데', '오', '▁협', '약', '의', '▁모든', '▁조건', '을', '▁만족', '하지', '▁못', '하거나', ',', '▁자주', '적이고', '▁독립', '적', '임을', '▁주장', '하지', '▁않는', '▁국가', '이다', '.']\n",
      "\n",
      "['▁화학']\n",
      "['▁화학', '(', '化', '學', ',', '▁)', '은', '▁물질', '의', '▁성', '질', ',', '▁조성', ',', '▁구조', ',', '▁변화', '▁및', '▁그', '에', '▁수', '반', '하는', '▁에너', '지의', '▁변', '화를', '▁연구', '하는', '▁자연', '과', '학의', '▁한', '▁분야', '이다', '.', '▁물리', '학', '도', '▁역시', '▁물질', '을', '▁다루', '는', '▁학', '문', '이지만', ',', '▁물리', '학', '이', '▁원', '소', '와', '▁화', '합', '물을', '▁모두', '▁포함한', '▁물', '체의', '▁운동', '과', '▁에너', '지', ',', '▁열', '적', '·', '전', '기', '적', '·', '광', '학적', '·', '기', '계', '적', '▁속', '성을', '▁다루', '고', '▁이러한', '▁현', '상', '으로부터', '▁통일', '된', '▁이론', '을', '▁구축', '하려는', '▁것', '과는', '▁달리', '▁화학', '에서는', '▁물질', '▁자', '체를', '▁연구', '▁대상으로', '▁한다', '.', '▁화학', '은', '▁이미', '▁존재', '하는', '▁물질', '을', '▁이용하여', '▁특', '정한', '▁목', '적', '에', '▁맞', '는', '▁새로운', '▁물질', '을', '▁합', '성', '하는', '▁길', '을', '▁제공', '하며', ',', '▁이는', '▁농', '작', '물의', '▁증', '산', ',', '▁질', '병', '의', '▁치료', '▁및', '▁예', '방', ',', '▁에너', '지', '▁효', '율', '▁증', '대', ',', '▁환경', '오', '염', '▁감소', '▁등', '▁여러', '▁가지', '▁이', '점을', '▁제공', '한다', '.']\n",
      "['▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '해', '낸', '▁화', '합', '물을', '▁뜻', '하였으나', '▁지금', '은', '▁유', '기', '▁화', '합', '물의', '▁범', '위가', '▁크게', '▁넓', '어져', '▁탄', '소', '▁사', '슬', '▁또는', '▁탄', '소', '▁고', '리를', '▁가진', '▁모든', '▁화', '합', '물을', '▁뜻', '한다', '.', '▁유', '기', '화', '학의', '▁오', '랜', '▁관', '심', '사는', '▁유', '기', '▁화', '합', '물의', '▁합', '성', '▁메', '커', '니', '즘', '이다', '.', '▁현', '대에', '▁들어', '서', '▁핵', '자', '기', '▁공', '명', '법', '과', '▁X', '선', '▁결정', '학', '▁등이', '▁개발', '되어', '▁유', '기', '▁화', '합', '물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "count = 5  # 처음 5개 문서만 출력해보기\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  \n",
    "    for line in tqdm(in_f, total=total):   # tqdm으로 전체 진행률 표시\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line == \"\":  # 빈 줄 → 문서 경계\n",
    "            if 0 < len(doc):\n",
    "                if 0 < count:\n",
    "                    count -= 1\n",
    "                    print(len(doc), \"lines :\", doc[0])   # 첫 문장\n",
    "                    print(doc[1])                        # 두 번째 문장\n",
    "                    print(doc[-1])                       # 마지막 문장\n",
    "                    print()\n",
    "                else:\n",
    "                    break\n",
    "                doc = []  # 문서 초기화\n",
    "        else: \n",
    "            # 문장을 SentencePiece 토큰화\n",
    "            pieces = vocab.encode_as_pieces(line)\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "\n",
    "    # 마지막에 남아 있는 문서 처리\n",
    "    if 0 < len(doc):  \n",
    "        print(doc[0])\n",
    "        print(doc[1])\n",
    "        print(doc[-1])\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c0b24af-0446-485d-a8b0-421ce65c6b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8391e25cfd84209be68cab062ffa352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 21 instances: 10\n",
      "{'tokens': ['[CLS]', '▁주', '니어', '(,', '[MASK]', '[MASK]', '[MASK]', '▁10', '월', '[MASK]', '[MASK]', '▁~', '▁)', '는', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '[MASK]', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.', '[SEP]', '▁지', '미', '▁카', '터', '는', '▁조지', '아', '주', '▁섬', '터', '▁카운', '티', '▁플', '레', '인', '스', '▁마을', '에서', '[MASK]', '[MASK]', '▁조지', '아', '▁공', '과', '대학교', '를', '▁졸업', '하였다', '.', '▁그', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [4, 5, 6, 9, 10, 21, 26, 51, 52], 'mask_label': ['▁192', '4', '년', '▁1', '일', '▁대통령', '▁~', '▁태어났다', '.']}\n",
      "{'tokens': ['[CLS]', '▁그는', '▁2002', '년', '▁말', '▁인', '권', '과', '▁중', '재', '[MASK]', '[MASK]', '[MASK]', '▁공', '로를', '▁인정', '받아', '▁노', '벨', '▁평화', '상을', '▁받', '게', '[MASK]', '[MASK]', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '▁해결', '하지', '▁못하고', '▁주', '▁이란', '▁미국', '▁대사', '관', '▁인', '질', '▁사건', '에', '▁발', '목', '이', '▁잡', '혀', '▁실패', '한', '▁대통령', '으로', '▁평가', '를', '▁받', '지만', '▁이란', '▁사', '태', '는', '▁미국', '▁내', '▁이란', '▁재', '산을', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [10, 11, 12, 23, 24, 26, 27, 28, 32], 'mask_label': ['▁역할', '에', '▁대한', '▁되었다', '.', '▁경제', '문', '제를', '▁주']}\n",
      "\n",
      "doc: 14 instances: 7\n",
      "{'tokens': ['[CLS]', '▁수학', '[SEP]', '▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '[MASK]', '[MASK]', '▁공간', ',', '▁변화', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁개념', '을', '▁다루', '는', '▁학', '문', '이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '[MASK]', '[MASK]', '▁공', '리로', '[MASK]', '▁추', '상', '적', '▁구조를', '▁연구', '하는', '▁학', '문', '으로', '▁여겨', '지', '기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조', '와', '▁발전', '▁과정', '에서는', '[SEP]'], 'segment': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [12, 13, 18, 19, 20, 21, 36, 37, 40], 'mask_label': ['▁구조', ',', '▁미', '적', '분', '▁등의', '▁이용', '해서', '▁구성된']}\n",
      "{'tokens': ['[CLS]', '▁논', '쟁', '에', '▁의해', '▁촉', '발', '되었으며', ',', '[MASK]', '▁논', '쟁', '에는', '▁칸', '토', '어의', '▁집합', '론', '과', '▁브라', '우', '어', '-', '힐', '베', '르트', '[MASK]', '[MASK]', '[MASK]', '▁포함', '되었다', '.', '[SEP]', '▁변화', '에', '▁대한', '▁이해', '와', '▁묘', '사는', '▁자연', '과학', '에', '[MASK]', '▁일반적인', '▁주', '제', '이며', ',', '▁미', '적', '분', '학', '은', '▁변', '화를', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁도', '구', '로서', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [9, 26, 27, 28, 43, 56, 57, 58, 59], 'mask_label': ['▁그', '▁논', '쟁', '이', '▁있어서', '▁탐', '구', '하는', '▁강력한']}\n",
      "\n",
      "doc: 4 instances: 1\n",
      "{'tokens': ['[CLS]', '▁수학', '▁상', '수', '[SEP]', '▁수학', '에서', '[MASK]', '[MASK]', '[MASK]', '▁그', '▁값', '이', '▁변', '하지', '▁않는', '▁불', '변', '량', '으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상', '수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리', '적', '▁측정', '과는', '▁상', '관', '없이', '▁정의', '된다', '.', '▁수학', '▁상', '수는', '[MASK]', '[MASK]', '▁실', '수', '체', '나', '▁복', '소', '수', '체의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 8, 9, 49, 50, 59, 60, 61, 62], 'mask_label': ['▁상', '수', '란', '▁대', '개', '▁원', '소', '이다', '.']}\n",
      "{'tokens': ['[CLS]', '▁수학', '▁상', '수', '[SEP]', '▁수학', '에서', '[MASK]', '[MASK]', '[MASK]', '▁그', '▁값', '이', '▁변', '하지', '▁않는', '▁불', '변', '량', '으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상', '수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리', '적', '▁측정', '과는', '▁상', '관', '없이', '▁정의', '된다', '.', '▁수학', '▁상', '수는', '[MASK]', '[MASK]', '▁실', '수', '체', '나', '▁복', '소', '수', '체의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 8, 9, 49, 50, 59, 60, 61, 62], 'mask_label': ['▁상', '수', '란', '▁대', '개', '▁원', '소', '이다', '.']}\n",
      "\n",
      "doc: 10 instances: 4\n",
      "{'tokens': ['[CLS]', '藝', ')', '라고', '▁부', '르는', '▁것이', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁문', '학을', '▁학', '문', '의', '▁대상', '으로서', '▁탐', '구', '하는', '▁학', '문', '의', '▁명칭', '▁역시', '▁문', '예', '학', '이다', '.', '▁문', '예', '학', '은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁인', '문', '학의', '▁하', '위', '범', '주에', '▁포함', '된다', '.', '[SEP]', '▁문학', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], 'is_next': 0, 'mask_idx': [7, 8, 9, 10, 46, 47, 48, 49, 50], 'mask_label': ['▁', '옳', '으며', ',', '▁핵', '심', '분', '야', '로서']}\n",
      "{'tokens': ['[CLS]', '하여', '▁그들의', '▁통', '속', '적인', '▁흥', '미', '와', '▁', '욕', '구를', '▁채', '워', '주는', '[MASK]', '[MASK]', '▁말한다', '.', '▁대중', '문', '학의', '▁하', '위', '장', '르', '에는', '▁여러', '가지', '가', '▁있다', '.', '[SEP]', '▁문', '학을', '▁창', '작', '하는', '▁예술', '가를', '▁문', '예', '가', '라고', '▁부른다', '.', '▁문', '예', '학을', '▁연구', '하는', '▁사람을', '▁문', '예', '학자', '라고', '▁부른다', '.', '▁문', '학을', '[MASK]', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [15, 16, 40, 41, 42, 43, 60, 61, 62], 'mask_label': ['▁문', '학을', '▁문', '예', '가', '라고', '▁창', '작', '하는']}\n",
      "\n",
      "doc: 10 instances: 3\n",
      "{'tokens': ['[CLS]', '▁각', '▁현', '황', '과', '▁주', '권', '▁승', '인', '▁정보를', '[MASK]', '[MASK]', '▁형태로', '▁나', '열', '하고', '▁있다', '.', '[MASK]', '▁목록', '은', '▁명', '료', '화를', '▁위해', '▁두', '▁부분', '으로', '▁나뉘', '어', '▁있다', '.', '[SEP]', '▁두', '▁목록', '은', '[MASK]', '▁가', '나다', '▁순', '이다', '.', '▁강원', '[MASK]', '[MASK]', '▁경우', '▁국가', '로서의', '▁자', '격', '에', '▁논', '쟁', '의', '▁여', '부가', '▁있으며', ',', '▁이', '▁때문에', '▁이러한', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [10, 11, 18, 36, 42, 43, 44, 61, 62], 'mask_label': ['▁개', '요', '▁이', '▁모두', '▁일부', '▁국가', '의', '▁목록', '을']}\n",
      "{'tokens': ['[CLS]', '▁위', '▁기준', '에', '▁논', '거', '하여', '[MASK]', '▁목록', '은', '▁다음', '[MASK]', '[MASK]', '[MASK]', '▁국가', '를', '▁포함', '하고', '▁있다', '.', '[SEP]', '▁특히', ',', '[MASK]', '▁조건', '은', '▁국제', '▁공동', '체의', '▁참여', '▁용', '인을', '▁내', '포', '하고', '▁있기', '▁때문에', ',', '▁다른', '▁나라', '의', '▁승', '인이', '▁매우', '▁중요한', '▁역할을', '▁할', '[MASK]', '▁있다', '.', '▁이', '▁목록', '에', '▁포함', '된', '▁모든', '▁국가', '는', '▁보통', '[MASK]', '▁기준', '을', '▁만족', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [7, 11, 12, 13, 23, 30, 31, 47, 59], 'mask_label': ['▁이', '▁20', '6', '개', '▁마지막', '▁용', '인을', '▁수', '▁이']}\n",
      "\n",
      "doc: 31 instances: 15\n",
      "{'tokens': ['[CLS]', '▁화학', '은', '[MASK]', '[MASK]', '[MASK]', '▁물질', '을', '▁이용하여', '▁특', '정한', '▁목', '적', '에', '▁맞', '는', '▁새로운', '[MASK]', '[MASK]', '▁합', '성', '하는', '▁길', '을', '▁제공', '하며', ',', '▁이는', '▁농', '작', '물의', '▁증', '산', ',', '▁질', '병', '의', '▁치료', '▁및', '[MASK]', '[MASK]', '[MASK]', '▁에너', '지', '▁효', '율', '▁증', '대', ',', '▁환경', '오', '염', '▁감소', '[MASK]', '▁여러', '▁가지', '▁이', '점을', '▁제공', '한다', '.', '[SEP]', '▁화학', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 5, 17, 18, 39, 40, 41, 53], 'mask_label': ['▁이미', '▁존재', '하는', '▁물질', '을', '▁예', '방', ',', '▁등']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁연구', '한다', '.', '▁생', '화', '학', '은', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁유전', '학', ',', '▁면', '역', '학', ',', '▁바이', '러스', '학의', '▁발', '전에', '▁큰', '▁영향을', '▁끼', '쳤다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '[MASK]', '[MASK]', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 10, 11, 12, 13, 14, 44, 45], 'mask_label': ['▁대해서', '도', '▁내', '분', '비', '학', ',', '▁연구', '하는']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 5\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = [] \n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line == \"\":  # 문서 경계\n",
    "            if 0 < len(doc):\n",
    "                instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "                # 인스턴스 생성 결과 출력\n",
    "                print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "                print(instances[0])   # 첫 인스턴스\n",
    "                print(instances[-1])  # 마지막 인스턴스\n",
    "                print()\n",
    "                \n",
    "                doc = []  # 초기화\n",
    "                if 0 < count: \n",
    "                    count -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:  \n",
    "            # 문장 토큰화\n",
    "            pieces = vocab.encode_as_pieces(line)\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    \n",
    "    # 마지막 문서 처리\n",
    "    if 0 < len(doc):  \n",
    "        instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "        print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        print(instances[0])\n",
    "        print(instances[-1])\n",
    "        print()\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "653ed301-f35b-40e4-873d-9f270ed98edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\"\n",
    "    BERT 프리트레이닝용 학습 데이터 생성 함수\n",
    "    Args:\n",
    "        vocab (SentencePieceProcessor): 학습된 토크나이저\n",
    "        in_file (str): 입력 파일 경로 (코퍼스, 예: kowiki.txt)\n",
    "        out_file (str): 출력 파일 경로 (JSONL 포맷)\n",
    "        n_seq (int): 최대 시퀀스 길이 ([CLS], [SEP], [SEP] 포함)\n",
    "        mask_prob (float): 마스킹 비율 (기본 15%)\n",
    "    \"\"\"\n",
    "    # 내부 함수: 한 문서(doc) 단위로 인스턴스 생성 & 저장\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            # JSONL (한 줄 = 하나의 instance)\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # vocab_list 구성 (특수토큰 제외)\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # 전체 라인 수 세기 (tqdm 진행 표시용)\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    # 코퍼스 파일 읽어서 학습 인스턴스 생성 및 저장\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # 빈 줄 = 문서 경계\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "\n",
    "            # 마지막 문서 처리\n",
    "            if 0 < len(doc):\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b61b172-cb24-43fd-b543-cc71c457f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력될 프리트레이닝 데이터 경로\n",
    "pretrain_json_path = \"bert_pre_train.json\"\n",
    "\n",
    "# 위 주석을 해제하면 학습 데이터 생성이 실행됩니다.\n",
    "# - vocab : SentencePiece 토크나이저\n",
    "# - corpus_file : 입력 위키 코퍼스 파일 (예: kowiki.txt)\n",
    "# - pretrain_json_path : 출력 JSONL 파일\n",
    "# - 128 : 최대 시퀀스 길이\n",
    "# make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53f93894-d875-4291-9100-42a3c5d5005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918189"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:     # 한 줄 = 하나의 인스턴스\n",
    "        total += 1\n",
    "\n",
    "# 전체 학습 인스턴스 개수 출력\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4faf223f-69d4-4ee3-aee5-735cdadeb8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " np.int32(0),\n",
       " np.int32(0),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 128\n",
    "max_seq = n_seq - 3  # [CLS], [SEP], [SEP] 제외한 길이\n",
    "\n",
    "# 메모리 효율적인 대규모 배열 저장 (memmap 사용)\n",
    "enc_tokens = np.memmap(\n",
    "    filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq)\n",
    ")  # 입력 토큰 ID\n",
    "segments = np.memmap(\n",
    "    filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq)\n",
    ")  # Segment IDs\n",
    "labels_nsp = np.memmap(\n",
    "    filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,)\n",
    ")  # NSP 라벨\n",
    "labels_mlm = np.memmap(\n",
    "    filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq)\n",
    ")  # MLM 라벨\n",
    "\n",
    "# 배열 일부 확인 (첫 번째, 마지막 샘플)\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ec9e10c-e788-46ef-b42a-ebcb8a9c6736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7b8e010d8b4f6fb90727b92815eb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/918189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '일', '▁~', '[MASK]', '[MASK]', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '▁대통령', '▁(19', '7', '7', '년', '[MASK]', '▁1981', '년', ')', '이다', '.', '▁지', '미', '▁카', '터', '는', '[MASK]', '[MASK]', '[MASK]', '▁섬', '터', '▁카운', '티', '▁플', '레', '인', '스', '▁마을', '에서', '▁태어났다', '.', '▁조지', '아', '▁공', '과', '대학교', '를', '▁졸업', '하였다', '.', '▁그', '▁후', '▁해', '군에', '▁들어가', '▁전', '함', '·', '원', '자', '력', '·', '잠', '수', '함', '의', '▁승', '무', '원으로', '▁일', '하였다', '.', '▁195', '3', '년', '▁미국', '▁해군', '▁대', '위로', '▁예', '편', '하였고', '▁이후', '▁땅', '콩', '·', '면', '화', '[MASK]', '▁가', '꿔', '▁많은', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁그의', '▁별', '명이', '▁\"', '땅', '콩', '▁농', '부', '\"', '▁(', 'P', 'e', 'an', 'ut', '▁F', 'ar', 'm', 'er', ')', '로', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁지', '미', '▁카', '터', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 9, 10, 11, 17, 28, 29, 30, 90, 94, 95, 96, 97, 98, 119, 120, 121], 'mask_label': ['▁)', '는', '▁3', '9', '번째', '▁~', '▁조지', '아', '주', '▁등을', '▁돈', '을', '▁벌', '었다', '.', '▁알려', '졌다', '.']}\n",
      "enc_token: [5, 3629, 203, 6, 6, 1114, 3724, 788, 243, 49, 3632, 796, 663, 1647, 3682, 3682, 3625, 6, 3008, 3625, 3616, 16, 3599, 18, 3686, 207, 3714, 3602, 6, 6, 6, 630, 3714, 3565, 3835, 429, 3740, 3628, 3626, 1369, 10, 1605, 3599, 1755, 3630, 41, 3644, 830, 3624, 1135, 52, 3599, 13, 81, 87, 1501, 2247, 25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636, 3779, 3601, 249, 3725, 1232, 33, 52, 3599, 479, 3652, 3625, 243, 2780, 14, 1509, 168, 3877, 414, 165, 1697, 4290, 3873, 3703, 3683, 6, 21, 5007, 399, 6, 6, 6, 6, 6, 307, 587, 931, 103, 4313, 4290, 613, 3638, 3718, 98, 3878, 3656, 256, 2543, 309, 337, 3735, 181, 3616, 3603, 6, 6, 6, 4, 18, 3686, 207, 3714, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [   0    0    0  241 3602    0    0    0    0   49 3632  796    0    0\n",
      "    0    0    0  203    0    0    0    0    0    0    0    0    0    0\n",
      " 1755 3630 3646    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0  593    0    0    0 1927 3607  813   17\n",
      " 3599    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0  489  376 3599    0    0    0    0\n",
      "    0    0]\n",
      "\n",
      "{'tokens': ['[CLS]', '아', '▁주', '▁상', '원', '▁의원', '▁선거', '에서', '▁낙', '선', '하나', '▁그', '▁선거', '가', '▁부정', '선거', '▁', '였', '음을', '▁입', '증', '하게', '▁되어', '▁당선', '되고', ',', '▁196', '6', '년', '▁조지', '아', '▁주', '▁지', '사', '▁선거', '에', '▁낙', '선', '하지만', '[MASK]', '[MASK]', '▁조지', '아', '▁주', '▁지', '사를', '▁역임', '했다', '.', '▁대통령', '이', '▁되', '기', '▁전', '▁조지', '아', '주', '總', '▁가르', '▁파', '▁두', '번', '▁연', '임', '했으며', ',', '[MASK]', '[MASK]', '▁1975', '년까지', '▁조지', '아', '▁지', '사로', '[MASK]', '[MASK]', '[MASK]', '▁조지', '아', '▁주', '지', '사로', '▁지', '내', '면서', ',', '▁미국', '에', '[MASK]', '▁흑', '인', '▁등', '용', '법을', '▁내', '세', '웠다', '.', '[SEP]', '▁1976', '년', '▁대통령', '▁선거', '에', '▁민주', '당', '▁후보', '로', '▁출', '마', '하여', '▁도', '덕', '주의', '[MASK]', '[MASK]', '▁내', '세', '워', ',', '[MASK]', '[MASK]', '▁누', '르고', '지', '▁달러', '잴', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [39, 40, 57, 58, 59, 66, 67, 74, 75, 76, 88, 114, 115, 120, 121, 124, 125, 126], 'mask_label': ['▁1970', '년', '▁상', '원의', '원을', '▁1971', '년부터', '▁근무', '했다', '.', '▁사는', '▁정책', '으로', '▁포', '드를', '▁당선', '되었다', '.']}\n",
      "enc_token: [5, 3630, 37, 76, 3667, 2378, 822, 10, 1567, 3668, 3294, 13, 822, 3608, 2386, 2163, 3596, 3671, 969, 213, 3929, 173, 607, 2387, 317, 3604, 386, 3673, 3625, 1755, 3630, 37, 18, 3620, 822, 3600, 1567, 3668, 1447, 6, 6, 1755, 3630, 37, 18, 451, 1398, 31, 3599, 663, 3597, 450, 3614, 25, 1755, 3630, 3646, 5400, 2190, 146, 157, 3821, 61, 3773, 530, 3604, 6, 6, 3409, 673, 1755, 3630, 18, 982, 6, 6, 6, 1755, 3630, 37, 3610, 982, 18, 3754, 151, 3604, 243, 3600, 6, 1733, 3628, 50, 3717, 2046, 114, 3692, 1853, 3599, 4, 3306, 3625, 663, 822, 3600, 1114, 3724, 958, 3603, 117, 3674, 54, 75, 4089, 238, 6, 6, 114, 3692, 3964, 3604, 6, 6, 807, 2056, 3610, 2178, 7877, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0 1921 3625    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0   76  955  928    0    0    0    0    0    0 3372  523    0    0\n",
      "    0    0    0    0 2711   31 3599    0    0    0    0    0    0    0\n",
      "    0    0    0    0 3554    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0 1421    9    0    0    0    0  119 1486    0    0 2387   43\n",
      " 3599    0]\n",
      "\n",
      "{'tokens': ['[CLS]', '[MASK]', '▁개발', '을', '▁촉', '구', '했으나', '▁공', '화', '당의', '[MASK]', '[MASK]', '▁무', '산', '되었다', '.', '▁카', '터', '는', '[MASK]', '[MASK]', '[MASK]', '▁이스라엘', '을', '[MASK]', '[MASK]', '[MASK]', '▁캠', '프', '▁데이', '비', '드에서', '▁안', '와', '르', '▁사', '다', '트', '[MASK]', '[MASK]', '▁메', '나', '헴', '▁베', '긴', '▁수상', '과', '▁함께', '▁중', '동', '▁평', '화를', '▁맡았다', '▁캠', '프', '데', '이', '비', '드', '▁협', '정을', '▁체결', '했다', '.', '[SEP]', '▁그러나', '[MASK]', '▁공', '화', '당', '과', '[MASK]', '▁유대', '인', '▁단', '체의', '▁반', '발', '을', '▁일으', '켰', '다', '.', '▁1979', '년', '▁백', '악', '관', '에서', '▁양', '국', '▁간의', '▁평화', '조', '약', '으로', '▁이끌', '어졌다', '.', '▁또한', '▁소련', '과', '▁제', '2', '차', '▁전략', '▁무', '기', '▁제한', '▁협', '상에', '▁조', '인', '했다', '.', '▁카', '터', '는', '▁1970', '년대', '[MASK]', '[MASK]', '▁대한민국', '▁등', '▁인', '권', '▁후', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 10, 11, 19, 20, 21, 24, 25, 26, 38, 39, 52, 66, 71, 100, 101, 120, 121], 'mask_label': ['지', '▁반', '대로', '▁이집', '트', '와', '▁조정', '하여', ',', '▁대통령', '과', '▁위한', '▁이것은', '▁미국의', '▁소련', '과', '▁후반', '▁당시']}\n",
      "enc_token: [5, 6, 570, 3607, 2270, 3653, 1003, 41, 3683, 1547, 6, 6, 107, 3726, 43, 3599, 207, 3714, 3602, 6, 6, 6, 3426, 3607, 6, 6, 6, 2432, 3721, 965, 3694, 3552, 172, 3665, 3699, 15, 3598, 3677, 6, 6, 334, 3637, 5887, 271, 4099, 1011, 3644, 280, 35, 3658, 232, 934, 1896, 2432, 3721, 3736, 3597, 3694, 3681, 617, 666, 2525, 31, 3599, 4, 330, 6, 41, 3683, 3724, 3644, 6, 2670, 3628, 164, 1314, 141, 3720, 3607, 1213, 4174, 3598, 3599, 2995, 3625, 456, 3928, 3708, 10, 230, 3643, 2714, 2793, 3676, 3827, 9, 1435, 2521, 3599, 276, 1302, 3644, 30, 3619, 3751, 2835, 107, 3614, 1956, 617, 1824, 53, 3628, 31, 3599, 207, 3714, 3602, 1921, 596, 6, 6, 410, 50, 42, 3830, 81, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [   0 3610    0    0    0    0    0    0    0    0  141  448    0    0\n",
      "    0    0    0    0    0 2703 3677 3665    0    0 3358   54 3604    0\n",
      "    0    0    0    0    0    0    0    0    0    0  663 3644    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  521    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0 1487    0    0    0\n",
      "    0  679    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0 1302 3644    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0 1840  316    0    0    0    0\n",
      "    0    0]\n",
      "\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁부', '딪', '혀', '吾', '팡', '▁계열', '도에', '▁완', '전', '철', '수', '▁대신', '▁6', ',000', '명을', '▁감', '축', '하는', '▁데', '▁그', '쳤다', '.', '▁또한', '▁박', '정', '희', '[MASK]', '[MASK]', '▁인', '권', '▁문제', '▁등', '과의', '▁논란', '으로', '▁불', '협', '화', '음을', '▁', '냈', '으나', ',', '▁1979', '년', '▁6', '월', '▁하', '순', ',', '▁대한민국', '을', '▁방문', '하여', '▁관계', '가', '▁다', '소', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁그러나', '▁주', '[MASK]', '▁미국', '▁대사', '관', '▁인', '질', '▁사건', '에서', '▁인', '질', '▁구', '출', '▁실패', '를', '[MASK]', '▁1980', '년', '[MASK]', '[MASK]', '[MASK]', '▁공', '화', '당의', '▁로', '널', '드', '▁레이', '건', '▁후보', '에게', '▁', '져', '[MASK]', '▁재', '선에', '▁실패', '했다', '.', '▁또한', '▁임', '기', '▁말', '기에', '▁터', '진', '▁소련', '의', '▁아', '프가', '니', '스탄', '▁침공', '▁사건', '으로', '[MASK]', '▁1980', '년', '▁하계', '▁올림픽', '에', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 6, 7, 8, 9, 29, 30, 61, 62, 63, 67, 81, 84, 85, 86, 99, 121], 'mask_label': ['▁반', '대에', '▁주', '한', '미', '군은', '▁정', '권의', '▁회복', '되었다', '.', '▁이란', '▁이유로', '▁대통령', '▁선거', '에서', '▁결국', '▁인해']}\n",
      "enc_token: [5, 6, 6, 51, 5148, 4178, 6398, 4758, 2440, 1464, 443, 3640, 3917, 3636, 1083, 125, 847, 859, 209, 3909, 38, 189, 13, 1523, 3599, 276, 338, 3642, 4055, 6, 6, 42, 3830, 550, 50, 786, 2408, 9, 128, 3993, 3683, 969, 3596, 4121, 191, 3604, 2995, 3625, 125, 3662, 27, 3946, 3604, 410, 3607, 2017, 54, 704, 3608, 29, 3688, 6, 6, 6, 4, 330, 37, 6, 243, 2630, 3708, 42, 3892, 636, 10, 42, 3892, 73, 3771, 1579, 3624, 6, 1640, 3625, 6, 6, 6, 41, 3683, 1547, 194, 4044, 3681, 1169, 3803, 958, 113, 3596, 3944, 6, 174, 2087, 1579, 31, 3599, 276, 273, 3614, 150, 329, 870, 3713, 1302, 3601, 26, 2986, 3733, 1323, 3232, 636, 9, 6, 1640, 3625, 2219, 779, 3600, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [   0  141  867    0    0    0   37 3612 3686  941    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0   36 2649    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0 3332   43 3599    0    0    0 3290    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0 1827    0    0\n",
      "  663  822   10    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0  875    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  751    0    0    0    0\n",
      "    0    0]\n",
      "\n",
      "{'tokens': ['[CLS]', '한', '▁뒤', '▁민주', '주의', '▁실', '현', '을', '▁위해', '▁제', '▁3', '세', '계의', '[MASK]', '▁감', '시', '▁활동', '▁및', '▁기', '니', '[MASK]', '[MASK]', '[MASK]', '▁의한', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁질', '병', '▁방', '재', '를', '▁위해', '▁힘', '썼', '다', '.', '▁미국의', '▁빈', '곤', '층', '▁지원', '▁활동', ',', '▁사랑', '의', '[MASK]', '[MASK]', '[MASK]', '▁운동', ',', '▁국제', '▁분', '쟁', '▁중', '재', '▁등의', '[MASK]', '[MASK]', '▁했다', '.', '[SEP]', '[MASK]', '[MASK]', '▁~', '▁1980', '년', '▁대한민국의', '▁정치적', '▁격', '변', '기', '[MASK]', '▁대통령', '이었던', '▁그는', '▁이에', '▁대해', '▁애', '매', '한', '▁태', '도를', '▁보', '였고', ',', '▁이는', '▁후에', '▁대한민국', '▁내에서', '▁고', '조', '되는', '▁반', '미', '▁운동', '의', '▁한', '▁원', '인이', '▁', '됐다', '.', '▁10', '월', '▁26', '일', ',', '▁박', '정', '희', '▁대통령', '이', '▁김', '재', '규', '▁중앙', '정보', '부', '장에', '▁의해', '▁살해', '된', '▁것에', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [13, 20, 21, 22, 24, 25, 26, 27, 28, 29, 49, 50, 51, 60, 61, 65, 66, 75], 'mask_label': ['▁선거', '▁벌', '레', '에', '▁드', '라', '쿤', '쿠', '르', '스', '▁집', '짓', '기', '▁활동', '도', '▁1979', '년', '▁당시의']}\n",
      "enc_token: [5, 3612, 339, 1114, 238, 158, 3756, 3607, 231, 30, 49, 3692, 1654, 6, 209, 3623, 375, 228, 24, 3733, 6, 6, 6, 1332, 6, 6, 6, 6, 6, 6, 761, 3886, 95, 3729, 3624, 231, 947, 4437, 3598, 3599, 679, 1412, 4234, 4083, 770, 375, 3604, 1424, 3601, 6, 6, 6, 887, 3604, 605, 147, 3972, 35, 3729, 507, 6, 6, 345, 3599, 4, 6, 6, 203, 1640, 3625, 447, 2843, 1032, 3889, 3614, 6, 663, 1277, 202, 695, 433, 442, 3823, 3612, 227, 701, 47, 2470, 3604, 594, 1140, 410, 3428, 70, 3676, 267, 141, 3686, 887, 3601, 34, 129, 828, 3596, 1027, 3599, 131, 3662, 981, 3629, 3604, 338, 3642, 4055, 663, 3597, 200, 3729, 3958, 782, 2275, 3638, 1312, 355, 2591, 3711, 2057, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0  822\n",
      "    0    0    0    0    0    0  813 3740 3600    0  311 3635 4956 3937\n",
      " 3699 3626    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0  313 4333 3614    0    0    0    0\n",
      "    0    0    0    0  375 3627    0    0    0 2995 3625    0    0    0\n",
      "    0    0    0    0    0 3195    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "\n",
      "{'tokens': ['[CLS]', '▁미국', '이', '▁북', '핵', '▁위', '기', ',', '▁코', '소', '보', '▁전쟁', ',', '▁이', '라크', '▁전쟁', '과', '▁같이', '▁미국', '이', '▁군사', '적', '▁행', '동을', '[MASK]', '[MASK]', '[MASK]', '▁선택', '하는', '[MASK]', '[MASK]', '▁사고', '를', '▁버', '리고', '▁군사', '적', '▁행', '동을', '[MASK]', '[MASK]', '[MASK]', '▁행', '위에', '[MASK]', '▁깊', '은', '▁유', '감을', '▁표시', '▁하며', '▁미국의', '▁군사', '적', '[MASK]', '[MASK]', '▁강한', '▁반대', '[MASK]', '[MASK]', '▁보', '이고', '▁있다', '.', '[SEP]', '▁특히', '▁국제', '▁분', '쟁', '▁조', '정을', '▁위해', '▁북한', '의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁아이', '티', '의', '▁세', '드', '라스', '▁장', '군', ',', '▁팔', '레', '인', '스타', '인의', '▁하', '마', '스', ',', '▁보', '스', '니아', '의', '▁세르', '비아', '계', '▁정', '권', '▁같이', '[MASK]', '▁정부', '에', '▁대해', '▁협', '상을', '▁거부', '하면서', '▁사', '태', '의', '▁위', '기를', '▁초', '래', '한', '▁인물', '▁및', '▁단', '체를', '▁직접', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [24, 25, 26, 29, 30, 39, 40, 41, 44, 54, 55, 58, 59, 74, 75, 76, 77, 106], 'mask_label': ['▁최', '후', '로', '▁전통', '적', '▁선', '행', '하는', '▁대해', '▁활동', '에', '▁입', '장을', '▁김', '일', '성', ',', '▁미국']}\n",
      "enc_token: [5, 243, 3597, 251, 4166, 45, 3614, 3604, 258, 3688, 3672, 506, 3604, 8, 3553, 506, 3644, 733, 243, 3597, 1250, 3657, 236, 1629, 6, 6, 6, 1715, 38, 6, 6, 1646, 3624, 407, 999, 1250, 3657, 236, 1629, 6, 6, 6, 236, 1157, 6, 1910, 3613, 46, 2196, 2466, 1368, 679, 1250, 3657, 6, 6, 2632, 1216, 6, 6, 47, 458, 28, 3599, 4, 698, 605, 147, 3972, 53, 666, 231, 1876, 3601, 6, 6, 6, 6, 520, 3835, 3601, 74, 3681, 1951, 104, 3722, 3604, 961, 3740, 3628, 936, 692, 27, 3674, 3626, 3604, 47, 3626, 491, 3601, 3189, 852, 3704, 36, 3830, 733, 6, 513, 3600, 433, 617, 460, 2324, 421, 15, 3800, 3601, 45, 333, 192, 3808, 3612, 1178, 228, 164, 1396, 1069, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  130 3706 3603    0\n",
      "    0 1306 3657    0    0    0    0    0    0    0    0   57 3752   38\n",
      "    0    0  433    0    0    0    0    0    0    0    0    0  375 3600\n",
      "    0    0  213  480    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0  200 3629 3650 3604    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0  243    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for i, line in enumerate(tqdm(f, total=total)):\n",
    "        if 5 < i:   # 처음 5개 샘플만 확인\n",
    "            break\n",
    "\n",
    "        # JSON 한 줄 읽기\n",
    "        data = json.loads(line)\n",
    "\n",
    "        # 토큰 시퀀스 → ID 변환 (SentencePiece)\n",
    "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "        enc_token += [0] * (n_seq - len(enc_token))  # padding\n",
    "\n",
    "        # Segment ID → padding\n",
    "        segment = data[\"segment\"]\n",
    "        segment += [0] * (n_seq - len(segment))\n",
    "\n",
    "        # NSP 라벨\n",
    "        label_nsp = data[\"is_next\"]\n",
    "\n",
    "        # MLM 라벨\n",
    "        mask_idx = np.array(data[\"mask_idx\"], dtype=int)  # 마스크 위치\n",
    "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=int)  # 정답 토큰 ID\n",
    "        label_mlm = np.full(n_seq, dtype=int, fill_value=0)  # 기본값 0\n",
    "        label_mlm[mask_idx] = mask_label  # 마스크된 위치만 정답 ID 채움\n",
    "\n",
    "        # 디버깅 출력\n",
    "        print(data)\n",
    "        print(\"enc_token:\", enc_token)\n",
    "        print(\"segment:\", segment)\n",
    "        print(\"label_nsp:\", label_nsp)\n",
    "        print(\"label_mlm:\", label_mlm)\n",
    "        print()\n",
    "\n",
    "        # 길이 일치 확인\n",
    "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "        # Memmap 배열에 저장\n",
    "        enc_tokens[i] = enc_token\n",
    "        segments[i] = segment\n",
    "        labels_nsp[i] = label_nsp\n",
    "        labels_mlm[i] = label_mlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a0e180a-8ffe-48d0-a3aa-b6d70b5e4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    BERT 프리트레이닝 데이터를 JSONL에서 읽어\n",
    "    Memmap 배열로 변환하여 반환하는 함수\n",
    "    \n",
    "    Args:\n",
    "        vocab (SentencePieceProcessor): 학습된 토크나이저\n",
    "        filename (str): 프리트레이닝 데이터 JSONL 파일 경로\n",
    "        n_seq (int): 최대 시퀀스 길이\n",
    "        count (int, optional): 로드할 최대 인스턴스 개수 (디버깅용)\n",
    "    \n",
    "    Returns:\n",
    "        (enc_tokens, segments), (labels_nsp, labels_mlm)\n",
    "    \"\"\"\n",
    "    # 전체 데이터 라인 수 확인\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "\n",
    "    # Memmap 배열 초기화\n",
    "    enc_tokens = np.memmap('enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments   = np.memmap('segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap('labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap('labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    # JSONL → Memmap 변환\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # 입력 토큰 → ID 변환 + padding\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "\n",
    "            # Segment IDs + padding\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "\n",
    "            # NSP 라벨\n",
    "            label_nsp = data[\"is_next\"]\n",
    "\n",
    "            # MLM 라벨 (정답 토큰 ID, 나머지는 0)\n",
    "            mask_idx   = np.array(data[\"mask_idx\"], dtype=np.int32)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int32)\n",
    "            label_mlm  = np.full(n_seq, dtype=np.int32, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            # 길이 확인\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            # Memmap 저장\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i]   = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "293fb479-06a4-406d-a66d-04df45717f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807f0d090b314a2a9649ed17d7e0c6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    }
   ],
   "source": [
    "# 프리트레이닝 데이터 로드\n",
    "# - vocab: SentencePiece 토크나이저\n",
    "# - pretrain_json_path: JSONL 데이터 경로 (bert_pre_train.json)\n",
    "# - 128: 최대 시퀀스 길이\n",
    "# - count=128000: 최대 128,000개 샘플만 로드 (디버깅/테스트용)\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(\n",
    "    vocab, pretrain_json_path, 128, count=128000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f91709d5-eca2-4951-9764-8cf5484be492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([   5, 3629,  203,    6,    6, 1114, 3724,  788,  243,   49, 3632,\n",
       "          796,  663, 1647, 3682, 3682, 3625,    6, 3008, 3625, 3616,   16,\n",
       "         3599,   18, 3686,  207, 3714, 3602,    6,    6,    6,  630, 3714,\n",
       "         3565, 3835,  429, 3740, 3628, 3626, 1369,   10, 1605, 3599, 1755,\n",
       "         3630,   41, 3644,  830, 3624, 1135,   52, 3599,   13,   81,   87,\n",
       "         1501, 2247,   25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636,\n",
       "         3779, 3601,  249, 3725, 1232,   33,   52, 3599,  479, 3652, 3625,\n",
       "          243, 2780,   14, 1509,  168, 3877,  414,  165, 1697, 4290, 3873,\n",
       "         3703, 3683,    6,   21, 5007,  399,    6,    6,    6,    6,    6,\n",
       "          307,  587,  931,  103, 4313, 4290,  613, 3638, 3718,   98, 3878,\n",
       "         3656,  256, 2543,  309,  337, 3735,  181, 3616, 3603,    6,    6,\n",
       "            6,    4,   18, 3686,  207, 3714,    4], dtype=int32),\n",
       " memmap([   5, 3676,  848, 3784, 1931,   58, 3676,  416, 2316, 3619, 3625,\n",
       "         3617, 3744, 4335,   12, 3625, 3616,  175, 3662,    7, 3629,  203,\n",
       "            6,    6,    6,    6,    6,    6,  143, 3625, 3616,  131, 3662,\n",
       "          342, 3629, 3616, 3602,  176,  334,  829, 1115, 3665,    6,    6,\n",
       "         3451, 1633,  375,  671, 1644, 3608,  547, 3423,  765,  815, 3604,\n",
       "            6,    6,    6, 2375, 3608, 3604,  532, 2589, 3599,    4,  307,\n",
       "          323,    6,  321, 3611,  622,  122, 3725, 3620, 3627, 3837, 3608,\n",
       "            6,  176,  268, 4082,   94,  567, 4014, 3617, 7474, 3616, 3830,\n",
       "           66, 3590,  307,  192, 1272,  158, 3788,  353, 3599,  202,  316,\n",
       "         3600,  176,   10,  323,  476, 3663, 1329,  605,  238, 3631, 2470,\n",
       "         3604, 1939,  106, 3627,   13,    6,    6, 1128,   48,    6,    6,\n",
       "          848, 3784, 3833,    8, 3637, 2263,    4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " np.int32(0),\n",
       " np.int32(1),\n",
       " memmap([   0,    0,    0,  241, 3602,    0,    0,    0,    0,   49, 3632,\n",
       "          796,    0,    0,    0,    0,    0,  203,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0, 1755, 3630, 3646,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  593,    0,    0,    0, 1927, 3607,  813,   17, 3599,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,  489,  376,\n",
       "         3599,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          578, 3652, 3625, 3617, 4148, 3665,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0, 1381, 4148,\n",
       "         3451,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          752, 3608, 3604,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0, 2143,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          347,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,  162,  490,    0,    0,   28, 3599,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre_train_inputs = (enc_tokens, segments)\n",
    "# pre_train_labels = (labels_nsp, labels_mlm)\n",
    "\n",
    "# enc_tokens[0][0]      → 첫 번째 샘플의 첫 번째 토큰 ID\n",
    "# enc_tokens[0][-1]     → 첫 번째 샘플의 마지막 토큰 ID\n",
    "# segments[0][0]        → 첫 번째 샘플의 첫 번째 segment ID\n",
    "# segments[0][-1]       → 첫 번째 샘플의 마지막 segment ID\n",
    "# labels_nsp[0][0]      → 첫 번째 샘플의 NSP 라벨\n",
    "# labels_nsp[0][-1]     → 마지막 샘플의 NSP 라벨\n",
    "# labels_mlm[0][0]      → 첫 번째 샘플의 첫 번째 MLM 라벨\n",
    "# labels_mlm[0][-1]     → 첫 번째 샘플의 마지막 MLM 라벨\n",
    "\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], \\\n",
    "pre_train_inputs[1][0], pre_train_inputs[1][-1], \\\n",
    "pre_train_labels[0][0], pre_train_labels[0][-1], \\\n",
    "pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33a3f1-fd54-4022-aa86-027c9fd35bf0",
   "metadata": {},
   "source": [
    "##### BERT 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15dd65d5-eb88-444b-a92b-15503f8c7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    Padding Mask 생성\n",
    "    - PAD 토큰(i_pad=0) 위치를 1로 표시, 나머지는 0\n",
    "    - shape: (batch, 1, seq_len)\n",
    "    \"\"\"\n",
    "    mask = (tokens == i_pad).float()   # PAD 위치 = 1\n",
    "    mask = mask.unsqueeze(1)           # shape: (batch, 1, seq_len)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    Look-ahead Mask (Decoder용)\n",
    "    - 미래 토큰을 보지 못하도록 마스크\n",
    "    - shape: (batch, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    n_seq = tokens.size(1)\n",
    "\n",
    "    # 상삼각 행렬 (미래 위치 = 1)\n",
    "    ahead_mask = 1 - torch.tril(torch.ones((n_seq, n_seq)))\n",
    "    ahead_mask = ahead_mask.unsqueeze(0)  # (1, seq_len, seq_len)\n",
    "\n",
    "    # PAD 위치 마스크\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)  # (batch, 1, seq_len)\n",
    "\n",
    "    # 두 마스크 결합 (max 연산으로 1이 우선됨)\n",
    "    mask = torch.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "270e859d-eb5b-4cae-b5e0-8b8162e3d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    Gaussian Error Linear Unit (GELU)\n",
    "    - BERT, GPT-2 등에서 사용되는 활성화 함수\n",
    "    - sigmoid와 ReLU의 장점을 결합\n",
    "    - 입력 분포를 고려해 부드럽게 비선형성을 적용\n",
    "\n",
    "    수식 (근사식):\n",
    "    GELU(x) = 0.5 * x * (1 + tanh( sqrt(2/pi) * (x + 0.044715 * x^3) ))\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + torch.tanh(\n",
    "        math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e39b5b9-105b-440b-90b7-2956f649745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    Weight Initializer\n",
    "    - Truncated Normal 분포를 사용하여 초기화\n",
    "    - stddev 기본값은 0.02 (BERT 논문에서 제안된 값)\n",
    "    \"\"\"\n",
    "    return torch.nn.init.trunc_normal_   # PyTorch 기본 제공\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    Bias Initializer\n",
    "    - 모든 bias 파라미터를 0으로 초기화\n",
    "    \"\"\"\n",
    "    return torch.zeros_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b95f4c-d7b0-4e4a-a590-91b225f4f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    모델 설정(Config) 클래스\n",
    "    - dict를 상속받아 key/value 접근 가능\n",
    "    - 속성(attribute) 접근도 지원 (ex: config.hidden_size)\n",
    "    \"\"\"\n",
    "\n",
    "    # dict[\"key\"] → dict.key 로도 접근 가능하도록 재정의\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        JSON 파일로부터 설정을 불러오는 메서드\n",
    "        Args:\n",
    "            file (str): 설정 파일 경로 (JSON 형식)\n",
    "        Returns:\n",
    "            Config 객체\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d15c126-2b8a-4961-9851-1f32166f7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(nn.Module):\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # 설정값 불러오기\n",
    "        self.n_vocab = config.n_vocab   # 단어 집합 크기\n",
    "        self.d_model = config.d_model   # 임베딩 차원\n",
    "\n",
    "        # 공유 임베딩 행렬 (입력 임베딩 & 출력 가중치 공유)\n",
    "        self.shared_weights = nn.Parameter(torch.empty(self.n_vocab, self.d_model))\n",
    "        nn.init.trunc_normal_(self.shared_weights, std=0.02)  # BERT 초기화 방식\n",
    "\n",
    "    def forward(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        mode=\"embedding\": 토큰 ID → 임베딩 벡터\n",
    "        mode=\"linear\": hidden state → 단어 분포(logits)\n",
    "        \"\"\"\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "\n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        입력 토큰 ID를 임베딩 벡터로 변환\n",
    "        \"\"\"\n",
    "        # 입력 ID 범위를 단어 집합 크기보다 크지 않게 보정\n",
    "        inputs = torch.clamp(inputs, max=self.shared_weights.size(0) - 1)\n",
    "        # 임베딩 조회 (n_batch, n_seq, d_model)\n",
    "        return self.shared_weights[inputs.long()]\n",
    "\n",
    "    def _linear(self, inputs):  \n",
    "        \"\"\"\n",
    "        hidden state를 단어 분포(logits)로 변환\n",
    "        (임베딩 행렬의 전치 행렬 사용)\n",
    "        \"\"\"\n",
    "        n_batch, n_seq, _ = inputs.shape\n",
    "        # (batch*seq, d_model)로 reshape\n",
    "        inputs = inputs.view(-1, self.d_model)\n",
    "        # (batch*seq, vocab) 출력\n",
    "        outputs = torch.matmul(inputs, self.shared_weights.T)\n",
    "        # 다시 (batch, seq, vocab)로 reshape\n",
    "        outputs = outputs.view(n_batch, n_seq, self.n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c823214-74cc-4ef1-ba36-7c34585c718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(nn.Module):\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        super().__init__()\n",
    "        # 최대 시퀀스 길이(config.n_seq) × 임베딩 차원(config.d_model)\n",
    "        self.embedding = nn.Embedding(config.n_seq, config.d_model)\n",
    "        # BERT 초기화 방식 (truncated normal)\n",
    "        nn.init.trunc_normal_(self.embedding.weight, std=0.02)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (Tensor): [batch, seq_len] 형태 (토큰 ID, 값은 사용 안 함)\n",
    "        Returns:\n",
    "            embed (Tensor): [batch, seq_len, d_model] 위치 임베딩\n",
    "        \"\"\"\n",
    "        # 입력 길이(seq_len) 만큼 위치 인덱스 생성\n",
    "        # torch.cumsum(ones) → 1, 2, ..., seq_len → -1 해서 0부터 시작\n",
    "        position = torch.cumsum(torch.ones_like(inputs), dim=1) - 1\n",
    "        position = position.long()  # int64로 변환\n",
    "\n",
    "        # 위치 인덱스를 임베딩 테이블에 매핑\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b011d54-f4b2-461b-a3e9-5ee6d341077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(nn.Module):\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Q: Query 벡터 (batch, head, seq_len, d_k)\n",
    "            K: Key 벡터   (batch, head, seq_len, d_k)\n",
    "            V: Value 벡터 (batch, head, seq_len, d_v)\n",
    "            attn_mask: 마스킹 텐서 (batch, 1, seq_len, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            attn_out: Attention 결과 (batch, head, seq_len, d_v)\n",
    "        \"\"\"\n",
    "        # (batch, head, seq_len, seq_len)\n",
    "        attn_score = torch.matmul(Q, K.transpose(-2, -1))\n",
    "\n",
    "        # d_k의 제곱근으로 스케일링\n",
    "        scale = torch.sqrt(torch.tensor(K.shape[-1], dtype=torch.float32))\n",
    "        attn_scale = attn_score / scale\n",
    "\n",
    "        # 마스킹 처리 (mask=1인 곳은 -1e9을 더해서 softmax 시 0에 가깝게)\n",
    "        attn_scale = attn_scale - (attn_mask * 1e9)\n",
    "\n",
    "        # softmax를 통해 attention 분포 계산\n",
    "        attn_prob = F.softmax(attn_scale, dim=-1)\n",
    "\n",
    "        # attention 분포 × V\n",
    "        attn_out = torch.matmul(attn_prob, V)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f250735b-1581-4a1a-88c8-19b519d0e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # 설정값\n",
    "        self.d_model = config.d_model   # 전체 hidden 차원\n",
    "        self.n_head  = config.n_head    # head 개수\n",
    "        self.d_head  = config.d_head    # head 당 차원 (d_model / n_head)\n",
    "\n",
    "        # Q, K, V projection\n",
    "        self.W_Q = nn.Linear(config.d_model, config.n_head * config.d_head)\n",
    "        self.W_K = nn.Linear(config.d_model, config.n_head * config.d_head)\n",
    "        self.W_V = nn.Linear(config.d_model, config.n_head * config.d_head)\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        self.attention = ScaleDotProductAttention()\n",
    "\n",
    "        # Output projection\n",
    "        self.W_O = nn.Linear(config.n_head * config.d_head, config.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        batch_size = Q.shape[0]\n",
    "\n",
    "        # (batch, seq_len, d_model) → (batch, n_head, seq_len, d_head)\n",
    "        Q_m = self.W_Q(Q).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        K_m = self.W_K(K).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        V_m = self.W_V(V).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "\n",
    "        # attn_mask: (batch, seq_len, seq_len) → (batch, n_head, seq_len, seq_len)\n",
    "        attn_mask_m = attn_mask.unsqueeze(1)\n",
    "\n",
    "        # Multi-Head Attention 수행\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)\n",
    "\n",
    "        # (batch, n_head, seq_len, d_head) → (batch, seq_len, n_head*d_head)\n",
    "        attn_out_m = attn_out.transpose(1, 2).contiguous()\n",
    "        attn_out   = attn_out_m.view(batch_size, -1, self.n_head * self.d_head)\n",
    "\n",
    "        # 최종 projection\n",
    "        attn_out = self.W_O(attn_out)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34207d18-5f0e-446b-a453-4c195c544a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        super().__init__()\n",
    "        # 첫 번째 선형 변환: d_model → d_ff (확장)\n",
    "        self.W_1 = nn.Linear(config.d_model, config.d_ff)\n",
    "        # 두 번째 선형 변환: d_ff → d_model (축소)\n",
    "        self.W_2 = nn.Linear(config.d_ff, config.d_model)\n",
    "        # 활성화 함수: GELU (BERT에서 사용)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [batch, seq_len, d_model]\n",
    "        Returns:\n",
    "            ff_val: [batch, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # FFN: Linear → GELU → Linear\n",
    "        ff_val = self.W_2(self.gelu(self.W_1(inputs)))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baa99651-effc-4c87-b247-10a88886cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        super().__init__()\n",
    "        # Self-Attention\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        # LayerNorm (Residual + Norm)\n",
    "        self.norm1 = nn.LayerNorm(config.d_model, eps=config.layernorm_epsilon)\n",
    "        # Feed Forward Network\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = nn.LayerNorm(config.d_model, eps=config.layernorm_epsilon)\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enc_embed: [batch, seq_len, d_model] 입력 임베딩\n",
    "            self_mask: [batch, seq_len, seq_len] self-attention 마스크\n",
    "        Returns:\n",
    "            enc_out: [batch, seq_len, d_model] 인코더 출력\n",
    "        \"\"\"\n",
    "        # 1. Self-Attention + Residual + Norm\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        # 2. Feed Forward + Residual + Norm\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a3a3607-ce39-4480-9f2c-ebd54f25ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERT, self).__init__()\n",
    "        self.i_pad = config.i_pad  # PAD 토큰 인덱스\n",
    "\n",
    "        # 임베딩 레이어\n",
    "        self.embedding = SharedEmbedding(config)       # 단어 임베딩 (입출력 공유)\n",
    "        self.position  = PositionEmbedding(config)     # 위치 임베딩\n",
    "        self.segment   = nn.Embedding(2, config.d_model)  # 세그먼트 임베딩 (A=0, B=1)\n",
    "        self.norm      = nn.LayerNorm(config.d_model, eps=config.layernorm_epsilon)\n",
    "\n",
    "        # 인코더 레이어 (n_layer만큼 반복)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(config, name=f\"encoder_layer_{i}\")\n",
    "            for i in range(config.n_layer)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, enc_tokens, segments):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enc_tokens: [batch, seq_len] 입력 토큰 ID\n",
    "            segments:   [batch, seq_len] 세그먼트 ID (0 or 1)\n",
    "        Returns:\n",
    "            logits_cls: [batch, d_model] NSP용 CLS 토큰 벡터\n",
    "            logits_lm:  [batch, seq_len, vocab] MLM 예측 로짓\n",
    "        \"\"\"\n",
    "        # 마스크 생성 (PAD 무시)\n",
    "        enc_self_mask = get_pad_mask(enc_tokens, self.i_pad)\n",
    "\n",
    "        # 임베딩 (단어 + 위치 + 세그먼트)\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "\n",
    "        # Transformer Encoder 반복 적용\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        # [CLS] 벡터 (문장 분류/NSP용)\n",
    "        logits_cls = enc_out[:, 0]\n",
    "\n",
    "        # MLM 예측 (임베딩 가중치 공유)\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "\n",
    "        return logits_cls, logits_lm\n",
    "\n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        단어 임베딩 + 위치 임베딩 + 세그먼트 임베딩\n",
    "        \"\"\"\n",
    "        embed = (\n",
    "            self.embedding(tokens)\n",
    "            + self.position(tokens)\n",
    "            + self.segment(segments)\n",
    "        )\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c47142e-7aa7-4a1d-8732-d37fddf77efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PooledOutput(nn.Module):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super(PooledOutput, self).__init__()\n",
    "        # [CLS] 벡터 → d_model\n",
    "        self.dense1 = nn.Linear(config.d_model, config.d_model)\n",
    "        # d_model → n_output (클래스 개수)\n",
    "        self.dense2 = nn.Linear(config.d_model, n_output, bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [batch, d_model] CLS 벡터\n",
    "        Returns:\n",
    "            outputs: [batch, n_output] softmax 확률\n",
    "        \"\"\"\n",
    "        # 1. tanh 활성화 (BERT pooler와 동일)\n",
    "        outputs = F.tanh(self.dense1(inputs))\n",
    "        # 2. 분류 헤드 (n_output 클래스)\n",
    "        outputs = self.dense2(outputs)\n",
    "        # 3. 소프트맥스 확률\n",
    "        outputs = F.softmax(outputs, dim=-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed9bac57-3538-4fd0-8870-478cdf4c3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(PreTrainModel, self).__init__()\n",
    "        # BERT 본체\n",
    "        self.bert = BERT(config)\n",
    "        # NSP용 [CLS] 분류 헤드\n",
    "        self.pooled_output = PooledOutput(config, 2)  # NSP → 2-class 분류\n",
    "\n",
    "    def forward(self, enc_tokens, segments):\n",
    "        # 입력은 LongTensor로 캐스팅\n",
    "        enc_tokens = enc_tokens.long()\n",
    "        segments   = segments.long()\n",
    "\n",
    "        # BERT 인코더 실행\n",
    "        logits_cls, logits_lm = self.bert(enc_tokens, segments)\n",
    "\n",
    "        # NSP (CLS 벡터 → 분류기)\n",
    "        logits_cls = self.pooled_output(logits_cls)\n",
    "        outputs_nsp = F.softmax(logits_cls, dim=-1)\n",
    "\n",
    "        # MLM (토큰별 단어 분포)\n",
    "        outputs_mlm = F.softmax(logits_lm, dim=-1)\n",
    "\n",
    "        return outputs_nsp, outputs_mlm\n",
    "\n",
    "\n",
    "def build_model_pre_train(config):\n",
    "    \"\"\"PreTrainModel을 생성하는 헬퍼 함수\"\"\"\n",
    "    return PreTrainModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "569cfb3e-71b5-4ffc-bec3-7d550520df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정 Config 클래스\n",
    "class Config:\n",
    "    def __init__(self, config_dict):\n",
    "        for key, value in config_dict.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "# 설정값 초기화\n",
    "config = Config({\n",
    "    \"d_model\": 64,              # hidden size\n",
    "    \"n_head\": 4,                # multi-head attention head 수\n",
    "    \"d_head\": 16,               # head 당 차원 (d_model / n_head)\n",
    "    \"dropout\": 0.1,             # dropout 비율\n",
    "    \"d_ff\": 256,                # FFN 내부 차원 (보통 4 * d_model)\n",
    "    \"layernorm_epsilon\": 0.001, # LayerNorm epsilon\n",
    "    \"n_layer\": 8,               # encoder layer 개수\n",
    "    \"n_seq\": 256,               # 최대 시퀀스 길이\n",
    "    \"n_vocab\": 8000,            # 단어 집합 크기\n",
    "    \"i_pad\": 0                  # PAD 토큰 인덱스\n",
    "})\n",
    "\n",
    "# Vocab 클래스 (간단 버전)\n",
    "class Vocab:\n",
    "    def __init__(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pad_id = 0  # [PAD]는 0번으로 고정\n",
    "\n",
    "# Vocab 객체 생성\n",
    "vocab = Vocab(config.n_vocab)\n",
    "\n",
    "# config와 vocab 연결\n",
    "config.n_vocab = vocab.vocab_size\n",
    "config.i_pad   = vocab.pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5d6d786-2bac-4981-a0b4-5fb091f767f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq = 10\n",
    "\n",
    "# 입력 토큰 ID (랜덤)\n",
    "enc_tokens = torch.randint(0, config.n_vocab, (10, n_seq))\n",
    "# 세그먼트 ID (0 또는 1)\n",
    "segments = torch.randint(0, 2, (10, n_seq))\n",
    "# NSP 라벨 (0 또는 1)\n",
    "labels_nsp = torch.randint(0, 2, (10,))\n",
    "# MLM 라벨 (정답 토큰 ID, 랜덤)\n",
    "labels_mlm = torch.randint(0, config.n_vocab, (10, n_seq))\n",
    "\n",
    "# DataLoader 준비\n",
    "batch_size = 5\n",
    "train_dataset = TensorDataset(enc_tokens, segments, labels_nsp, labels_mlm)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "968e119a-82f6-4348-be5f-540da3cf919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Loss: 9.685194969177246\n",
      "Epoch 2/2 - Loss: 9.656314849853516\n"
     ]
    }
   ],
   "source": [
    "model = build_model_pre_train(config)\n",
    "\n",
    "# 손실 함수 정의\n",
    "loss_fn_nsp = nn.CrossEntropyLoss()  # NSP (binary classification)\n",
    "loss_fn_mlm = nn.CrossEntropyLoss()  # MLM (multi-class classification)\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        enc_tokens_batch, segments_batch, labels_nsp_batch, labels_mlm_batch = batch\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 forward\n",
    "        logits_nsp, logits_mlm = model(enc_tokens_batch, segments_batch)\n",
    "\n",
    "        # NSP Loss\n",
    "        loss_nsp = loss_fn_nsp(logits_nsp, labels_nsp_batch)\n",
    "\n",
    "        # MLM Loss (flatten 해서 계산)\n",
    "        loss_mlm = loss_fn_mlm(\n",
    "            logits_mlm.view(-1, config.n_vocab),\n",
    "            labels_mlm_batch.view(-1)\n",
    "        )\n",
    "\n",
    "        # 총 Loss\n",
    "        total_loss_batch = loss_nsp + loss_mlm\n",
    "        total_loss += total_loss_batch.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        total_loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Epoch 결과 출력\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15dd4b-1a82-482e-9285-e14ce3df6860",
   "metadata": {},
   "source": [
    "##### pretrain 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebb742fa-9773-4eb5-aa50-7288be5baf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Masked Language Model (MLM) Loss\n",
    "    Args:\n",
    "        y_true: [batch, seq_len] (정답 토큰 ID, PAD=0)\n",
    "        y_pred: [batch, seq_len, vocab] (모델 출력 logits)\n",
    "\n",
    "    Returns:\n",
    "        loss: MLM loss (PAD 무시, 평균 후 스케일링)\n",
    "    \"\"\"\n",
    "    # CrossEntropyLoss (reduction='none' → 각 위치별 loss)\n",
    "    loss = F.cross_entropy(\n",
    "        y_pred.view(-1, y_pred.size(-1)),  # [batch*seq, vocab]\n",
    "        y_true.view(-1),                   # [batch*seq]\n",
    "        reduction='none'\n",
    "    )\n",
    "\n",
    "    # PAD 위치 무시 (정답이 0인 경우는 계산 제외)\n",
    "    mask = (y_true != 0).float().view(-1)\n",
    "    loss = loss * mask\n",
    "\n",
    "    # 평균 loss (PAD 제외된 위치만 평균)\n",
    "    loss = loss.sum() / mask.sum()\n",
    "\n",
    "    # 스케일링 (MLM의 비중을 크게 줌, 보통 20배)\n",
    "    return loss * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c6f2102-a5fe-4b6f-9a55-8bd411878465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Masked Language Model (MLM) Accuracy\n",
    "    Args:\n",
    "        y_true: [batch, seq_len] (정답 토큰 ID, PAD=0)\n",
    "        y_pred: [batch, seq_len, vocab] (모델 출력 logits)\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): MLM 예측 정확도 (PAD 무시)\n",
    "    \"\"\"\n",
    "    # 모델 예측 클래스 (argmax)\n",
    "    y_pred_class = torch.argmax(y_pred, dim=-1).float()\n",
    "\n",
    "    # 정답과 비교\n",
    "    matches = (y_true == y_pred_class).float()\n",
    "\n",
    "    # PAD 토큰 무시\n",
    "    mask = (y_true != 0).float()\n",
    "    matches *= mask\n",
    "\n",
    "    # 정확도 계산 (PAD 제외)\n",
    "    accuracy = matches.sum() / mask.sum().clamp(min=1)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2000a94-c292-4e4e-af42-e31701b3db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule:\n",
    "    def __init__(self, optimizer=None, train_steps=4000, warmup_steps=500, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer (torch.optim.Optimizer): 옵티마이저\n",
    "            train_steps (int): 전체 학습 step 수\n",
    "            warmup_steps (int): 학습 초반 warmup step 수\n",
    "            max_lr (float): 최대 학습률\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.train_steps = train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.step_num = 0\n",
    "\n",
    "    def get_lr(self):\n",
    "        # Warmup 단계\n",
    "        if self.step_num <= self.warmup_steps:\n",
    "            lr = (self.step_num / self.warmup_steps) * self.max_lr\n",
    "        else:\n",
    "            # Cosine Decay 단계\n",
    "            progress = (self.step_num - self.warmup_steps) / max(1, self.train_steps - self.warmup_steps)\n",
    "            lr = 0.5 * self.max_lr * (1 + math.cos(math.pi * progress))\n",
    "        return lr\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        step_num을 증가시키고, 옵티마이저의 learning rate를 업데이트\n",
    "        \"\"\"\n",
    "        self.step_num += 1\n",
    "        lr = self.get_lr()\n",
    "\n",
    "        # 옵티마이저 learning rate 갱신\n",
    "        if self.optimizer is not None:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aee6ddbc-5956-477e-9c7e-9c43c11cb2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAHFCAYAAAAqg1fhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdJJJREFUeJzt3Xl4TNcfBvB3ksxkF1nIYklijdiTWEKtbRNbUUWoqlaraNVSWlsVLaK6L5ZWU7RVlKBULaESW+yhiFoTsSQilsSa9fz+uL8ZRhYzkcmd5f08zzy5uXPm3u+dwbzuPedchRBCgIiIiIjKnJXcBRARERGZKwYtIiIiIgNh0CIiIiIyEAYtIiIiIgNh0CIiIiIyEAYtIiIiIgNh0CIiIiIyEAYtIiIiIgNh0CIiIiIyEAYtojKwePFiKBQKHDx4UO5S9Na+fXu0b99etn0rFArNw87ODoGBgZgxYwZycnJKtc3ExERMmzYNycnJZVssgIsXL+Ltt99GnTp1YG9vDzc3NzRs2BBDhgzBxYsX9drWtGnToFAokJGRUeZ1Pu5pPuPXXnsNfn5+ZVoPAHz88ccIDAxEQUGB1vqsrCzMnDkTISEhqFChAmxtbeHn54fBgwfj8OHDZV4H8PCzMKSbN2+iYsWKWLt2rUH3Q8bHRu4CiEhe8+bNk3X/NWrUwNKlSwEA165dw08//YQpU6YgJSUFP/74o97bS0xMxPTp09G+ffsyDQiXLl1CUFAQKlasiLFjx6Ju3brIzMxEYmIi/vjjD5w/fx7VqlUrs/2ZsytXrmDOnDlYvHgxrKwe/n//3LlzCAsLQ3p6OoYNG4bp06fDyckJycnJ+OOPPxAcHIxbt27BxcWlTOt588030alTpzLd5uNcXV0xZswYvP/+++jSpQtUKpVB90fGg0GLyIwIIfDgwQPY29vr/JrAwEADVvRk9vb2aNmypeb3zp07IzAwEEuWLMG3334LOzs7Gat7aOHChcjIyMD+/fvh7++vWd+zZ09MmjSp0JkZKt4333yDihUrolevXpp1+fn5ePHFF5GRkYH4+Hg0aNBA81y7du0waNAgbNy4EUqlsszrqVq1KqpWrVrm233csGHDMGPGDKxatQovv/yywfdHxoGXDonK0ZkzZ/Dyyy+jcuXKsLW1Rb169TB37lytNg8ePMDYsWPRpEkTuLi4wM3NDaGhofjzzz8LbU+hUGDEiBFYsGAB6tWrB1tbWyxZskRzKXP79u0YPnw4PDw84O7ujl69euHKlSta23j8slJycjIUCgU+//xzfPnll/D394eTkxNCQ0Oxd+/eQjUsXLgQderUga2tLQIDA/H7778/1eUmGxsbNGnSBDk5Obh165Zm/cGDB9GvXz/4+fnB3t4efn5+6N+/Py5cuKBps3jxYvTp0wcA0KFDB80lycWLF2vabN26Fc8++ywqVKgABwcHtG7dGtu2bXtiXdevX4eVlRUqV65c5POPnpkBgH379uGFF16Au7s77OzsULNmTYwePbrQ665evYr+/fvDxcUFnp6eGDx4MDIzM7XaCCEwb948NGnSBPb29nB1dUXv3r1x/vz5Qu3mzJkDX19f2NnZISgoCBs3biy0T/Wfj8cvr8bGxkKhUCA2NrbE90LXeoqSk5ODqKgovPzyy1rv2dq1a3Hs2DFMnDhRK2Q9qnPnznBwcND8vmvXLjz77LNwdnaGg4MDWrVqhQ0bNmi95t69exg3bhz8/f1hZ2cHNzc3hISEYNmyZZo2RV069PPzQ7du3bBp0yYEBQXB3t4eAQEB+PnnnwvVlZaWhqFDh6Jq1apQqVTw9/fH9OnTkZeXp9XO09MTzz//PBYsWPDE94nMB4MWUTlJTExEs2bNcPz4cXzxxRf466+/0LVrV4wcORLTp0/XtMvOzsaNGzcwbtw4rF27FsuWLcMzzzyDXr164Zdffim03bVr12L+/Pn46KOPsHnzZrRp00bz3JtvvgmlUonff/8dc+bMQWxsLF555RWd6p07dy5iYmLw9ddfY+nSpbh79y66dOmiFQJ+/PFHvPXWW2jUqBFWr16NDz/8ENOnT3/iF/WTJCUloWLFiqhUqZJmXXJyMurWrYuvv/4amzdvxqefforU1FQ0a9ZM08+pa9eumDVrlqb++Ph4xMfHo2vXrgCA3377DWFhYahQoQKWLFmCP/74A25ubggPD39i2AoNDUVBQQF69eqFzZs3Iysrq9i26s8hJSUFX375JTZu3IgPP/wQV69eLdT2pZdeQp06dRAdHY0JEybg999/x5gxY7TaDB06FKNHj8Zzzz2HtWvXYt68eThx4gRatWqltc3p06dj/PjxeP7557F27VoMHz4cQ4YMwalTp57wjutH13qKsm/fPly/fh0dOnTQWr9lyxYA0hlCXcTFxaFjx47IzMxEVFQUli1bBmdnZ7zwwgtYsWKFpt17772H+fPnY+TIkdi0aRN+/fVX9OnTB9evX3/iPo4ePYqxY8dizJgx+PPPP9GoUSO88cYb2LFjh6ZNWloamjdvjs2bN+Ojjz7Cxo0b8cYbbyAyMhJDhgwptM327dtj9+7dWv+JIDMniOipLVq0SAAQBw4cKLZNeHi4qFq1qsjMzNRaP2LECGFnZydu3LhR5Ovy8vJEbm6ueOONN0TTpk21ngMgXFxcCr1WXc/bb7+ttX7OnDkCgEhNTdWsa9eunWjXrp3m96SkJAFANGzYUOTl5WnW79+/XwAQy5YtE0IIkZ+fL7y8vESLFi209nHhwgWhVCqFr69vse/Fo/uuX7++yM3NFbm5uSI1NVV89NFHAoBYsGBBia/Ny8sTd+7cEY6OjuKbb77RrF+5cqUAILZv367V/u7du8LNzU288MILWuvz8/NF48aNRfPmzUvcX0FBgRg6dKiwsrISAIRCoRD16tUTY8aMEUlJSVpta9asKWrWrCnu379f7PamTp0qAIg5c+ZorX/77beFnZ2dKCgoEEIIER8fLwCIL774QqvdxYsXhb29vfjggw+EEELcvHlT2NnZiRdffFGr3e7duwUArc9Y/efj8bq3b99e6L0bNGiQ1mepaz3F+fTTTwUAkZaWprW+U6dOAoB48OBBia9Xa9mypahcubK4ffu2Zl1eXp5o0KCBqFq1qub9a9CggejZs2eJ21J/Fo/y9fUVdnZ24sKFC5p19+/fF25ubmLo0KGadUOHDhVOTk5a7YQQ4vPPPxcAxIkTJ7TWx8TECABi48aNOh0nmT6e0SIqBw8ePMC2bdvw4osvwsHBAXl5eZpHly5d8ODBA63LcitXrkTr1q3h5OQEGxsbKJVKREVF4eTJk4W23bFjR7i6uha53+7du2v93qhRIwDQutxWnK5du8La2rrY1546dQppaWno27ev1uuqV6+O1q1bP3H7aidOnIBSqYRSqYS3tzc+/vhjTJw4EUOHDtVqd+fOHYwfPx61atWCjY0NbGxs4OTkhLt37xb5vjxuz549uHHjBgYNGqT1/hcUFKBTp044cOAA7t69W+zrFQoFFixYgPPnz2PevHl4/fXXkZubi6+++gr169dHXFwcAOD06dM4d+4c3njjDZ36lxX1GT148ADp6ekAgL/++gsKhQKvvPKKVt1eXl5o3Lix5uxhfHw8Hjx4gAEDBmhtr1WrVvD19X1iHbrStZ7iXLlyBQqFAh4eHqWu4e7du9i3bx969+4NJycnzXpra2sMHDgQly5d0pzFa968OTZu3IgJEyYgNjYW9+/f13k/TZo0QfXq1TW/29nZoU6dOlp/f/766y906NABPj4+Wu9H586dAUDz50JNfen58uXL+h84mSR2hicqB9evX0deXh6+++47fPfdd0W2UV/+Wr16Nfr27Ys+ffrg/fffh5eXF2xsbDB//vwi+4d4e3sXu193d3et321tbQFApy+bJ71WfenF09Oz0Gs9PT2RlJT0xH0AQM2aNbF8+XIIIXDhwgXMmDEDkZGRaNSoEfr166dp9/LLL2Pbtm2YMmUKmjVrhgoVKkChUKBLly46HY/6klbv3r2LbXPjxg04OjqWuB1fX18MHz5c8/sff/yB/v374/3338f+/ftx7do1ANC5c/WT3uerV69CCFHk+wxIozaBh5+Hl5dXoTZFrSstXespzv3796FUKrVCPABNoElKSkJAQECJ27h58yaEEEX+2ffx8QHw8P349ttvUbVqVaxYsQKffvop7OzsEB4ejs8++wy1a9cucT+PfzaA9Pk8+uft6tWrWL9+fbGd9B+fvkMdvvUJfGTaGLSIyoGrq6vmf9vvvPNOkW3UI9l+++03+Pv7Y8WKFVoddLOzs4t8naHn/ymO+kuoqD45aWlpOm/Hzs4OISEhAIBmzZqhQ4cOqF+/PkaPHo1u3brByckJmZmZ+OuvvzB16lRMmDBB81p1fzZdqM+gfPfdd1qjHB9VXHgoSd++fREZGYnjx48DgKZf2aVLl/TeVlE8PDygUCiwc+dOTQh7lHqd+vMo6r1PS0vTGpyg/rJ//M+ULnN66VpPSa/PycnB3bt3tUJteHg4fvzxR6xdu1brMy6Kq6srrKyskJqaWug59WAP9eft6OiI6dOnY/r06bh69arm7NYLL7yA//7774nH+yQeHh5o1KgRZs6cWeTz6uCnpv7z+jRn9Mi08NIhUTlwcHBAhw4dkJCQgEaNGiEkJKTQQ/1FqVAooFKptAJUWlpakaMO5VS3bl14eXnhjz/+0FqfkpKCPXv2lHq77u7umD17Nq5evao5+6dQKCCEKPQl/tNPPyE/P19rXXFn7Vq3bo2KFSsiMTGxyPc/JCSkxLmNivpSB6RLmhcvXtR8odapUwc1a9bEzz//XGw41ke3bt0ghMDly5eLrLlhw4YAgJYtW8LOzk4zJ5nanj17Cl0qVoeuf//9V2v9unXryqye4qjPVp07d05rfY8ePdCwYUOt0Pq4zZs34969e3B0dESLFi2wevVqrc+5oKAAv/32G6pWrYo6deoUer2npydee+019O/fH6dOncK9e/eeeLxP0q1bNxw/fhw1a9Ys8v14PGipR2bKPa0KlR+e0SIqQ//880+RM5J36dIF33zzDZ555hm0adMGw4cPh5+fH27fvo2zZ89i/fr1+OeffwBI/3CvXr0ab7/9Nnr37o2LFy/ik08+gbe3N86cOVPOR1Q8KysrTJ8+HUOHDkXv3r0xePBg3Lp1C9OnT4e3t3eh6Q708eqrr+LLL7/E559/jnfeeQcVKlRA27Zt8dlnn8HDwwN+fn6Ii4tDVFQUKlasqPVa9dQAP/74I5ydnWFnZwd/f3+4u7vju+++w6BBg3Djxg307t0blStXxrVr13D06FFcu3YN8+fPL7ammTNnYvfu3YiIiNBMa5CUlITvv/8e169fx2effaZpO3fuXLzwwgto2bIlxowZg+rVqyMlJQWbN28uFISepHXr1njrrbfw+uuv4+DBg2jbti0cHR2RmpqKXbt2oWHDhhg+fDhcXV0xbtw4zJgxA2+++Sb69OmDixcvYtq0aYUuHTZr1gx169bFuHHjkJeXB1dXV6xZswa7du0qs3qKo55KZO/evZp+f4DUv2rNmjUICwtDaGgohg8fjg4dOsDR0REXLlzAqlWrsH79ety8eRMAEBkZieeffx4dOnTAuHHjoFKpMG/ePBw/fhzLli3T/EelRYsW6NatGxo1agRXV1ecPHkSv/76K0JDQ7Wmiiitjz/+GDExMWjVqhVGjhyJunXr4sGDB0hOTsbff/+NBQsWaF1G3rt3L9zd3Z8YSMmMyNgRn8hsqEdxFfdQj+5KSkoSgwcPFlWqVBFKpVJUqlRJtGrVSsyYMUNre7NnzxZ+fn7C1tZW1KtXTyxcuLDIkVEAxDvvvFNsPY+PgixqVFlxow4/++yzQtsFIKZOnaq17scffxS1atUSKpVK1KlTR/z888+iR48ehUZIFkU96rAoGzZsEADE9OnThRBCXLp0Sbz00kvC1dVVODs7i06dOonjx48LX19fMWjQIK3Xfv3118Lf319YW1sLAGLRokWa5+Li4kTXrl2Fm5ubUCqVokqVKqJr165i5cqVJda6d+9e8c4774jGjRsLNzc3YW1tLSpVqiQ6deok/v7770Lt4+PjRefOnYWLi4uwtbUVNWvWFGPGjNE8r/48r127pvW64kYE/vzzz6JFixbC0dFR2Nvbi5o1a4pXX31VHDx4UNOmoKBAREZGimrVqgmVSiUaNWok1q9fX+gzFkKI06dPi7CwMFGhQgVRqVIl8e6772re85JGHepTT3HatGkjunTpUuRzt27dEp988okICgoSTk5OQqlUiurVq4tXXnlF7N69W6vtzp07RceOHTU1tGzZUqxfv16rzYQJE0RISIhwdXUVtra2okaNGmLMmDEiIyND06a4UYddu3YtVF9R7+W1a9fEyJEjhb+/v1AqlcLNzU0EBweLyZMnizt37mjaFRQUCF9fX/Huu+8+8T0i86EQQohyznZEZMZu3bqFOnXqoGfPnqW6hQ6Zv+joaERERODChQuoUqWK3OWUm23btiEsLAwnTpx4Yod/Mh8MWkRUamlpaZg5cyY6dOgAd3d3XLhwAV999RX+++8/HDx4EPXr15e7RDJCQgi0atUKwcHB+P777+Uup9x06NABtWrVwsKFC+UuhcoR+2gRUanZ2toiOTkZb7/9Nm7cuAEHBwe0bNkSCxYsYMiiYikUCixcuBDr1q1DQUHBU/XnMxU3b95Eu3bt8Pbbb8tdCpUzntEiIiIiMhDz/28EERERkUwYtIiIiIgMhEGLiIiIyEDYGV5mBQUFuHLlCpydnWW7lQoRERHpRwiB27dvw8fHp8QBHQxaMrty5QqqVasmdxlERERUChcvXizxJvIMWjJzdnYGIH1QFSpUkLkaIiIi0kVWVhaqVaum+R4vDoOWzNSXCytUqMCgRUREZGKe1O2HneGJiIiIDIRBi4iIiMhAGLSIiIiIDIR9tIiIyKLk5+cjNzdX7jLIyCmVSlhbWz/1dhi0iIjIIgghkJaWhlu3bsldCpmIihUrwsvL66nmuWTQIiIii6AOWZUrV4aDgwMniaZiCSFw7949pKenAwC8vb1LvS0GLSIiMnv5+fmakOXu7i53OWQC7O3tAQDp6emoXLlyqS8jsjM8ERGZPXWfLAcHB5krIVOi/vPyNH36GLSIiMhi8HIh6aMs/rwwaBEREREZiOxBa968efD394ednR2Cg4Oxc+fOEtvHxcUhODgYdnZ2qFGjBhYsWFCoTXR0NAIDA2Fra4vAwECsWbNGr/3m5uZi/PjxaNiwIRwdHeHj44NXX30VV65c0dpG+/btoVAotB79+vUr5TtBRERUWPv27TF69Gi5y8C0adPQpEkTucswObIGrRUrVmD06NGYPHkyEhIS0KZNG3Tu3BkpKSlFtk9KSkKXLl3Qpk0bJCQkYNKkSRg5ciSio6M1beLj4xEREYGBAwfi6NGjGDhwIPr27Yt9+/bpvN979+7h8OHDmDJlCg4fPozVq1fj9OnT6N69e6GahgwZgtTUVM3jhx9+KON3iYiISH7jxo3Dtm3b5C5DJ6+99hp69uwpdxkAAIUQQsi18xYtWiAoKAjz58/XrKtXrx569uyJyMjIQu3Hjx+PdevW4eTJk5p1w4YNw9GjRxEfHw8AiIiIQFZWFjZu3Khp06lTJ7i6umLZsmWl2i8AHDhwAM2bN8eFCxdQvXp1ANL/Mpo0aYKvv/661O9BVlYWXFxckJmZyZtK6+v2bemhUgG2ttJPlQpgHwwiesyDBw+QlJSkuZJhSsriu6YkOTk5UKlUBtl2WcvNzYVSqXxiu9deew23bt3C2rVrn2p/Jf250fX7W7YzWjk5OTh06BDCwsK01oeFhWHPnj1FviY+Pr5Q+/DwcBw8eFAzIqC4Nuptlma/AJCZmQmFQoGKFStqrV+6dCk8PDxQv359jBs3Drdv3y7+oAFkZ2cjKytL60GlcPw44OEBVKkCVKoEVKgA2NkB1taAuztQpw4QGgp06wa8+SbwySfAr78CO3YAKSlAQYHcR0BEpLecnBx88MEHqFKlChwdHdGiRQvExsZqnr9+/Tr69++PqlWrwsHBAQ0bNtScZFBr3749RowYgffeew8eHh54/vnnERsbC4VCgW3btiEkJAQODg5o1aoVTp06pXnd45cO1WeNPv/8c3h7e8Pd3R3vvPOO1gi91NRUdO3aFfb29vD398fvv/8OPz8/nUOjQqHAggUL0KNHDzg6OmLGjBnIz8/HG2+8AX9/f9jb26Nu3br45ptvtOpcsmQJ/vzzT023HvV7dPnyZURERMDV1RXu7u7o0aMHkpOTdX7/S0O2ebQyMjKQn58PT09PrfWenp5IS0sr8jVpaWlFts/Ly0NGRga8vb2LbaPeZmn2++DBA0yYMAEvv/yyVmodMGAA/P394eXlhePHj2PixIk4evQoYmJiij3uyMhITJ8+vdjnSUcxMUBOTuH1QgA3bkiPM2eKf72jI1C/PtCggfRo1Aho1kwKbERk/oQA7t2TZ98ODqU+8/76668jOTkZy5cvh4+PD9asWYNOnTrh2LFjqF27Nh48eIDg4GCMHz8eFSpUwIYNGzBw4EDUqFEDLVq00GxnyZIlGD58OHbv3q2ZMR8AJk+ejC+++AKVKlXCsGHDMHjwYOzevbvYerZv3w5vb29s374dZ8+eRUREBJo0aYIhQ4YAAF599VVkZGQgNjYWSqUS7733nmYSUF1NnToVkZGR+Oqrr2BtbY2CggJUrVoVf/zxBzw8PLBnzx689dZb8Pb2Rt++fTFu3DicPHkSWVlZWLRoEQDAzc0N9+7dQ4cOHdCmTRvs2LEDNjY2mDFjBjp16oR///3XYGf1ZJ+w9PGhk0KIEodTFtX+8fW6bFPX/ebm5qJfv34oKCjAvHnztJ5T/0ECgAYNGqB27doICQnB4cOHERQUVGT9EydOxHvvvaf5PSsrC9WqVSuyLZXgxAnp50cfAVOnSqErO1v6h/PGDeD6delnRgZw5QqQnAxcuPDwcfcusH+/9FBTKKTw1bKldDasTRugVi1eiiQyR/fuAU5O8uz7zh3pP3t6OnfuHJYtW4ZLly7Bx8cHgNRvatOmTVi0aBFmzZqFKlWqYNy4cZrXvPvuu9i0aRNWrlypFbRq1aqFOXPmaH5XB62ZM2eiXbt2AIAJEyaga9euePDgQbGXW11dXfH999/D2toaAQEB6Nq1K7Zt24YhQ4bgv//+w9atW3HgwAGEhIQAAH766SfUrl1br+N++eWXMXjwYK11j56w8Pf3x549e/DHH3+gb9++cHJygr29PbKzs+Hl5aVp99tvv8HKygo//fST5vt+0aJFqFixImJjYwtd6SorsgUtDw8PWFtbFzqLlJ6eXuhsk5qXl1eR7W1sbDQz/RbXRr1Nffabm5uLvn37IikpCf/8888T+1AFBQVBqVTizJkzxQYtW1tb2Nralrgd0oE6aNWvD1hZSZcN7ewAFxfgSbdKyM0Fzp6VLj8ePy5t69AhKYyp1/30k9TW1xd4/nnp8eyz0mVJIiIZHD58GEII1KlTR2t9dna25jswPz8fs2fPxooVK3D58mVkZ2cjOzsbjo8FO3XweVyjRo00y+rbzqSnp2v6Jj+ufv36WjOme3t749ixYwCAU6dOwcbGRuv7sFatWnB1ddX1kIutdcGCBfjpp59w4cIF3L9/Hzk5OU8cEXno0CGcPXsWzs7OWusfPHiAc+fO6VWTPmQLWiqVCsHBwYiJicGLL76oWR8TE4MePXoU+ZrQ0FCsX79ea92WLVsQEhKi6RwXGhqKmJgYjBkzRqtNq1at9NqvOmSdOXMG27dv1+mWDSdOnEBubu5T3ROJdCAEkJgoLdevr//rlUqgXj3p0afPw/VpacC+fUB8PLBnD7B3r3T266efpIdCAbRuDbz4ovTw9y+b4yGi8ufgIJ1ZkmvfpVBQUABra2scOnSo0O1gnP5/du6LL77AV199ha+//lozRdHo0aOR81hXi8eDl9qjHc3VZ30KSujT+njHdIVCoWlf3Fg7fcfgPV7rH3/8gTFjxuCLL75AaGgonJ2d8dlnn2nNLlCUgoICBAcHY+nSpYWeq1Spkl416UPWS4fvvfceBg4ciJCQEISGhuLHH39ESkoKhg0bBkC6zHb58mX88ssvAKQRht9//z3ee+89DBkyBPHx8YiKitLq6Ddq1Ci0bdsWn376KXr06IE///wTW7duxa5du3Teb15eHnr37o3Dhw/jr7/+Qn5+vuYMmJubG1QqFc6dO4elS5eiS5cu8PDwQGJiIsaOHYumTZuidevW5fUWWqZLl4CsLMDGBtDzFHSJvLyAHj2kByD9I7xjh9QfLCZGOvO1a5f0GDsWaNoU6NULePlloEaNsquDiAxPoSjV5Ts5NW3aFPn5+UhPT0ebNm2KbLNz50706NEDr7zyCgApXJw5cwb16tUrz1IBAAEBAcjLy0NCQgKCg4MBAGfPnsWtW7eears7d+5Eq1at8Pbbb2vWPX5GSqVSIT8/X2tdUFAQVqxYgcqVK5frKH9Z59GKiIjA119/jY8//hhNmjTBjh078Pfff8PX1xeANFrh0Tm1/P398ffffyM2NhZNmjTBJ598gm+//RYvvfSSpk2rVq2wfPlyLFq0CI0aNcLixYuxYsUKrWvTT9rvpUuXsG7dOly6dAlNmjSBt7e35qEemahSqbBt2zaEh4ejbt26GDlyJMLCwrB169ZS33iSdKS+bFinjjSdg6E4OQFdugBffSVdTkxJAb79FmjfXrpcmZAATJkC1KwJtG0rnfXKzDRcPURk0erUqYMBAwbg1VdfxerVq5GUlIQDBw7g008/xd9//w1AujQXExODPXv24OTJkxg6dGixA70MLSAgAM899xzeeust7N+/HwkJCXjrrbdgb2//VLe2qVWrFg4ePIjNmzfj9OnTmDJlCg4cOKDVxs/PD//++y9OnTqFjIwM5ObmYsCAAfDw8ECPHj2wc+dOJCUlIS4uDqNGjcKlS5ee9nCLJXtn+LffflsrlT5q8eLFhda1a9cOhw8fLnGbvXv3Ru/evUu9Xz8/vyee2qxWrRri4uJKbEMG8mj/rPJUrRrw7rvSIyMDWLcOWLFCOtu1c6f0GDFCOss1fDjwzDPsSE9EZWrRokWYMWMGxo4di8uXL8Pd3R2hoaHo0qULAGDKlClISkpCeHg4HBwc8NZbb6Fnz57IlOk/gb/88gveeOMNtG3bFl5eXoiMjMSJEyeeai6zYcOG4ciRI4iIiIBCoUD//v3x9ttva82fOWTIEMTGxiIkJAR37tzB9u3b0b59e+zYsQPjx49Hr169cPv2bVSpUgXPPvusQc9wyTphKXHC0lIZPBhYtAiYNk0acSi3y5eBpUuBJUse9h0DgIYNgbffBl55Rb7RTUQEwLQnLDUnly5dQrVq1bB161Y8++yzcpfzRCY9YSlRqcl1Rqs4VaoAH3wgXV48eFCaINXeHjh2TDqz5eMDjB4tdawnIrIg//zzD9atW4ekpCTs2bMH/fr1g5+fH9q2bSt3aeWGQYtMy9OOODQkhQIIDgYWLpTm7vrqK6mz/u3bwDffSH25Xn1VCmRERBYgNzcXkyZNQv369fHiiy+iUqVKmslLly5dCicnpyIf9Y3t3/enwEuHMuOlQz1duAD4+UlTNNy9K/00ZgUFUh+uzz4DHr0Za9euwKRJwP+nHSEiw+KlQ+Nz+/ZtXL16tcjnlEqlZoCanMri0qHsneGJ9KK+bFi3rvGHLEAanRgeLj0OHgTmzAFWrQI2bJAenTpJ92EsZvJAIiJz5ezsXGjyUHPES4dkWoytf5Y+QkKAP/4ATp+W+nHZ2ACbNkn3WHzxRalPFxERmRUGLTItphy01GrVkvpx/fef1GfLygpYuxZo3FgaofjI3HFEVLZKmuWc6HFl8eeFlw7JtJhD0FKrWVOaEmLCBGmqij/+kKaJiI6WZp4fPx6wgNPqROVBpVLBysoKV65cQaVKlaBSqZ5q0kwyb0II5OTk4Nq1a7CysoLqKSbHZmd4mbEzvB4KCqTgce+edDaobl25Kypbhw8D770HqCfC9fQEZswAXn8d4N0GiJ5aTk4OUlNTce/ePblLIRPh4OAAb2/vIoOWrt/fDFoyY9DSQ3KydCNnlUoacWhjhidkhZBmnB83Djh7VlrXpAkwfz7QsqWspRGZAyEE8vLyCt0Hj+hx1tbWsLGxKfbMJ0cdkvl5dMShOYYsQJqLq0cPoHNnYN48YPp04MgRaRqIIUOAyEjAzU3uKolMlkKhgFKphNIURi2TWWBneDId5tQ/60lUKmk2+dOngddek850/fijFDIXL5Z+JyIio8egRabDkoKWWqVK0n0dd+yQjjsjQ+qz1b49cOaM3NUREdETMGiR6bDEoKXWpg2QkCBNeOrgIAWvRo2AL78E2NeEiMhoMWiRaSgoAE6elJYtMWgB0kz4778v3evxueeABw+kaSDatJFGYRIRkdFh0CLTkJwsTetgayvNP2XJfH2BLVukSU+dnYH4eGlk4pw5PLtFRGRkGLTINKgvGwYEcE4pQBqd+OabwPHj0n0Us7OlCU7bt5duvE1EREaBQYtMgyX3zypJ9erAxo1AVJR0dmvXLqnv1rJlcldGRERg0CJTwaBVPIUCGDxYmm8rNBTIygJeflm6b2JmptzVERFZNAYtMg0MWk9Wo4Y0GnHaNOlG1UuXSjeq3r1b7sqIiCwWgxYZv/x8jjjUlY0NMHUqsHOndLuiCxeAdu2Azz/nJKdERDJg0CLjl5QkTWVgZyeFB3qyVq2kS4n9+0tB9f33gZ49gZs35a6MiMiiMGiR8VNfNqxXjyMO9VGhgnT5cP586ZY+69YBQUHAwYNyV0ZEZDEYtMj4sX9W6SkUwLBh0lxbNWpI85G1bi3dsJqXEomIDI5Bi4wfg9bTCwoCDh0CXnwRyMkB3nkHGDQIuH9f7sqIiMwagxYZPwatslGxIhAdLd0f0doa+PVXoG1b4NIluSsjIjJbDFpk3PLzH97Hj0Hr6SkUwJgx0i183N2l/lohIZwCgojIQBi0yLidOyfdXsbBAfDzk7sa89GxI3DggDSL/NWrQIcOwI8/yl0VEZHZYdAi4/boiEMr/nEtU/7+wJ49QJ8+QG4uMHQoMHy4tExERGWC31xk3Ng/y7AcHYEVK4BZs6TLigsWAF26ALduyV0ZEZFZYNAi46YOWoGB8tZhzhQKYOJE4M8/peC1das0BURystyVERGZPAYtMm6JidJPntEyvBdekG7d4+Mjve8tWgD79sldFRGRSWPQIuOVl8cRh+WtaVMpXDVpAqSnA+3bS1NCEBFRqTBokfE6d06aXNPBAfD1lbsay1G1qnRmq2tX6R6TvXsDc+ZwJnkiolJg0CLj9Wj/LI44LF9OTlKfrXfflX4fPx4YNQooKJC3LiIiE8NvLzJeHHEoL2tr4Ntvga++kn7/7jugf39pXjMiItIJgxYZLwYt4zB6NLBsGaBUAn/8IU3/kJUld1VERCaBQYuMF4OW8ejXD/j7b+mS4j//SJ3kr16VuyoiIqPHoEXGKTcXOHVKWmbQMg7PPQfExgKVKgEJCdJcW+fOyV0VEZFRY9Ai43T2rBS2nJyA6tXlrobUgoOlG1D7+0shq1Ur4OhRuasiIjJaDFpknB4dcahQyFsLaatdW7pH4qNzbXFiUyKiIjFokXFi/yzj5uUFbN8undG6dUu6rLhjh9xVEREZHQYtMk4MWsavYkVg82agY0fgzh2gUyfpdyIi0mDQIuPEoGUanJyADRukWeTv35ful7hmjdxVEREZDQYtMj45OcDp09Iyg5bxs7MDVq8G+vSRBjD06QMsXSp3VURERoFBi4zPmTPSDaUrVJDuu0fGT6WSJjV97TUgPx8YOBCIipK7KiIi2TFokfHhiEPTZG0that33pFuQP3mmwxbRGTxGLTI+LB/lumyspLuiThypPQ7wxYRWTgGLTI+DFqmTaEAvv6aYYuICAxaZIwYtEwfwxYREQAGLTI22dlSZ3iAQcvUMWwRETFokZE5fVoatVahAuDjI3c19LQYtojIwjFokXF59LIhRxyah6LC1pIlspZERFReGLTIuCQmSj952dC8qMPWu+9Kvw8eDKxaJWtJRETlgUGLjAs7wpsvddh64w2goADo31+6fQ8RkRlj0CLjwqBl3qysgB9+kEJWXh7w0kvAP//IXRURkcHIHrTmzZsHf39/2NnZITg4GDt37iyxfVxcHIKDg2FnZ4caNWpgwYIFhdpER0cjMDAQtra2CAwMxJoibnJb0n5zc3Mxfvx4NGzYEI6OjvDx8cGrr76KK1euaG0jOzsb7777Ljw8PODo6Iju3bvj0qVLpXwnCNnZwNmz0jKDlvmytpb6aPXoIX3m3bsDe/bIXRURkUHIGrRWrFiB0aNHY/LkyUhISECbNm3QuXNnpKSkFNk+KSkJXbp0QZs2bZCQkIBJkyZh5MiRiI6O1rSJj49HREQEBg4ciKNHj2LgwIHo27cv9u3bp/N+7927h8OHD2PKlCk4fPgwVq9ejdOnT6N79+5a9YwePRpr1qzB8uXLsWvXLty5cwfdunVDfn6+Ad4tC3DqlDTisGJFwNtb7mrIkJRKYMUKICwMuHsX6NwZOHxY7qqIiMqekFHz5s3FsGHDtNYFBASICRMmFNn+gw8+EAEBAVrrhg4dKlq2bKn5vW/fvqJTp05abcLDw0W/fv1KvV8hhNi/f78AIC5cuCCEEOLWrVtCqVSK5cuXa9pcvnxZWFlZiU2bNhW7ncdlZmYKACIzM1Pn15it338XAhCidWu5K6HycveuEG3bSp+7u7sQx47JXRERkU50/f6W7YxWTk4ODh06hLCwMK31YWFh2FPMZYT4+PhC7cPDw3Hw4EHk5uaW2Ea9zdLsFwAyMzOhUChQsWJFAMChQ4eQm5urtR0fHx80aNCgxO1kZ2cjKytL60H/x/5ZlsfBAfjrL6B5c+D6deD554Hz5+WuioiozMgWtDIyMpCfnw9PT0+t9Z6enkhLSyvyNWlpaUW2z8vLQ0ZGRolt1NsszX4fPHiACRMm4OWXX0aFChU0+1GpVHB1ddV5OwAQGRkJFxcXzaNatWrFtrU4DFqWydkZ2LQJaNQISEuTwlYJf4eIiEyJ7J3hFY9NSimEKLTuSe0fX6/LNnXdb25uLvr164eCggLMmzevhCPRrf6JEyciMzNT87h48eITt2kxGLQsl6srsHkzUKOGdEarUycgM1PuqoiInppsQcvDwwPW1taFzv6kp6cXOtuk5uXlVWR7GxsbuLu7l9hGvU199pubm4u+ffsiKSkJMTExmrNZ6v3k5OTg5s2bOtcPALa2tqhQoYLWgwA8eACcOyctM2hZJi8vYMsWwNMTOHpUGo14/77cVRERPRXZgpZKpUJwcDBiYmK01sfExKBVq1ZFviY0NLRQ+y1btiAkJARKpbLENupt6rpfdcg6c+YMtm7dqglyasHBwVAqlVrbSU1NxfHjx4utn0rw33/SJJZubtIXLVmmmjWly4gVKgA7djycb4uIyFQZvl9+8ZYvXy6USqWIiooSiYmJYvTo0cLR0VEkJycLIYSYMGGCGDhwoKb9+fPnhYODgxgzZoxITEwUUVFRQqlUilWrVmna7N69W1hbW4vZs2eLkydPitmzZwsbGxuxd+9enfebm5srunfvLqpWrSqOHDkiUlNTNY/s7GzNdoYNGyaqVq0qtm7dKg4fPiw6duwoGjduLPLy8nR+Dzjq8P9++00aedamjdyVkDGIixPC1lb6MzF4sBAFBXJXRESkRdfvb1mDlhBCzJ07V/j6+gqVSiWCgoJEXFyc5rlBgwaJdu3aabWPjY0VTZs2FSqVSvj5+Yn58+cX2ubKlStF3bp1hVKpFAEBASI6Olqv/SYlJQkART62b9+uaXf//n0xYsQI4ebmJuzt7UW3bt1ESkqKXsfPoPV/EydKX6qPTbtBFmztWiGsrKQ/Fx98IHc1RERadP3+Vgjx/97kJIusrCy4uLggMzPTsvtr9egBrFsHfPcdMGKE3NWQsVi0SLoBNQB89hkwbpy89RAR/Z+u39+yjzokAsARh1S0118HPv1UWn7/feC33+Sth4hITwxaJL979x5OUsmgRY/74ANg7FhpefBgYNs2eeshItIDgxbJ77//ACEADw+gcmW5qyFjNGcOEBEB5OYCvXoBx47JXRERkU4YtEh+vGxIT2JlBSxZArRtC2RlSTehvnRJ7qqIiJ6IQYvkx6BFurC1BdauBerVAy5flsIWZ48nIiPHoEXyUwetwEB56yDj5+oKbNwozSJ//Lh0GTEnR+6qiIiKxaBF8uMZLdKHry/w99+AkxPwzz/AG29IffyIiIwQgxbJ6+5dIClJWmbQIl01bQqsWgVYW0tTPnz4odwVEREViUGL5PXff9LPSpWkB5GuwsOBhQul5VmzgAUL5K2HiKgIDFokL142pKfx+uvAtGnS8ogR0g2piYiMCIMWyYtBi57WRx8Br70G5OcDfftKneSJiIwEgxbJi0GLnpZCAfzwA9CuHXD7NtCtG3D1qtxVEREBYNAiuTFoUVlQqYDoaKB2beDCBekm5ffvy10VERGDFsnozh0gOVlaZtCip+XuDmzYIM21tW+f1H+roEDuqojIwjFokXxOnpR+enpKX5JET6t2bWDNGkCpBFasAKZOlbsiIrJwDFokH142JENo1w748UdpecYM4Jdf5K2HiCwagxbJh0GLDOW114AJE6TlN98Edu6UtRwislwMWiQfBi0ypJkzgZdeAnJzgRdfBM6elbsiIrJADFokHwYtMiQrK+myYbNmwPXr0rQPt27JXRURWRgGLZLH7dtASoq0zKBFhuLgAPz5J1CtGnDqFNCvnzSxKRFROWHQInkkJko/vb2l4fhEhuLtLYUtBwdg82bggw/kroiILAiDFsmDlw2pPDVtCixeLC1/+eXDZSIiA2PQInkwaFF569NHui8iAAwdCsTHy1sPEVkEBi2SB4MWyWHqVGkEYk6O9PPSJbkrIiIzx6BF8mDQIjmoRyI2bCjdeLpHD+DePbmrIiIzxqBF5S8z8+GZhMBAeWshy+PkBKxbB3h4AIcPA4MHA0LIXRURmSkGLSp/6hGHPj5AxYqylkIWys8PWLUKsLGR7okYGSl3RURkphi0qPzxsiEZg3btgLlzpeXJk6UpIIiIyhiDFpU/Bi0yFm+9BbzzjrT8yivAsWPy1kNEZodBi8ofgxYZk6++Ajp0AO7ckTrH37ghd0VEZEYYtKj8qftoMWiRMVAqgZUrAX9/ICkJ6N+ft+khojLDoEXl69Yt4PJlaZkjDslYuLsDa9YA9vbAli3Ahx/KXRERmQkGLSpf6rNZVasCLi7y1kL0qMaNgZ9/lpZnz5bOchERPSUGLSpf7J9FxqxfP2DcOGn59deB48flrYeITB6DFpUvBi0ydpGRwLPPAnfvAj17Ajdvyl0REZkwBi0qXwxaZOxsbIDlywFfX+DcOWDAAHaOJ6JSY9Ci8sWgRabAw0PqHG9nB2zcKN2MmoioFBi0qPzcvAmkpkrLHHFIxq5pU2DhQml55kxg9Wp56yEik8SgReVHfTarenXA2VneWoh08corwOjR0vKgQQ9HzRIR6YhBi8oPLxuSKZozB2jfXpo5vmdPIDNT7oqIyIQwaFH5YdAiU6RUAn/8AVSrBpw5I53lKiiQuyoiMhEMWlR+GLTIVFWqJHWOt7UF/voL+OQTuSsiIhPBoEXlh0GLTFlwMPDDD9Ly9OnApk3y1kNEJoFBi8rH9evA1avScr168tZCVFqDBgFDhwJCSPNrJSfLXRERGTkGLSof6rNZfn6Ak5OspRA9lW++AZo1A27cAHr3Bh48kLsiIjJiDFpUPnjZkMyFrS2wahXg7g4cOgSMHCl3RURkxBi0qHyogxYnKiVzUL068PvvgEIhTWq6aJHcFRGRkSp10MrJycGpU6eQl5dXlvWQueIZLTI3YWFSp3gAePttICFB3nqIyCjpHbTu3buHN954Aw4ODqhfvz5SUlIAACNHjsTs2bPLvEAyEwxaZI4mTwa6dpX6ab30knSbKSKiR+gdtCZOnIijR48iNjYWdnZ2mvXPPfccVqxYUabFkZm4dk16ABxxSObFygr49VfA3x9ISgIGDuRkpkSkRe+gtXbtWnz//fd45plnoFAoNOsDAwNx7ty5Mi2OzIT6bJa/P+DoKG8tRGXN1RWIjpY6yW/YAMyaJXdFRGRE9A5a165dQ+XKlQutv3v3rlbwItLgZUMyd02bAvPmScsffQTExMhbDxEZDb2DVrNmzbBhwwbN7+pwtXDhQoSGhpZdZWQ+EhOlnwxaZM4GDwbefFOazLR/f+D//VeJyLLZ6PuCyMhIdOrUCYmJicjLy8M333yDEydOID4+HnFxcYaokUwdz2iRpfjuO2n04aFD0mSmO3dKlxSJyGLpfUarVatW2L17N+7du4eaNWtiy5Yt8PT0RHx8PIKDgw1RI5k6Bi2yFHZ20mSmrq7AgQPA6NFyV0REMlMIIYTcRViyrKwsuLi4IDMzExUqVJC7nLKXng54ekoTO965Azg4yF0RkeFt3ChN+yAE8Msv0mhEIjIrun5/631Gy9raGunp6YXWX79+HdbW1vpuDvPmzYO/vz/s7OwQHByMnTt3ltg+Li4OwcHBsLOzQ40aNbBgwYJCbaKjoxEYGAhbW1sEBgZizZo1eu939erVCA8Ph4eHBxQKBY4cOVJoG+3bt4dCodB69OvXT783wNypz2bVqMGQRZajc2epUzwADBv28O8BEVkcvYNWcSfAsrOzoVKp9NrWihUrMHr0aEyePBkJCQlo06YNOnfurJkE9XFJSUno0qUL2rRpg4SEBEyaNAkjR45EdHS0pk18fDwiIiIwcOBAHD16FAMHDkTfvn2xb98+vfZ79+5dtG7d+omTsA4ZMgSpqamaxw8//KDXe2D2eNmQLNWUKcBzzwH37gF9+khndInI4uh86fDbb78FAIwZMwaffPIJnJycNM/l5+djx44dSE5ORoIet6Fo0aIFgoKCMH/+fM26evXqoWfPnoiMjCzUfvz48Vi3bh1OnjypWTds2DAcPXoU8fHxAICIiAhkZWVh48aNmjadOnWCq6srli1bpvd+k5OT4e/vj4SEBDRp0kTrufbt26NJkyb4+uuvdT7mx5n9pcPhw4EFC4CJEzm/EFme9HRp6ocrV4ABA6TJTTkNDpFZ0PX7W+dRh1999RUA6YzWggULtC4TqlQq+Pn5FXkZrzg5OTk4dOgQJkyYoLU+LCwMe/bsKfI18fHxCAsL01oXHh6OqKgo5ObmQqlUIj4+HmPGjCnURh2GSrPfkixduhS//fYbPD090blzZ0ydOhXOzs7Fts/OzkZ2drbm96ysLL33aVJ4RossWeXKwPLlQIcOwNKlQNu2wFtvyV0VEZUjnYNWUlISAKBDhw5YvXo1XF1dn2rHGRkZyM/Ph6enp9Z6T09PpKWlFfmatLS0Itvn5eUhIyMD3t7exbZRb7M0+y3OgAED4O/vDy8vLxw/flxze6KYEiYrjIyMxHT1jWjNnRAMWkRt2khnc8ePB0aOBEJCgKAguasionKi9zxa27dvL9MCHp9NXghR4gzzRbV/fL0u29R3v0UZMmSIZrlBgwaoXbs2QkJCcPjwYQQV8w/pxIkT8d5772l+z8rKQrVq1fTar8m4ehW4cUO6H1xAgNzVEMln3Dhg1y5g/Xqpv9bhw4CLi9xVEVE50DtoAcClS5ewbt06pKSkICcnR+u5L7/8UqdteHh4wNrautBZpPT09EJnm9S8vLyKbG9jYwN3d/cS26i3WZr96iooKAhKpRJnzpwpNmjZ2trC1lImMFSfzapZU5pfiMhSWVkBixdLZ7LOn5dmkV+1iv21iCyA3qMOt23bhrp162LevHn44osvsH37dixatAg///xzkVMgFEelUiE4OLjQZbaYmBi0atWqyNeEhoYWar9lyxaEhIRAqVSW2Ea9zdLsV1cnTpxAbm4uvL29n2o7ZoOXDYkecnMDVq4ElEpg9Wrgm2/kroiIyoPQU7NmzcSUKVOEEEI4OTmJc+fOidu3b4vu3buLefPm6bWt5cuXC6VSKaKiokRiYqIYPXq0cHR0FMnJyUIIISZMmCAGDhyoaX/+/Hnh4OAgxowZIxITE0VUVJRQKpVi1apVmja7d+8W1tbWYvbs2eLkyZNi9uzZwsbGRuzdu1fn/QohxPXr10VCQoLYsGGDACCWL18uEhISRGpqqhBCiLNnz4rp06eLAwcOiKSkJLFhwwYREBAgmjZtKvLy8nR+DzIzMwUAkZmZqdd7ZxLeeksIQIjJk+WuhMh4fPed9PfCxkaI+Hi5qyGiUtL1+1vvoOXk5CTOnj0rhBCiYsWK4vjx40IIIY4cOSJ8fX31LnTu3LnC19dXqFQqERQUJOLi4jTPDRo0SLRr106rfWxsrGjatKlQqVTCz89PzJ8/v9A2V65cKerWrSuUSqUICAgQ0dHReu1XCCEWLVokABR6TJ06VQghREpKimjbtq1wc3MTKpVK1KxZU4wcOVJcv35dr+M366DVurX0hfL773JXQmQ8CgqE6NNH+rtRrZoQGRlyV0REpaDr97fet+Dx8vLCP//8g8DAQNSvXx+RkZHo3r07jh49itatW+MOJ+XTi9nOoyWEdKnk1i3g6FGgUSO5KyIyHllZ0ujDM2ekWeT/+kvqx0VEJsNgt+Bp2bIldu/eDQDo2rUrxo4di5kzZ2Lw4MFo2bJl6Ssm85KaKoUsKyugTh25qyEyLhUqSJ3h7eyk+yI+4Q4URGS69A5aX375JVq0aAEAmDZtGp5//nmsWLECvr6+iIqKKvMCyUSpO8LXqsURh0RFadQImDtXWp4yBYiNlbUcIjIMvad3qFGjhmbZwcEB8+bNK9OCyExwxCHRk73+OrBjB7BkCdC/P5CQAHh5yV0VEZWhMusUsHr1ajRiPxxSY9AiejKFApg3D2jQAEhLA15+GcjPl7sqIipDegWthQsXok+fPnj55Zexb98+AMA///yDpk2b4pVXXkFoaKhBiiQTxKBFpBsHB2l+LScnYPt2YNo0uSsiojKkc9D6/PPP8c477yApKQl//vknOnbsiFmzZqFv377o2bMnUlJS8MMPPxiyVjIVvMchkX4CAoAff5SWZ8wANm2Stx4iKjM6B62oqCgsWLAABw8exIYNG3D//n38888/OHv2LKZOnQoPDw9D1kmm5PJlafi6tTVHHBLpqn9/YPhwafmVV4BLl+Sth4jKhM5B68KFC3juuecAAO3bt4dSqcTMmTNRsWJFQ9VGpioxUfpZuzZgKfd1JCoLX34p3Q/x+nUpeOXlyV0RET0lnYPWgwcPYPfIMH2VSoVKlSoZpCgycbxsSFQ6dnbAH39I82zt2gV89JHcFRHRU9JreoeffvoJTk5OAIC8vDwsXry40CXDkSNHll11ZJoYtIhKr2ZN4KefgL59gchIoG1boFMnuasiolLS+RY8fn5+UCgUJW9MocD58+fLpDBLYZa34AkNBfbuBVaskL4siEh/77wjTf3g4SHNr1W1qtwVEdEjdP3+1vmMVnJyclnUReZOiId9tHhGi6j0vvgCiI+XQlb//tLUDzZ6zzFNRDLjXUypbF26JI04tLGROsMTUemo+2s5O7O/FpEJY9CisqXun1WnDqBSyVsLkamrVUvqrwVI/bU2b5a3HiLSG4MWlS12hCcqW337as+vdfmyvPUQkV4YtKhsMWgRlb0vvwSaNAEyMji/FpGJYdCissWgRVT2Hu2vtXMnMHWq3BURkY70DlpZWVlFPm7fvo2cnBxD1EimgiMOiQyndm1g4UJpedYs9tciMhF6B62KFSvC1dW10KNixYqwt7eHr68vpk6dioKCAkPUS8YsJQW4cwdQKqVOvERUtiIi2F+LyMToPSnL4sWLMXnyZLz22mto3rw5hBA4cOAAlixZgg8//BDXrl3D559/DltbW0yaNMkQNZOxUl82rFtXCltEVPa+/FKaX+vIEeDll4Ft2zi/FpER0/tv55IlS/DFF1+g7yMzfnfv3h0NGzbEDz/8gG3btqF69eqYOXMmg5alYf8sIsNT99cKCgJ27ACmTQNmzJC7KiIqht6XDuPj49G0adNC65s2bYr4+HgAwDPPPIOUlJSnr45MizpoBQbKWweRuWN/LSKToXfQqlq1KqKiogqtj4qKQrVq1QAA169fh6ur69NXR6aFZ7SIyk+/fsCwYdIglIEDgStX5K6IiIqg96XDzz//HH369MHGjRvRrFkzKBQKHDhwAP/99x9WrVoFADhw4AAiIiLKvFgyYgUFHHFIVN6++krqr3X0qNRfa+tW9tciMjIKIYTQ90XJyclYsGABTp8+DSEEAgICMHToUPj5+RmgRPOm692/jV5SElCjhnTbnbt3+Y89UXk5c0bqr3XnDvDhh8Ann8hdEZFF0PX7u1RBi8qO2QStv/4CXngBaNgQ+PdfuashsizLlklntBQKYNMmICxM7oqIzJ6u39+lOu1w69Yt7N+/H+np6YXmy3r11VdLs0kydeyfRSSf/v2BuDjghx+k+bWOHAF8fOSuiohQiqC1fv16DBgwAHfv3oWzszMUCoXmOYVCwaBlqRi0iOT11VfA3r3sr0VkZPQedTh27FgMHjwYt2/fxq1bt3Dz5k3N48aNG4aokUwBgxaRvOztpfm1nJyks1sffyx3RUSEUgSty5cvY+TIkXBwcDBEPWSKCgqAkyelZQYtIvnUqQP8+KO0PGMGEBMjbz1EpH/QCg8Px8GDBw1RC5mq5GTg/n3A1haoWVPuaogsW//+wFtvSfNrDRjA+bWIZKb3BfyuXbvi/fffR2JiIho2bAjlY/e06969e5kVRyZCfdkwIACwtpa3FiICvv5a6q/177/sr0UkM73/5g0ZMgQA8HER1/8VCgXy8/OfvioyLeyfRWRc1P21QkIe9tdiny0iWeh96bCgoKDYB0OWhWLQIjI+detq99faulXeeogslN5Bi6gQBi0i49S/PzBkyMP+WqmpcldEZHF0unT47bff4q233oKdnR2+/fbbEtuOHDmyTAojE5GfzxGHRMbsm2+k/lrHjj3sr8W+lETlRqdb8Pj7++PgwYNwd3eHv79/8RtTKHD+/PkyLdDcmfwteM6eBWrXBuzspHut8R9wIuNz6hQQHCzdh/Sjj4Dp0+WuiMjklekteJKSkopcJtJcNqxXjyGLyFjVrfvw9jyffAK0aQM895zcVRFZBPbRoqfD/llEpmHAgIf9tV55BUhLk7siIoug9/QO+fn5WLx4MbZt21bkTaX/+eefMiuOTACDFpHpeLy/VkwMz0QTGZjeQWvUqFFYvHgxunbtigYNGmjdVJosEIMWkel4dH6t7dulubXYX4vIoHTqDP8oDw8P/PLLL+jSpYuharIoJt0ZPj8fcHQEsrOBc+eAGjXkroiIdLF0qXT5UKEANm8Gnn9e7oqITI6u399699FSqVSoVavWUxVHZuLcOSlk2dsDfn5yV0NEunq0v9aAAcDly3JXRGS29A5aY8eOxTfffAM9T4SROXp0xKEVx1UQmZRvvgEaNwauXZMmNs3Lk7siIrOkdx+tXbt2Yfv27di4cSPq169f6KbSq1evLrPiyMixfxaR6bK3B1aulObX2rkTmDIFiIyUuyois6N30KpYsSJefPFFQ9RCpoZBi8i01a4NREUBffsCs2cDzzwDdO0qd1VEZkWvoJWXl4f27dsjPDwcXl5ehqqJTAWDFpHp69MHGDEC+P574NVXgYQEoHp1uasiMht6dayxsbHB8OHDkZ2dbah6yFTk5Um39QAYtIhM3eefS1M+3LgBREQAOTlyV0RkNvTuwdyiRQskJCQYohYyJWfPSv8YOzgAvr5yV0NET8PWVppfq2JFaULTCRPkrojIbOjdR+vtt9/G2LFjcenSJQQHB8PR0VHr+UaNGpVZcWTE1JcNAwM54pDIHPj7A4sXAz17Al99Jd0Pkf1xiZ6a3kErIiICADBy5EjNOoVCASEEFAoF8vPzy646Ml7sn0Vkfnr0AMaOBb74Anj9dWn6B05ETPRU9A5aSUlJhqiDTE1iovSTQYvIvERGAnv2APHxUkf53bsBOzu5qyIyWXoHLV/2xyGAZ7SIzJVSCaxYATRtChw+LJ3hmjtX7qqITJbeQUstMTERKSkpyHlsdEr37t2fuigycrm5HHFIZM6qVQN+/RXo0gWYNw9o21YajUhEetM7aJ0/fx4vvvgijh07pumbBUj9tACwj5YlOHtWCltOTpxvh8hcde4MTJoEzJoFvPmmdIarTh25qyIyOXoPFxs1ahT8/f1x9epVODg44MSJE9ixYwdCQkIQGxtrgBLJ6Dw64vD/AZuIzND06UC7dsCdO0Dv3sD9+3JXRGRy9A5a8fHx+Pjjj1GpUiVYWVnBysoKzzzzDCIjI7VGIupq3rx58Pf3h52dHYKDg7Fz584S28fFxSE4OBh2dnaoUaMGFixYUKhNdHQ0AgMDYWtri8DAQKxZs0bv/a5evRrh4eHw8PCAQqHAkSNHCm0jOzsb7777Ljw8PODo6Iju3bvj0qVL+r0Bpoj9s4gsg40NsGwZULkycOwY8O67cldEZHL0Dlr5+flwcnICAHh4eODKlSsApE7yp9T9dnS0YsUKjB49GpMnT0ZCQgLatGmDzp07IyUlpcj2SUlJ6NKlC9q0aYOEhARMmjQJI0eORHR0tKZNfHw8IiIiMHDgQBw9ehQDBw5E3759sW/fPr32e/fuXbRu3RqzZ88utv7Ro0djzZo1WL58OXbt2oU7d+6gW7du5n/5lEGLyHJ4ewO//y6dvY6KAn75Re6KiEyL0NMzzzwj1qxZI4QQon///qJTp05i165d4tVXXxX169fXa1vNmzcXw4YN01oXEBAgJkyYUGT7Dz74QAQEBGitGzp0qGjZsqXm9759+4pOnTpptQkPDxf9+vUr1X6TkpIEAJGQkKC1/tatW0KpVIrly5dr1l2+fFlYWVmJTZs2FVl/UTIzMwUAkZmZqfNrZBcYKAQgxMaNcldCROVl+nTp772DgxDHj8tdDZHsdP3+1vuM1ocffoiCggIAwIwZM3DhwgW0adMGf//9N7799ludt5OTk4NDhw4hLCxMa31YWBj27NlT5Gvi4+MLtQ8PD8fBgweRm5tbYhv1Nkuz36IcOnQIubm5Wtvx8fFBgwYN9NqOycnJAU6flpZ5RovIckyeDDz/PHDvnjS/1p07cldEZBL0HnUYHh6uWa5RowYSExNx48YNuLq6akYe6iIjIwP5+fnw9PTUWu/p6Ym0tLQiX5OWllZk+7y8PGRkZMDb27vYNuptlma/xdWiUqng6uqq13ays7O1bsqdlZWl8z6Nwpkz0g2lK1QAqlaVuxoiKi/W1sBvv0mjD0+eBIYPly4jckAMUYlKfZO6s2fPYvPmzbh//z7c3NxKXcDj4Uz8/1Y++rR/fL0u29R3v7p60nYiIyPh4uKieVSrVu2p91muOOKQyHJVrix1jleHrqgouSsiMnp6B63r16/j2WefRZ06ddClSxekpqYCAN58802MHTtW5+14eHjA2tq60Nmf9PT0Qmeb1Ly8vIpsb2NjA3d39xLbqLdZmv0WV0tOTg5u3ryp13YmTpyIzMxMzePixYs679MosCM8kWVr2xaYOVNaHjECSEiQtx4iI6d30BozZgyUSiVSUlLg4OCgWR8REYFNmzbpvB2VSoXg4GDExMRorY+JiUGrVq2KfE1oaGih9lu2bEFISAiUSmWJbdTbLM1+ixIcHAylUqm1ndTUVBw/frzE7dja2qJChQpaD5Py6BktIrJM778PdO0KZGcDL70EPPYfTiJ6hL697D09PcWRI0eEEEI4OTmJc+fOCSGEOH/+vHB0dNRrW8uXLxdKpVJERUWJxMREMXr0aOHo6CiSk5OFEEJMmDBBDBw4UNP+/PnzwsHBQYwZM0YkJiaKqKgooVQqxapVqzRtdu/eLaytrcXs2bPFyZMnxezZs4WNjY3Yu3evzvsVQojr16+LhIQEsWHDBgFALF++XCQkJIjU1FRNm2HDhomqVauKrVu3isOHD4uOHTuKxo0bi7y8PJ3fA5MbdRgQII080mNkJRGZoRs3hPDzk/496NZNiPx8uSsiKle6fn/rHbScnJzE6dOnNcvqoLV//37h5uamd6Fz584Vvr6+QqVSiaCgIBEXF6d5btCgQaJdu3Za7WNjY0XTpk2FSqUSfn5+Yv78+YW2uXLlSlG3bl2hVCpFQECAiI6O1mu/QgixaNEiAaDQY+rUqZo29+/fFyNGjBBubm7C3t5edOvWTaSkpOh1/CYVtB48EMLaWvqH9eJFuashIrkdOiSEra30b8LMmXJXQ1SudP3+Vgjx/97kOuratSuCgoLwySefwNnZGf/++y98fX3Rr18/FBQUYNWqVWV7ys3MZWVlwcXFBZmZmcZ/GfHYMaBRI2nE4a1b7AxPRMDPPwNvvAFYWQGbNwPPPSd3RUTlQtfvb72nd/jss8/Qvn17HDx4EDk5Ofjggw9w4sQJ3LhxA7t3736qosnIPdoRniGLiABg8GBgzx5pBGL//sDhw4CpjaYmMiC9O8MHBgbi33//RfPmzfH888/j7t276NWrFxISElCzZk1D1EjGgiMOiago330nza+VkSFNZpqTI3dFREZD7zNagDS1wfTp07XWXbx4EYMHD8bPP/9cJoWREWLQIqKi2NsDq1YBwcHAvn3A2LFS+CKi0k9Y+rgbN25gyZIlZbU5MkYMWkRUnBo1pElMAeD776UbURNR2QUtMnMPHgBnz0rLDFpEVJSuXYEPP5SWhwwBjh+Xtx4iI8CgRbo5dQooKAAqVgS8veWuhoiM1bRpD28+/dJLgKndz5WojDFokW4SE6WfHHFIRCWxtpYuG1arBpw+LY1K1G8WISKzonNn+F69epX4/K1bt562FjJm7J9FRLry8ABWrgTatAGio4GvvgLee0/uqohkoXPQcnFxeeLzr7766lMXREaKQYuI9NGiBfD118A77wAffACEhEg3pCayMDoHrUWLFhmyDjJ2DFpEpK/hw4H4eGk0YkSENJkp+3iShWEfLXqyBw+Ac+ekZQYtItKVQgEsWAA0aACkpUlhKzdX7qqIyhWDFj3Zf/9JIw7d3ABPT7mrISJT4ugo9dOqUAHYuRMYN07uiojKFYMWPRnvcUhET6NOHeDXX6Xlb78FfvlF3nqIyhGDFj0Z+2cR0dPq3h2YOlVaHjoUOHRI3nqIygmDFj0ZgxYRlYWPPgK6dZP6ffbqBVy7JndFRAbHoEVPxqBFRGXBykq6hFi7NpCSAvTrB+TlyV0VkUExaFHJ7t0Dzp+Xlhm0iOhpVawIrF0LODkB//wDTJggd0VEBsWgRSX77z/p9hnu7kClSnJXQ0TmIDAQWLJEWv7iC2DZMnnrITIgBi0qGUccEpEh9OoFTJokLb/xBnD0qLz1EBkIgxaVjP2ziMhQPv4YCA8H7t8HXnwRuH5d7oqIyhyDFpWMQYuIDMXaGvj9d6BGDSApCejfH8jPl7sqojLFoEUlY9AiIkNycwPWrAEcHICYGGDyZLkrIipTDFpUvLt3pf9lAgxaRGQ4jRoBP/8sLX/6KbBypbz1EJUhBi0q3smT0s9KlTjikIgMKyICeP99afn114F//5W3HqIywqBFxeNlQyIqT7NmAc89J51N796dM8eTWWDQouIxaBFRebKxAVasAGrVAi5cAHr3BnJy5K6K6KkwaFHxGLSIqLy5uQHr1gHOzsCOHcC770qTJhOZKAYtKh6DFhHJoV49abZ4hQL48Udg/ny5KyIqNQYtKtqdO9Kpe4BBi4jKX9euwOzZ0vLIkdJ9EYlMEIMWFU094tDTU7rPIRFReXv/feCVV6RJTPv0Ac6dk7siIr0xaFHReNmQiOSmUAALFwLNmwM3bkgjEbOy5K6KSC8MWlQ0Bi0iMgZ2dtLM8d7eQGKidIaroEDuqoh0xqBFRWPQIiJj4eMDrF0L2NoC69cDU6bIXRGRzhi0qGgMWkRkTJo3B6KipOVZs6RRiUQmgEGLCrt9G0hJkZYZtIjIWAwYAIwfLy0PHgzs2ydvPUQ6YNCiwhITpZ/e3oCrq7y1EBE9auZMoFs34MEDoEePh9PQEBkpBi0qjJcNichYWVsDv/8ONG4MXL0qhS6ORCQjxqBFhTFoEZExc3aWOsV7ewPHjwP9+gF5eXJXRVQkBi0qTB20AgPlrYOIqDjVqkn3RLS3BzZuBMaMkbsioiIxaFFhPKNFRKYgJAT47Tdp+fvvge++k7ceoiIwaJG2zEzg0iVpmUGLiIxdr17Ap59Ky6NHA3//LWs5RI9j0CJt6hGHPj5AxYqylkJEpJP33wfeeEOaMT4iAvj3X7krItJg0CJtvGxIRKZGoQDmzQM6dADu3JFGIqalyV0VEQAGLXocgxYRmSKVCoiOBurWBS5elG5Afe+e3FURMWjRYxi0iMhUuboCf/0FuLsDBw5IM8nn58tdFVk4Bi3SxqBFRKasVq2HN6BeuxYYNQoQQu6qyIIxaNFDt24BV65Iy5xDi4hM1TPPSNM+KBTA3LnA55/LXRFZMAYtekh9NqtqVcDFRd5aiIieRu/ewJdfSssffAAsWyZvPWSxGLToIV42JCJzMnq09ACAQYOA7dvlrIYsFIMWPcSgRUTm5osvpLNbubnAiy9K90YkKkcMWvSQerJSBi0iMhdWVsCvv0r9tjIzgc6dgcuX5a6KLAiDFj3EM1pEZI7s7IA//wQCAqRbjHXpIoUuonLAoEWSmzeB1FRpmSMOicjcuLkBGzcCXl7SLXpeegnIyZG7KrIADFokUZ/Nql4dcHaWtxYiIkPw8wM2bAAcHYFt24BXX+WEpmRwDFok4WVDIrIEQUHA6tWAUgmsWAGMHMkJTcmgGLRIwqBFRJYiLAz45ZeHN6OePl3uisiMyR605s2bB39/f9jZ2SE4OBg7d+4ssX1cXByCg4NhZ2eHGjVqYMGCBYXaREdHIzAwELa2tggMDMSaNWv03q8QAtOmTYOPjw/s7e3Rvn17nFCHkf9r3749FAqF1qNfv36leBeMAIMWEVmSfv2A77+XlqdPf7hMVNaEjJYvXy6USqVYuHChSExMFKNGjRKOjo7iwoULRbY/f/68cHBwEKNGjRKJiYli4cKFQqlUilWrVmna7NmzR1hbW4tZs2aJkydPilmzZgkbGxuxd+9evfY7e/Zs4ezsLKKjo8WxY8dERESE8Pb2FllZWZo27dq1E0OGDBGpqamax61bt/R6DzIzMwUAkZmZqdfrypynpxCAEPv3y1sHEVF5mjZN+rcPEOL33+WuhkyIrt/fsgat5s2bi2HDhmmtCwgIEBMmTCiy/QcffCACAgK01g0dOlS0bNlS83vfvn1Fp06dtNqEh4eLfv366bzfgoIC4eXlJWbPnq15/sGDB8LFxUUsWLBAs65du3Zi1KhROhxp8YwiaGVkPPyH5vZt+eogIipvBQVCjBgh/ftnYyPExo1yV0QmQtfvb9kuHebk5ODQoUMICwvTWh8WFoY9e/YU+Zr4+PhC7cPDw3Hw4EHk5uaW2Ea9TV32m5SUhLS0NK02tra2aNeuXaHali5dCg8PD9SvXx/jxo3D7du3dX0LjIf6sqGvL+DkJG8tRETlSaEAvvkG6N8fyMuTpn2Ij5e7KjIjNnLtOCMjA/n5+fD09NRa7+npibS0tCJfk5aWVmT7vLw8ZGRkwNvbu9g26m3qsl/1z6LaXLhwQfP7gAED4O/vDy8vLxw/fhwTJ07E0aNHERMTU+xxZ2dnIzs7W/N7VlZWsW3LDftnEZEls7ICFi8GbtwANm8GunYFdu7kv4lUJmQLWmoKhULrdyFEoXVPav/4el22WRZthgwZollu0KABateujZCQEBw+fBhBQUFF1h8ZGYnpxjbChUGLiCydSgVERwPPPQfs3Sv93LEDqF1b7srIxMl26dDDwwPW1taFzl6lp6cXOpOk5uXlVWR7GxsbuLu7l9hGvU1d9uvl5QUAetUGAEFBQVAqlThz5kyxbSZOnIjMzEzN4+LFi8W2LTcMWkRE0kSmGzYAjRoBaWnAs88Cj1zFICoN2YKWSqVCcHBwoctsMTExaNWqVZGvCQ0NLdR+y5YtCAkJgVKpLLGNepu67Fd9OfDRNjk5OYiLiyu2NgA4ceIEcnNz4e3tXWwbW1tbVKhQQeshOwYtIiKJmxsQEwPUrQtcvAh07MibUNPTMXy//OKpp1mIiooSiYmJYvTo0cLR0VEkJycLIYSYMGGCGDhwoKa9enqHMWPGiMTERBEVFVVoeofdu3cLa2trMXv2bHHy5Ekxe/bsYqd3KG6/QkjTO7i4uIjVq1eLY8eOif79+2tN73D27Fkxffp0ceDAAZGUlCQ2bNggAgICRNOmTUVeXp7O74Hsow7T0x+OOLxzR54aiIiMzaVLQtSoIf3bGBAgxNWrcldERsYkpncQQoi5c+cKX19foVKpRFBQkIiLi9M8N2jQINGuXTut9rGxsaJp06ZCpVIJPz8/MX/+/ELbXLlypahbt65QKpUiICBAREdH67VfIaQpHqZOnSq8vLyEra2taNu2rTh27Jjm+ZSUFNG2bVvh5uYmVCqVqFmzphg5cqS4fv26Xscve9Davl36h8TfX579ExEZq6QkIapWlf6NbNRICD3/fSfzpuv3t0II3uRJTllZWXBxcUFmZqY8lxHnzgVGjAC6dQPWry///RMRGbPTp4G2bYGrV4FmzYCtWwFj6PJBstP1+1v2W/CQzNg/i4ioeHXqSOHK3R04cECa+uHuXbmrIhPCoGXpGLSIiErWoAGwZQvg4gLs2iVdAWDYIh0xaFkyIRi0iIh0ERQEbNwIODsDsbEMW6QzBi1Llp4OXL8u3YIiIEDuaoiIjFtoqDRzvDps8TIi6YBBy5Kpz2bVqAE4OMhbCxGRKQgNlS4jVqgAxMUBXboAd+7IXRUZMQYtS5aYKP3kZUMiIt21bPkwbO3YwbBFJWLQsmTsn0VEVDotWkgzyLu4SDeg7twZuH1b7qrICDFoWTIGLSKi0mve/GHY2rWLYYuKxKBlqTjikIjo6TVr9jBs7d4NPPcccOOG3FWREWHQslRXr0r/GFhZccQhEdHTaNYM2LZNmtR0/36gXTsgLU3uqshIMGhZKvXZrJo1ATs7eWshIjJ1wcHSKERvb+D4cem2PSkpcldFRoBBy1LxsiERUdmqX1/qGO/nB5w5AzzzjPSTLBqDlqVi0CIiKns1a0phq25d4OJFoE0b4NgxuasiGTFoWSp10AoMlLcOIiJzU7WqNL9W48ZSf9h27aS+W2SRGLQsEUccEhEZVuXKwPbt0kzyN28CHToAmzbJXRXJgEHLEqWmArduSSMO69aVuxoiIvPk6irNIB8WBty7B7zwAvDLL3JXReWMQcsSqc9m1arFEYdERIbk5ASsXw8MGADk5QGDBgGffipdWSCLwKBliXjZkIio/KhU0pms99+Xfp8wARg9GigokLUsKh8MWpaIQYuIqHxZWQFz5gBffin9/u23QP/+QHa2vHWRwTFoWSIGLSIieYwZAyxbBiiVwB9/AOHhvGWPmWPQsjQccUhEJK9+/YCNGwFnZ2k2+dBQTmxqxhi0LM3ly0BWFmBtDdSpI3c1RESW6dlnpZtQV68OnD4NtGwpzb1FZodBy9Koz2bVrg3Y2spbCxGRJWvYENi3D2jeXLp8+NxzwJIlcldFZYxBy9LwsiERkfHw8gJiY4E+fYDcXOC114APP+SIRDPCoGVpGLSIiIyLvT2wfDkwaZL0+8yZQEQEcOeOvHVRmWDQsjQMWkRExsfKSgpYixdLIxJXrQJatQLOnZO7MnpKDFqWRAggMVFaZtAiIjI+gwZJ90j09ASOHQOaNQM2b5a7KnoKDFqW5NIl4PZtwMZG6gxPRETGp3Vr4NAhaSTizZtAly68bY8JY9CyJOrLhnXqSLeEICIi41SlitRJ/s03pY7xEyaw35aJYtCyJOyfRURkOmxtgYULgQULpH5bK1cCLVo87AJCJoFBy5IwaBERmZ6hQ6WzW97eUshq1ozzbZkQBi1LwqBFRGSaWrUCjhwBnn8euHdPmm/r9deBu3flroyegEHLUnDEIRGRaatcGdi0CZgxQ5oOYvFiaVZ5Xko0agxaliIlRepEqVQCtWrJXQ0REZWGlRUweTKwbZs0q7z6UuKPP3JUopFi0LIUj444VCrlrYWIiJ5O+/balxKHDgV69ADS0+WujB7DoGUp2D+LiMi8eHpKlxI//1yasmf9eqBBA+knGQ0GLUvBoEVEZH6srICxY4EDB4CGDYFr14Du3aUzXJxzyygwaFkKBi0iIvPVqBGwf78UuhQKqc9W48bS7XxIVgxalqCggCMOiYjMnZ2ddBlx2zagWjXg/HmgY0fp7FZmptzVWSwGLUtw4YLUWVKl4ohDIiJz16EDcPw4MHy49PuPP0r/yf7rL3nrslAMWpZAfdmwbl3phtJERGTeKlQA5s0D4uKA2rWBy5eBF14AXn4ZuHpV7uosCoOWJWD/LCIiy9S2LXD0KPDBB1LH+WXLpGl+vv0WyMuTuzqLwKBlCRi0iIgsl7098OmnUmf5kBAgKwsYNQoIDgZ27pS7OrPHoGUJGLSIiCg4GNi7F/jhB8DNDfj3X+mM16uvAqmpcldnthi0zF1BAXDypLTMoEVEZNmsrYG33gJOn5Z+KhTAr79K/bimTePcWwbAoGXukpKA+/cBW1ugZk25qyEiImPg7i6d2dq3D2jZErh7F5g+XRqZvmAB+2+VIQYtc6e+bBgQIP1PhoiISK1ZM2DPHmDlSilkXb0qTQvRoAGwerV0VYSeCoOWuWP/LCIiKolCAfTuLX1ffPst4OEBnDoFvPQSEBTEwPWUGLTMHYMWERHpQqUC3n0XOHsW+PBDwNlZmhripZeApk0ZuEqJQcvc8dY7RESkDxcX4JNPgOTkh4Hr33+lwNWoEfDzz0B2ttxVmgwGLXOWn88Rh0REVDpubg8D15Qp0mzzJ04Ab7wB+PpKz2VkyF2l0WPQMmdJScCDB9KNRv395a6GiIhMkZsb8PHHQEoK8NlnQNWqUqf5jz4CqleXpok4dEjuKo0Wg5Y5U/fPqlePIw6JiOjpuLgA48YB588DS5dKHeXv3wcWLpRmnA8OlqaMuH1b7kqNCoOWOWNHeCIiKmtKpXRz6oMHgR07pGWVCjh8GBg2DPD2Bl57Ddi8mfNxgUHLvDFoERGRoSgUQJs20tmtK1eAL7+U5my8exdYsgTo1AmoUgUYMQLYvdtiRywyaJkzddAKDJS3DiIiMm/u7sCYMdJI9127gLfflubjSk8H5s4FnnlGCl1vvgn8+acUxiyEQggh5C7CkmVlZcHFxQWZmZmoUKFC2W04Px9wdJSG4J49y9vvEBFR+crNBbZtA5YtA9as0e67ZWsLdOwoPdq3l+bpMrG+xLp+f8t+RmvevHnw9/eHnZ0dgoODsXPnzhLbx8XFITg4GHZ2dqhRowYWLFhQqE10dDQCAwNha2uLwMBArFmzRu/9CiEwbdo0+Pj4wN7eHu3bt8cJ9Rmi/8vOzsa7774LDw8PODo6onv37rh06VIp3gUDOHdOCln29hxxSERE5U+plC4fLlkiTQOxZQswcqT0nZSdDWzcCLz/vnQbIDc34IUXgE8/lcLZzZtyV192hIyWL18ulEqlWLhwoUhMTBSjRo0Sjo6O4sKFC0W2P3/+vHBwcBCjRo0SiYmJYuHChUKpVIpVq1Zp2uzZs0dYW1uLWbNmiZMnT4pZs2YJGxsbsXfvXr32O3v2bOHs7Cyio6PFsWPHREREhPD29hZZWVmaNsOGDRNVqlQRMTEx4vDhw6JDhw6icePGIi8vT+f3IDMzUwAQmZmZ+rx1T7Z6tRCAEEFBZbtdIiKip1FQIMTx40J88YUQL7wghIuL9H31+KNmTSH69hVi+nQhVqwQ4sgRIe7elbt6DV2/v2W9dNiiRQsEBQVh/vz5mnX16tVDz549ERkZWaj9+PHjsW7dOpxUT8IJYNiwYTh69Cji4+MBABEREcjKysLGjRs1bTp16gRXV1csW7ZMp/0KIeDj44PRo0dj/PjxAKSzV56envj0008xdOhQZGZmolKlSvj1118REREBALhy5QqqVauGv//+G+Hh4Tq9Bwa7dDhjhjTB3MCBwC+/lN12iYiIylJ+vnSrn+3bgX37pNGMSUnFt69aVXpUqQL4+Eg/K1WSJlR1dn74U6WSLkfa2Eh9yJycyrRsXb+/bcp0r3rIycnBoUOHMGHCBK31YWFh2LNnT5GviY+PR1hYmNa68PBwREVFITc3F0qlEvHx8RgzZkyhNl9//bXO+01KSkJaWprWvmxtbdGuXTvs2bMHQ4cOxaFDh5Cbm6vVxsfHBw0aNMCePXuKDVrZ2dnIfuTWBVlZWUW2e2occUhERKbA2lqakyso6OG669el6SIOHwb++0+6yfWpU8CNG8ClS9JDHwsWAEOHlm3dOpItaGVkZCA/Px+enp5a6z09PZGWllbka9LS0opsn5eXh4yMDHh7exfbRr1NXfar/llUmwsXLmjaqFQquLq66lw/AERGRmL69OnFPl9mZs0CIiI44pCIiEyPuzvw/PPS41EZGVIf5MuXpSklLl+WHjduAFlZDx+3b0tzeKkfSqU8xwEZg5aaQqHQ+l0IUWjdk9o/vl6XbZZVm8c9qc3EiRPx3nvvaX7PyspCtWrVStxmqfj7sxM8ERGZFw8P6WFCZBt16OHhAWtr60Jnf9LT0wudSVLz8vIqsr2NjQ3c3d1LbKPepi779fLyAoAntsnJycHNx0ZGlFQ/IF2CrFChgtaDiIiIzJNsQUulUiE4OBgxMTFa62NiYtCqVasiXxMaGlqo/ZYtWxASEgLl/08LFtdGvU1d9uvv7w8vLy+tNjk5OYiLi9O0CQ4OhlKp1GqTmpqK48ePF1s/ERERWRjDDn4smXqahaioKJGYmChGjx4tHB0dRXJyshBCiAkTJoiBAwdq2qundxgzZoxITEwUUVFRhaZ32L17t7C2thazZ88WJ0+eFLNnzy52eofi9iuENL2Di4uLWL16tTh27Jjo379/kdM7VK1aVWzdulUcPnxYdOzY0XimdyAiIiKD0fX7W9agJYQQc+fOFb6+vkKlUomgoCARFxeneW7QoEGiXbt2Wu1jY2NF06ZNhUqlEn5+fmL+/PmFtrly5UpRt25doVQqRUBAgIiOjtZrv0IIUVBQIKZOnSq8vLyEra2taNu2rTh27JhWm/v374sRI0YINzc3YW9vL7p16yZSUlL0On4GLSIiItNjEvNokQHn0SIiIiKDMZlb8BARERGZKwYtIiIiIgNh0CIiIiIyEAYtIiIiIgNh0CIiIiIyEAYtIiIiIgNh0CIiIiIyEAYtIiIiIgNh0CIiIiIyEBu5C7B06on5s7KyZK6EiIiIdKX+3n7SDXYYtGR2+/ZtAEC1atVkroSIiIj0dfv2bbi4uBT7PO91KLOCggJcuXIFzs7OUCgUZbbdrKwsVKtWDRcvXjTbeyia+zGa+/EB5n+MPD7TZ+7HyOMrPSEEbt++DR8fH1hZFd8Ti2e0ZGZlZYWqVasabPsVKlQwy788jzL3YzT34wPM/xh5fKbP3I+Rx1c6JZ3JUmNneCIiIiIDYdAiIiIiMhAGLTNla2uLqVOnwtbWVu5SDMbcj9Hcjw8w/2Pk8Zk+cz9GHp/hsTM8ERERkYHwjBYRERGRgTBoERERERkIgxYRERGRgTBoERERERkIg5aZmjdvHvz9/WFnZ4fg4GDs3LlT7pJ0Mm3aNCgUCq2Hl5eX5nkhBKZNmwYfHx/Y29ujffv2OHHihNY2srOz8e6778LDwwOOjo7o3r07Ll26VN6HAgDYsWMHXnjhBfj4+EChUGDt2rVaz5fV8dy8eRMDBw6Ei4sLXFxcMHDgQNy6dcvAR/fk43vttdcKfZ4tW7bUamPMxxcZGYlmzZrB2dkZlStXRs+ePXHq1CmtNqb+GepyjKb8Oc6fPx+NGjXSTFgZGhqKjRs3ap439c/vScdnyp9dUSIjI6FQKDB69GjNOqP/DAWZneXLlwulUikWLlwoEhMTxahRo4Sjo6O4cOGC3KU90dSpU0X9+vVFamqq5pGenq55fvbs2cLZ2VlER0eLY8eOiYiICOHt7S2ysrI0bYYNGyaqVKkiYmJixOHDh0WHDh1E48aNRV5eXrkfz99//y0mT54soqOjBQCxZs0arefL6ng6deokGjRoIPbs2SP27NkjGjRoILp16yb78Q0aNEh06tRJ6/O8fv26VhtjPr7w8HCxaNEicfz4cXHkyBHRtWtXUb16dXHnzh1NG1P/DHU5RlP+HNetWyc2bNggTp06JU6dOiUmTZoklEqlOH78uBDC9D+/Jx2fKX92j9u/f7/w8/MTjRo1EqNGjdKsN/bPkEHLDDVv3lwMGzZMa11AQICYMGGCTBXpburUqaJx48ZFPldQUCC8vLzE7NmzNesePHggXFxcxIIFC4QQQty6dUsolUqxfPlyTZvLly8LKysrsWnTJoPW/iSPB5GyOp7ExEQBQOzdu1fTJj4+XgAQ//33n4GP6qHiglaPHj2KfY0pHZ8QQqSnpwsAIi4uTghhfp+hEIWPUQjz+xxdXV3FTz/9ZJafnxAPj08I8/nsbt++LWrXri1iYmJEu3btNEHLFD5DXjo0Mzk5OTh06BDCwsK01oeFhWHPnj0yVaWfM2fOwMfHB/7+/ujXrx/Onz8PAEhKSkJaWprWsdna2qJdu3aaYzt06BByc3O12vj4+KBBgwZGd/xldTzx8fFwcXFBixYtNG1atmwJFxcXozjm2NhYVK5cGXXq1MGQIUOQnp6uec7Uji8zMxMA4ObmBsA8P8PHj1HNHD7H/Px8LF++HHfv3kVoaKjZfX6PH5+aOXx277zzDrp27YrnnntOa70pfIa8qbSZycjIQH5+Pjw9PbXWe3p6Ii0tTaaqdNeiRQv88ssvqFOnDq5evYoZM2agVatWOHHihKb+oo7twoULAIC0tDSoVCq4uroWamNsx19Wx5OWlobKlSsX2n7lypVlP+bOnTujT58+8PX1RVJSEqZMmYKOHTvi0KFDsLW1NanjE0LgvffewzPPPIMGDRpoalPX+yhT/QyLOkbA9D/HY8eOITQ0FA8ePICTkxPWrFmDwMBAzReoqX9+xR0fYPqfHQAsX74chw8fxoEDBwo9Zwp/Bxm0zJRCodD6XQhRaJ0x6ty5s2a5YcOGCA0NRc2aNbFkyRJNB87SHJsxH39ZHE9R7Y3hmCMiIjTLDRo0QEhICHx9fbFhwwb06tWr2NcZ4/GNGDEC//77L3bt2lXoOXP5DIs7RlP/HOvWrYsjR47g1q1biI6OxqBBgxAXF1dsXab2+RV3fIGBgSb/2V28eBGjRo3Cli1bYGdnV2w7Y/4MeenQzHh4eMDa2rpQAk9PTy+U+E2Bo6MjGjZsiDNnzmhGH5Z0bF5eXsjJycHNmzeLbWMsyup4vLy8cPXq1ULbv3btmtEds7e3N3x9fXHmzBkApnN87777LtatW4ft27ejatWqmvXm9BkWd4xFMbXPUaVSoVatWggJCUFkZCQaN26Mb775xmw+v+KOryim9tkdOnQI6enpCA4Oho2NDWxsbBAXF4dvv/0WNjY2mv0b82fIoGVmVCoVgoODERMTo7U+JiYGrVq1kqmq0svOzsbJkyfh7e0Nf39/eHl5aR1bTk4O4uLiNMcWHBwMpVKp1SY1NRXHjx83uuMvq+MJDQ1FZmYm9u/fr2mzb98+ZGZmGt0xX79+HRcvXoS3tzcA4z8+IQRGjBiB1atX459//oG/v7/W8+bwGT7pGItiap/j44QQyM7ONovPryjq4yuKqX12zz77LI4dO4YjR45oHiEhIRgwYACOHDmCGjVqGP9n+FRd6ckoqad3iIqKEomJiWL06NHC0dFRJCcny13aE40dO1bExsaK8+fPi71794pu3boJZ2dnTe2zZ88WLi4uYvXq1eLYsWOif//+RQ7jrVq1qti6das4fPiw6Nixo2zTO9y+fVskJCSIhIQEAUB8+eWXIiEhQTPVRlkdT6dOnUSjRo1EfHy8iI+PFw0bNiyXodclHd/t27fF2LFjxZ49e0RSUpLYvn27CA0NFVWqVDGZ4xs+fLhwcXERsbGxWsPj7927p2lj6p/hk47R1D/HiRMnih07doikpCTx77//ikmTJgkrKyuxZcsWIYTpf34lHZ+pf3bFeXTUoRDG/xkyaJmpuXPnCl9fX6FSqURQUJDWUG1jpp7/RKlUCh8fH9GrVy9x4sQJzfMFBQVi6tSpwsvLS9ja2oq2bduKY8eOaW3j/v37YsSIEcLNzU3Y29uLbt26iZSUlPI+FCGEENu3bxcACj0GDRokhCi747l+/boYMGCAcHZ2Fs7OzmLAgAHi5s2bsh7fvXv3RFhYmKhUqZJQKpWievXqYtCgQYVqN+bjK+rYAIhFixZp2pj6Z/ikYzT1z3Hw4MGafwsrVaoknn32WU3IEsL0P7+Sjs/UP7viPB60jP0zVAghxNOdEyMiIiKiorCPFhEREZGBMGgRERERGQiDFhEREZGBMGgRERERGQiDFhEREZGBMGgRERERGQiDFhEREZGBMGgRERERGQiDFhGRDtLT0zF06FBUr14dtra28PLyQnh4OOLj4wEACoUCa9eulbdIIjI6NnIXQERkCl566SXk5uZiyZIlqFGjBq5evYpt27bhxo0bcpdGREaMt+AhInqCW7duwdXVFbGxsWjXrl2h5/38/HDhwgXN776+vkhOTgYArF+/HtOmTcOJEyfg4+ODQYMGYfLkybCxkf6fq1AoMG/ePKxbtw6xsbHw8vLCnDlz0KdPn3I5NiIyLF46JCJ6AicnJzg5OWHt2rXIzs4u9PyBAwcAAIsWLUJqaqrm982bN+OVV17ByJEjkZiYiB9++AGLFy/GzJkztV4/ZcoUvPTSSzh69CheeeUV9O/fHydPnjT8gRGRwfGMFhGRDqKjozFkyBDcv38fQUFBaNeuHfr164dGjRoBkM5MrVmzBj179tS8pm3btujcuTMmTpyoWffbb7/hgw8+wJUrVzSvGzZsGObPn69p07JlSwQFBWHevHnlc3BEZDA8o0VEpIOXXnoJV65cwbp16xAeHo7Y2FgEBQVh8eLFxb7m0KFD+PjjjzVnxJycnDBkyBCkpqbi3r17mnahoaFarwsNDeUZLSIzwc7wREQ6srOzw/PPP4/nn38eH330Ed58801MnToVr732WpHtCwoKMH36dPTq1avIbZVEoVCURclEJDOe0SIiKqXAwEDcvXsXAKBUKpGfn6/1fFBQEE6dOoVatWoVelhZPfznd+/evVqv27t3LwICAgx/AERkcDyjRUT0BNevX0efPn0wePBgNGrUCM7Ozjh48CDmzJmDHj16AJBGHm7btg2tW7eGra0tXF1d8dFHH6Fbt26oVq0a+vTpAysrK/z77784duwYZsyYodn+ypUrERISgmeeeQZLly7F/v37ERUVJdfhElEZYmd4IqInyM7OxrRp07BlyxacO3cOubm5mvA0adIk2NvbY/369XjvvfeQnJyMKlWqaKZ32Lx5Mz7++GMkJCRAqVQiICAAb775JoYMGQJAukQ4d+5crF27Fjt27ICXlxdmz56Nfv36yXjERFRWGLSIiGRU1GhFIjIf7KNFREREZCAMWkREREQGws7wREQyYu8NIvPGM1pEREREBsKgRURERGQgDFpEREREBsKgRURERGQgDFpEREREBsKgRURERGQgDFpEREREBsKgRURERGQgDFpEREREBvI/gqwDfU1n92YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "\n",
    "# step() 호출하면서 학습률 추적\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule.step())\n",
    "\n",
    "# 시각화\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend()\n",
    "plt.title('Learning Rate Schedule (Cosine)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fab4151-81d0-4852-b429-7322eb1cc8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "PreTrainModel                                                [10, 2]                   --\n",
       "├─BERT: 1-1                                                  [10, 64]                  --\n",
       "│    └─SharedEmbedding: 2-1                                  [10, 128, 64]             512,000\n",
       "│    └─PositionEmbedding: 2-2                                [10, 128, 64]             --\n",
       "│    │    └─Embedding: 3-1                                   [10, 128, 64]             8,192\n",
       "│    └─Embedding: 2-3                                        [10, 128, 64]             128\n",
       "│    └─LayerNorm: 2-4                                        [10, 128, 64]             128\n",
       "│    └─Dropout: 2-5                                          [10, 128, 64]             --\n",
       "│    └─ModuleList: 2-6                                       --                        --\n",
       "│    │    └─EncoderLayer: 3-2                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-3                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-4                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-5                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-6                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-7                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-8                                [10, 128, 64]             49,984\n",
       "│    │    └─EncoderLayer: 3-9                                [10, 128, 64]             49,984\n",
       "│    └─SharedEmbedding: 2-7                                  [10, 128, 8000]           (recursive)\n",
       "├─PooledOutput: 1-2                                          [10, 2]                   --\n",
       "│    └─Linear: 2-8                                           [10, 64]                  4,160\n",
       "│    └─Linear: 2-9                                           [10, 2]                   128\n",
       "==============================================================================================================\n",
       "Total params: 924,608\n",
       "Trainable params: 924,608\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.31\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 142.22\n",
       "Params size (MB): 3.70\n",
       "Estimated Total Size (MB): 145.93\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.n_seq = 128\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "\n",
    "# GPU/CPU 자동 선택\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pre_train_model.to(device)\n",
    "\n",
    "# 더미 입력 생성 (batch=10, seq_len=128)\n",
    "enc_tokens_example = torch.randint(0, config.n_vocab, (10, config.n_seq), dtype=torch.long).to(device)\n",
    "segments_example   = torch.randint(0, 2, (10, config.n_seq), dtype=torch.long).to(device)\n",
    "\n",
    "# 모델 summary 출력\n",
    "summary(pre_train_model, [(10, config.n_seq), (10, config.n_seq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a8de75d-2061-4c31-94ff-2c17a003c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# 총 train step 계산 (배치 개수 × epoch)\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "\n",
    "# 학습률 스케줄러 (Warmup + Cosine Decay)\n",
    "learning_rate_scheduler = CosineSchedule(\n",
    "    train_steps=train_steps,\n",
    "    warmup_steps=max(100, train_steps // 10)  # 최소 100 step 이상 warmup\n",
    ")\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = optim.Adam(pre_train_model.parameters(), lr=1e-4)\n",
    "\n",
    "# 손실 함수\n",
    "loss_fn_nsp = nn.CrossEntropyLoss()  # NSP (2-class)\n",
    "loss_fn_mlm = nn.CrossEntropyLoss()  # MLM (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edfc0f6d-1c46-454a-a8ac-b341b4322d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 9.0404, NSP Loss: 0.6625, MLM Loss: 8.3779, NSP Accuracy: 0.5971, MLM Accuracy: 0.7244\n",
      "Epoch 2/10 - Loss: 8.7776, NSP Loss: 0.6587, MLM Loss: 8.1189, NSP Accuracy: 0.5993, MLM Accuracy: 0.8693\n",
      "Epoch 3/10 - Loss: 8.7763, NSP Loss: 0.6580, MLM Loss: 8.1184, NSP Accuracy: 0.5963, MLM Accuracy: 0.8693\n",
      "Epoch 4/10 - Loss: 8.7758, NSP Loss: 0.6576, MLM Loss: 8.1182, NSP Accuracy: 0.5982, MLM Accuracy: 0.8693\n",
      "Epoch 5/10 - Loss: 8.7755, NSP Loss: 0.6574, MLM Loss: 8.1182, NSP Accuracy: 0.5962, MLM Accuracy: 0.8693\n",
      "Epoch 6/10 - Loss: 8.7753, NSP Loss: 0.6571, MLM Loss: 8.1181, NSP Accuracy: 0.5990, MLM Accuracy: 0.8693\n",
      "Epoch 7/10 - Loss: 8.7752, NSP Loss: 0.6570, MLM Loss: 8.1181, NSP Accuracy: 0.5986, MLM Accuracy: 0.8693\n",
      "Epoch 8/10 - Loss: 8.7747, NSP Loss: 0.6565, MLM Loss: 8.1181, NSP Accuracy: 0.5992, MLM Accuracy: 0.8693\n",
      "Epoch 9/10 - Loss: 8.7744, NSP Loss: 0.6563, MLM Loss: 8.1181, NSP Accuracy: 0.6041, MLM Accuracy: 0.8693\n",
      "Epoch 10/10 - Loss: 8.7716, NSP Loss: 0.6535, MLM Loss: 8.1181, NSP Accuracy: 0.6141, MLM Accuracy: 0.8693\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Memmap → Tensor 변환 후 GPU로 이동\n",
    "pre_train_inputs = [torch.tensor(np.array(x)).to(device) for x in pre_train_inputs]\n",
    "pre_train_labels = [torch.tensor(np.array(x)).to(device) for x in pre_train_labels]\n",
    "\n",
    "# Dataset & Dataloader 구성\n",
    "train_dataset = TensorDataset(\n",
    "    pre_train_inputs[0],  # enc_tokens\n",
    "    pre_train_inputs[1],  # segments\n",
    "    pre_train_labels[0],  # labels_nsp\n",
    "    pre_train_labels[1]   # labels_mlm\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 모델 GPU로 이동\n",
    "pre_train_model.to(device)\n",
    "\n",
    "# 학습 로그 저장용\n",
    "history = {\n",
    "    'nsp_loss': [],\n",
    "    'mlm_loss': [],\n",
    "    'nsp_acc': [],\n",
    "    'mlm_acc': []\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pre_train_model.train()\n",
    "    total_loss = 0\n",
    "    total_nsp_loss = 0\n",
    "    total_mlm_loss = 0\n",
    "    total_nsp_acc = 0\n",
    "    total_mlm_acc = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        enc_tokens_batch, segments_batch, labels_nsp_batch, labels_mlm_batch = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        logits_nsp, logits_mlm = pre_train_model(enc_tokens_batch, segments_batch)\n",
    "\n",
    "        # 라벨 타입 보정\n",
    "        labels_nsp_batch = labels_nsp_batch.long()\n",
    "        labels_mlm_batch = labels_mlm_batch.clamp(0, config.n_vocab - 1).long()\n",
    "\n",
    "        # Loss 계산\n",
    "        loss_nsp = loss_fn_nsp(logits_nsp, labels_nsp_batch)\n",
    "        loss_mlm = loss_fn_mlm(\n",
    "            logits_mlm.view(-1, logits_mlm.shape[-1]),\n",
    "            labels_mlm_batch.view(-1)\n",
    "        )\n",
    "\n",
    "        total_loss_batch = loss_nsp + loss_mlm\n",
    "        total_loss += total_loss_batch.item()\n",
    "        total_nsp_loss += loss_nsp.item()\n",
    "        total_mlm_loss += loss_mlm.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        total_loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy 계산\n",
    "        nsp_acc = (logits_nsp.argmax(dim=-1) == labels_nsp_batch).float().mean()\n",
    "        mlm_acc = (logits_mlm.argmax(dim=-1) == labels_mlm_batch).float().mean()\n",
    "\n",
    "        total_nsp_acc += nsp_acc.item()\n",
    "        total_mlm_acc += mlm_acc.item()\n",
    "\n",
    "    # Epoch 평균 기록\n",
    "    history['nsp_loss'].append(total_nsp_loss / len(train_dataloader))\n",
    "    history['mlm_loss'].append(total_mlm_loss / len(train_dataloader))\n",
    "    history['nsp_acc'].append(total_nsp_acc / len(train_dataloader))\n",
    "    history['mlm_acc'].append(total_mlm_acc / len(train_dataloader))\n",
    "\n",
    "    # 로그 출력\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} - \"\n",
    "        f\"Loss: {total_loss / len(train_dataloader):.4f}, \"\n",
    "        f\"NSP Loss: {total_nsp_loss / len(train_dataloader):.4f}, \"\n",
    "        f\"MLM Loss: {total_mlm_loss / len(train_dataloader):.4f}, \"\n",
    "        f\"NSP Accuracy: {total_nsp_acc / len(train_dataloader):.4f}, \"\n",
    "        f\"MLM Accuracy: {total_mlm_acc / len(train_dataloader):.4f}\"\n",
    "    )\n",
    "\n",
    "    # 모델 저장 \n",
    "    torch.save(pre_train_model.state_dict(), f\"bert_pre_train_epoch_{epoch+1}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c81e5a7-9506-4dca-897e-552dde341ec4",
   "metadata": {},
   "source": [
    "##### 프로젝트 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab6a88dd-2468-4225-8f37-9206e8677cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# (왼쪽) NSP/MLM Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['nsp_loss'], 'b-', label='NSP Loss')\n",
    "plt.plot(history['mlm_loss'], 'r--', label='MLM Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# (오른쪽) NSP/MLM Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['nsp_acc'], 'g-', label='NSP Accuracy')\n",
    "plt.plot(history['mlm_acc'], 'k--', label='MLM Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b828700-391f-442c-bed4-4566542bd04c",
   "metadata": {},
   "source": [
    "#### 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db3110",
   "metadata": {},
   "source": [
    "이번 프로젝트는 노드를 충실히 따라가며 한국어 위키피디아 코퍼스를 활용해 BERT 사전학습을 직접 구현하는 데 초점을 맞추었다. \n",
    "\n",
    "프로젝트에서 제시한 1M 이하의 파라미터 제한을 만족하기 위해 약 92만 개의 파라미터를 가진 경량 BERT 모델을 구축하였고, 보카브 사이즈는 8,000으로 설정하였다.\n",
    "\n",
    "학습 과정에서는 BERT의 핵심 과제인 MLM(Masked Language Modeling)과 NSP(Next Sentence Prediction)을 구현하였으며, \n",
    "\n",
    "이를 위해 트랜스포머의 Encoder 구조를 기반으로 멀티헤드 어텐션, 포지션와이즈 피드포워드 네트워크, 임베딩 레이어 등을 직접 구성하였다. \n",
    "\n",
    "학습은 총 10 epoch 동안 진행되었고, 그 결과 NSP Loss는 0.6625에서 0.6535로, MLM Loss는 8.3779에서 8.1181로 점차 감소하였다. \n",
    "\n",
    "또한 NSP 정확도는 약 61.4%, MLM 정확도는 약 86.9%에 도달하여 모델이 정상적으로 학습되고 있음을 확인할 수 있었다. \n",
    "\n",
    "특히 Warmup과 Cosine Decay를 적용한 학습률 스케줄러가 학습의 안정성에 크게 기여한 것으로 보인다.\n",
    "\n",
    "아쉬운 점은 전체 위키피디아 코퍼스에서 생성된 약 91만 개의 학습 인스턴스 중 128,000개만 사용하여 학습을 진행했다는 점이다. \n",
    "\n",
    "또한 10 epoch라는 짧은 학습 기간 역시 성능을 제약한 요인으로 작용했다고 생각한다. \n",
    "\n",
    "그 결과 NSP 정확도가 61% 수준에 머문 것도 데이터와 학습량 부족의 영향이 컸을 것으로 보인다.\n",
    "\n",
    "이번 프로젝트를 통해 BERT 사전학습의 구조와 원리를 직접 구현하며 이론적 이해를 실제로 체득할 수 있었고, 학습 안정성을 위한 학습률 스케줄러의 효과를 경험할 수 있었다. \n",
    "\n",
    "향후에는 이번에 사전학습시킨 모델을 파인튜닝하여 다운스트림 태스크에 적용해보고, 더 많은 데이터와 자원을 활용해 성능을 개선하는 실험을 진행해보고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268df6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-sEJcFcNq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
